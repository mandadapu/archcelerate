# Architectural ROI: Unit Economics & Model Selection Matrix

Engineering for **cost-performance efficiency** at scale—because every token has a price, and every model choice has an ROI.

> **Architect Perspective**: AI architecture isn't about "which is best"—it's about **maximizing value per dollar** while meeting quality thresholds. The right model is the **cheapest one that passes your quality bar**.

## The Unit Economics Problem

**Reality Check**: AI costs scale linearly with usage
- Production chatbot: 10K users × 100 msgs/day × 500 tokens/msg = **500M tokens/day**
- At Opus pricing ($15/MTok input): **$7,500/day** = **$225K/month**
- At Sonnet pricing ($3/MTok input): **$1,500/day** = **$45K/month**
- At Haiku pricing ($0.25/MTok input): **$125/day** = **$3.75K/month**

**Architectural Mandate**: Your model selection directly determines whether your AI product is **profitable or a cost center**.

## The Efficiency Frontier: 2026 Model Pricing Reality

**The Physics of Cost**: Every model sits on a cost-performance curve. Your job is to find the **minimum viable quality** at the **lowest cost**.

### Claude 4.5 Series: The 2026 Price-Performance Landscape

| Model | Input $/MTok | Output $/MTok | Latency (p95) | Quality Tier | Best For |
|-------|-------------|--------------|---------------|--------------|----------|
| **Opus 4.5** | $15 | $75 | 4-8s | Tier 1 (Frontier) | Complex reasoning, research, code generation |
| **Sonnet 4.5** | $3 | $15 | 1-3s | Tier 1 (Production) | General chat, summarization, most tasks |
| **Haiku 4.5** | $0.25 | $1.25 | 0.3-0.8s | Tier 2 (Fast) | Classification, extraction, high-volume |

**The Cost Multiplier Effect**:
- Opus is **60x more expensive** than Haiku
- Sonnet is **12x more expensive** than Haiku
- At 500M tokens/day, the difference between Haiku and Opus is **$221K/month**

### The Model Selection Matrix: ROI-Driven Decisions

**Framework**: Start with the cheapest model, upgrade only when quality metrics fail.

```typescript
interface ModelTier {
  name: string
  costPerMTok: { input: number; output: number }
  latency: number
  qualityScore: number  // 0-100, measured on your eval set
}

const TIER_SYSTEM: ModelTier[] = [
  {
    name: 'claude-haiku-4.5',
    costPerMTok: { input: 0.25, output: 1.25 },
    latency: 500,      // ms p95
    qualityScore: 75   // Your evals
  },
  {
    name: 'claude-sonnet-4.5',
    costPerMTok: { input: 3, output: 15 },
    latency: 2000,
    qualityScore: 92
  },
  {
    name: 'claude-opus-4.5',
    costPerMTok: { input: 15, output: 75 },
    latency: 6000,
    qualityScore: 98
  }
]

// Decision Logic: Cost-First Selection
function selectModel(
  taskType: string,
  qualityThreshold: number = 85
): string {
  // Try tiers in cost order
  for (const tier of TIER_SYSTEM) {
    const taskQuality = getTaskQuality(taskType, tier.name)

    if (taskQuality >= qualityThreshold) {
      console.log(`Selected ${tier.name} (quality: ${taskQuality}, cost: $${tier.costPerMTok.input}/MTok)`)
      return tier.name
    }
  }

  // Fallback to highest quality if nothing passes
  return TIER_SYSTEM[TIER_SYSTEM.length - 1].name
}

// Example: Task-based quality mapping
function getTaskQuality(task: string, model: string): number {
  const qualityMatrix: Record<string, Record<string, number>> = {
    'classification': {
      'claude-haiku-4.5': 95,   // ✅ Haiku excels at this
      'claude-sonnet-4.5': 97,
      'claude-opus-4.5': 98
    },
    'summarization': {
      'claude-haiku-4.5': 78,   // ⚠️  Below threshold for critical use
      'claude-sonnet-4.5': 93,  // ✅ Sonnet hits 85%+ threshold
      'claude-opus-4.5': 97
    },
    'code-generation': {
      'claude-haiku-4.5': 65,   // ❌ Fails threshold
      'claude-sonnet-4.5': 88,  // ✅ Acceptable
      'claude-opus-4.5': 96     // ✅ Best, but is it worth 5x cost?
    }
  }

  return qualityMatrix[task]?.[model] ?? 0
}
```

**Result**:
- Classification: **Always use Haiku** (95% quality, $0.25/MTok)
- Summarization: **Use Sonnet** (93% quality, $3/MTok) - Haiku fails threshold
- Code Gen: **Use Sonnet** (88% quality, $3/MTok) - Opus's 8-point improvement doesn't justify 5x cost

### ROI Calculation: The Cost-Per-Conversation Economics

**Framework**: Calculate unit economics to justify model selection.

```typescript
interface ConversationCost {
  model: string
  avgInputTokens: number
  avgOutputTokens: number
  conversationsPerDay: number
  monthlyCost: number
  costPerConversation: number
}

function calculateCosts(
  model: string,
  inputPrice: number,
  outputPrice: number,
  avgInputTokens: number,
  avgOutputTokens: number,
  dailyConversations: number
): ConversationCost {
  // Cost per single conversation
  const inputCost = (avgInputTokens / 1_000_000) * inputPrice
  const outputCost = (avgOutputTokens / 1_000_000) * outputPrice
  const costPerConvo = inputCost + outputCost

  // Monthly cost at scale
  const monthlyCost = costPerConvo * dailyConversations * 30

  return {
    model,
    avgInputTokens,
    avgOutputTokens,
    conversationsPerDay: dailyConversations,
    monthlyCost,
    costPerConversation: costPerConvo
  }
}

// Example: Customer support chatbot
const DAILY_CONVERSATIONS = 50_000
const AVG_INPUT_TOKENS = 2_000   // System prompt + history + question
const AVG_OUTPUT_TOKENS = 500    // Response length

const scenarios = [
  calculateCosts('Opus 4.5', 15, 75, AVG_INPUT_TOKENS, AVG_OUTPUT_TOKENS, DAILY_CONVERSATIONS),
  calculateCosts('Sonnet 4.5', 3, 15, AVG_INPUT_TOKENS, AVG_OUTPUT_TOKENS, DAILY_CONVERSATIONS),
  calculateCosts('Haiku 4.5', 0.25, 1.25, AVG_INPUT_TOKENS, AVG_OUTPUT_TOKENS, DAILY_CONVERSATIONS)
]

/* Results:
Opus 4.5:   $0.0675/conversation × 50K/day = $101,250/month
Sonnet 4.5: $0.0135/conversation × 50K/day = $20,250/month
Haiku 4.5:  $0.00113/conversation × 50K/day = $1,695/month

ROI Analysis:
- Opus costs 60x more than Haiku
- Sonnet costs 12x more than Haiku
- If Haiku quality is 85% and Sonnet is 92%:
  → Is 7% quality improvement worth $18,555/month?
  → Only if customer retention impact > $18,555/month
*/
```

**Decision Framework**:
```typescript
// The ROI Formula
const qualityGain = sonnetQuality - haikuQuality  // e.g., 92 - 85 = 7%
const costDelta = sonnetCost - haikuCost          // e.g., $20,250 - $1,695 = $18,555
const breakEvenLTV = costDelta / (conversionRate * qualityGain)

// Example: If 7% quality improvement increases conversions by 3%
const additionalRevenue = dailyConversions * 0.03 * avgOrderValue
// Use Sonnet only if additionalRevenue > $18,555/month
```

## Optimization Strategies: Input Token Cost Management

**The Input Token Problem**: In conversational AI, input tokens (context) grow unbounded, but **you pay for every token on every request**.

### Cost Growth Pattern

```typescript
// Conversation turn costs
interface TurnCost {
  turn: number
  inputTokens: number
  cost: number
}

// ❌ Naive approach: Send full history every time
function calculateNaiveCosts(): TurnCost[] {
  const SYSTEM_PROMPT = 1_000  // tokens
  const TURN_SIZE = 500        // tokens per turn (user + assistant)

  const costs: TurnCost[] = []
  let cumulativeTokens = SYSTEM_PROMPT

  for (let turn = 1; turn <= 20; turn++) {
    cumulativeTokens += TURN_SIZE
    costs.push({
      turn,
      inputTokens: cumulativeTokens,
      cost: (cumulativeTokens / 1_000_000) * 3  // Sonnet pricing
    })
  }

  return costs
}

/* Result: Exponential cost growth
Turn 1:  1,500 tokens  = $0.0045
Turn 5:  3,500 tokens  = $0.0105
Turn 10: 6,000 tokens  = $0.0180
Turn 20: 11,000 tokens = $0.0330

20-turn conversation cost: 20 turns × avg $0.0195 = $0.39
At 50K conversations/day: $585K/month (unsustainable!)
*/
```

### Strategy 1: Truncate (Sliding Window)

**Pattern**: Keep only the last N turns, discard old context.

```typescript
// ✅ Truncation: Fixed token budget
const MAX_HISTORY_TURNS = 10  // Last 10 turns only

function truncateHistory(
  messages: Message[],
  maxTurns: number = MAX_HISTORY_TURNS
): Message[] {
  // Always keep system prompt
  const systemMessage = messages.find(m => m.role === 'system')

  // Take last N user/assistant turns
  const conversationTurns = messages.filter(m => m.role !== 'system')
  const recentTurns = conversationTurns.slice(-maxTurns * 2)  // *2 for user+assistant pairs

  return systemMessage
    ? [systemMessage, ...recentTurns]
    : recentTurns
}

// Cost impact: Caps at ~6K tokens regardless of conversation length
// Turn 20 cost: $0.018 (instead of $0.033)
// Monthly savings: $585K → $270K (54% reduction)
```

**Pros:**
- ✅ Simple to implement
- ✅ Predictable costs
- ✅ No additional API calls

**Cons:**
- ❌ Loses context from early conversation
- ❌ Poor for long-running sessions (e.g., multi-day support tickets)

### Strategy 2: Summarize (Context Compression)

**Pattern**: Summarize old turns into a condensed context block.

```typescript
// ✅ Summarization: Compress old context
async function summarizeAndCompress(
  messages: Message[],
  turnThreshold: number = 10
): Promise<Message[]> {
  if (messages.length <= turnThreshold * 2) {
    return messages  // Not long enough to summarize
  }

  const systemMessage = messages.find(m => m.role === 'system')
  const conversationTurns = messages.filter(m => m.role !== 'system')

  // Split into old (to summarize) and recent (keep verbatim)
  const oldTurns = conversationTurns.slice(0, -turnThreshold * 2)
  const recentTurns = conversationTurns.slice(-turnThreshold * 2)

  // Summarize old turns using Haiku (cheap summarization)
  const summary = await anthropic.messages.create({
    model: 'claude-haiku-4.5',  // $0.25/MTok for summarization
    max_tokens: 500,              // Cap summary length
    messages: [
      {
        role: 'user',
        content: `Summarize this conversation history into key points (max 500 tokens):

${oldTurns.map(m => `${m.role}: ${m.content}`).join('\n\n')}`
      }
    ]
  })

  // Build compressed context
  return [
    systemMessage!,
    { role: 'system', content: `Previous context: ${summary.content[0].text}` },
    ...recentTurns
  ]
}

/* Cost Analysis:
Original 20-turn conversation: 11,000 input tokens
After summarization:
  - System prompt: 1,000 tokens
  - Summary of turns 1-10: 500 tokens (compressed from 5,000)
  - Recent turns 11-20: 5,000 tokens
  - Total: 6,500 tokens (vs. 11,000 original)

Savings: 41% input token reduction
Summarization cost: ~2,500 tokens @ $0.25/MTok = $0.000625 (negligible)
*/
```

**Pros:**
- ✅ Preserves context from entire conversation
- ✅ Suitable for long-running sessions
- ✅ Quality degradation minimal

**Cons:**
- ❌ Additional API call for summarization
- ❌ Adds latency (~500ms for summary)
- ❌ More complex implementation

### Decision Matrix: Truncate vs. Summarize

| Factor | Truncate | Summarize |
|--------|----------|-----------|
| **Cost Savings** | 54% | 41% + summary cost |
| **Context Retention** | Poor (loses history) | Good (compresses history) |
| **Complexity** | Low | Medium |
| **Latency** | None | +500ms per summarization |
| **Best For** | Short sessions (<10 turns), FAQ bots | Long sessions, customer support, research |

**Production Pattern: Hybrid Approach**

```typescript
// ✅ Best of both worlds
async function optimizeContext(
  messages: Message[],
  sessionType: 'short' | 'long'
): Promise<Message[]> {
  const turnCount = messages.filter(m => m.role !== 'system').length / 2

  if (sessionType === 'short' || turnCount <= 15) {
    // Short sessions: Truncate (simpler, faster)
    return truncateHistory(messages, 10)
  } else {
    // Long sessions: Summarize (preserve context)
    return await summarizeAndCompress(messages, 10)
  }
}
```

## Production Cost Optimization Patterns

### Pattern 1: Tiered Quality System

**Strategy**: Route tasks to different model tiers based on complexity and user tier.

```typescript
interface UserTier {
  tier: 'free' | 'pro' | 'enterprise'
  model: string
  maxTokens: number
  monthlyCost: number
}

const USER_TIER_CONFIG: Record<string, UserTier> = {
  free: {
    tier: 'free',
    model: 'claude-haiku-4.5',
    maxTokens: 500,
    monthlyCost: 0  // Target: break even with ads/upsell
  },
  pro: {
    tier: 'pro',
    model: 'claude-sonnet-4.5',
    maxTokens: 2000,
    monthlyCost: 20  // $20/month subscription
  },
  enterprise: {
    tier: 'enterprise',
    model: 'claude-opus-4.5',
    maxTokens: 4000,
    monthlyCost: 200  // $200/month subscription
  }
}

async function routeByUserTier(
  userTier: string,
  message: string
): Promise<string> {
  const config = USER_TIER_CONFIG[userTier]

  const response = await anthropic.messages.create({
    model: config.model,
    max_tokens: config.maxTokens,
    messages: [{ role: 'user', content: message }]
  })

  return response.content[0].text
}

/* Unit Economics by Tier:
Free tier:
  - Haiku @ $0.25/MTok input, ~2K tokens/request = $0.0005/request
  - Target: 40K requests/month breakeven (via ads/upsell)

Pro tier ($20/month):
  - Sonnet @ $3/MTok input, ~2K tokens/request = $0.006/request
  - Breakeven: 3,333 requests/month
  - Average user: ~500 requests/month → $17 margin/user

Enterprise tier ($200/month):
  - Opus @ $15/MTok input, ~2K tokens/request = $0.030/request
  - Breakeven: 6,667 requests/month
  - Average user: ~2,000 requests/month → $140 margin/user
*/
```

### Pattern 2: Intelligent Caching

**Strategy**: Cache common responses to avoid redundant API calls.

```typescript
import { createHash } from 'crypto'

interface CachedResponse {
  response: string
  timestamp: number
  hits: number
}

const responseCache = new Map<string, CachedResponse>()

function getCacheKey(prompt: string): string {
  return createHash('sha256').update(prompt).digest('hex')
}

async function getCachedOrGenerate(
  prompt: string,
  cacheTTL: number = 3600000  // 1 hour
): Promise<{ response: string; cached: boolean }> {
  const cacheKey = getCacheKey(prompt)
  const cached = responseCache.get(cacheKey)

  // Check cache
  if (cached && Date.now() - cached.timestamp < cacheTTL) {
    cached.hits++
    console.log(`Cache hit (saved $${calculateSavings(prompt)})`)
    return { response: cached.response, cached: true }
  }

  // Cache miss - call API
  const response = await anthropic.messages.create({
    model: 'claude-sonnet-4.5',
    max_tokens: 1024,
    messages: [{ role: 'user', content: prompt }]
  })

  const responseText = response.content[0].text

  // Cache response
  responseCache.set(cacheKey, {
    response: responseText,
    timestamp: Date.now(),
    hits: 1
  })

  return { response: responseText, cached: false }
}

/* ROI Analysis:
FAQ bot with 100K requests/day:
  - 20% of requests are duplicates (20K/day)
  - Avg request: 2K tokens input + 500 tokens output
  - Cost per request: (2000/1M × $3) + (500/1M × $15) = $0.0135
  - Savings: 20K requests × $0.0135 = $270/day = $8,100/month

Redis cache cost: ~$50/month
Net savings: $8,050/month (99.4% savings on cached requests)
*/
```

### Pattern 3: Batching and Asynchronous Processing

**Strategy**: Batch non-urgent requests to optimize throughput.

```typescript
interface BatchRequest {
  id: string
  prompt: string
  priority: 'urgent' | 'normal' | 'low'
  callback: (response: string) => void
}

class BatchProcessor {
  private queue: BatchRequest[] = []
  private processing = false

  async add(request: BatchRequest) {
    this.queue.push(request)

    // Urgent requests process immediately
    if (request.priority === 'urgent') {
      return this.processNow(request)
    }

    // Batch normal/low priority requests
    if (!this.processing && this.queue.length >= 10) {
      this.processBatch()
    }
  }

  private async processBatch() {
    this.processing = true
    const batch = this.queue.splice(0, 10)

    // Process in parallel (respect rate limits)
    const results = await Promise.allSettled(
      batch.map(req => this.callAPI(req.prompt))
    )

    results.forEach((result, i) => {
      if (result.status === 'fulfilled') {
        batch[i].callback(result.value)
      }
    })

    this.processing = false

    // Process next batch if queue has items
    if (this.queue.length >= 10) {
      this.processBatch()
    }
  }

  private async callAPI(prompt: string): Promise<string> {
    const response = await anthropic.messages.create({
      model: 'claude-haiku-4.5',  // Use cheaper model for batched tasks
      max_tokens: 512,
      messages: [{ role: 'user', content: prompt }]
    })
    return response.content[0].text
  }
}

/* Cost Optimization:
Batch processing allows:
  - Using cheaper models (Haiku) for non-urgent tasks
  - Rate limit optimization (fewer API calls during peak)
  - Better utilization of concurrent request limits

Example: Email classification system
  - Urgent emails: Sonnet in real-time (~$0.006/email)
  - Normal emails: Haiku in 30s batches (~$0.0005/email)
  - Savings: 92% on 80% of traffic = 73% overall cost reduction
*/
```

## Cost Attribution and Monitoring

**Architect Perspective**: You can't optimize what you don't measure. Track costs per user, per feature, per endpoint.

### Pattern 1: Per-Request Cost Tracking

```typescript
interface RequestCost {
  userId: string
  endpoint: string
  model: string
  inputTokens: number
  outputTokens: number
  cost: number
  timestamp: Date
}

async function trackCost(
  userId: string,
  endpoint: string,
  usage: { input_tokens: number; output_tokens: number },
  model: string
) {
  const pricing = {
    'claude-haiku-4.5': { input: 0.25, output: 1.25 },
    'claude-sonnet-4.5': { input: 3, output: 15 },
    'claude-opus-4.5': { input: 15, output: 75 }
  }

  const price = pricing[model]
  const cost =
    (usage.input_tokens / 1_000_000) * price.input +
    (usage.output_tokens / 1_000_000) * price.output

  await prisma.aiCost.create({
    data: {
      userId,
      endpoint,
      model,
      inputTokens: usage.input_tokens,
      outputTokens: usage.output_tokens,
      cost,
      timestamp: new Date()
    }
  })

  return cost
}

// Usage in API route
export async function POST(request: Request) {
  const { message } = await request.json()
  const userId = request.headers.get('x-user-id')

  const response = await anthropic.messages.create({
    model: 'claude-sonnet-4.5',
    max_tokens: 1024,
    messages: [{ role: 'user', content: message }]
  })

  // Track cost
  await trackCost(
    userId!,
    '/api/chat',
    response.usage,
    'claude-sonnet-4.5'
  )

  return Response.json({ reply: response.content[0].text })
}
```

### Pattern 2: Cost Anomaly Detection

```typescript
// Detect users/features with abnormally high costs
async function detectCostAnomalies() {
  const anomalies = await prisma.$queryRaw`
    SELECT
      userId,
      endpoint,
      SUM(cost) as total_cost,
      COUNT(*) as request_count,
      AVG(cost) as avg_cost
    FROM ai_costs
    WHERE timestamp > NOW() - INTERVAL '24 hours'
    GROUP BY userId, endpoint
    HAVING SUM(cost) > 100  -- Alert if user costs > $100/day
    ORDER BY total_cost DESC
  `

  return anomalies
}

/* Use cases:
1. Infinite loop bugs (user making 10K requests/min)
2. Abuse detection (free tier user exceeding quota)
3. Feature optimization (which endpoints are most expensive?)

Example output:
[
  { userId: 'user123', endpoint: '/api/code-review', total_cost: 250, request_count: 5000 },
  { userId: 'user456', endpoint: '/api/chat', total_cost: 180, request_count: 12000 }
]

Actions:
- Rate limit user123's code-review requests
- Investigate why user456 is making 12K chat requests/day
*/
```

### Pattern 3: Budget Enforcement

```typescript
interface UserBudget {
  dailyLimit: number
  monthlyLimit: number
  currentDailySpend: number
  currentMonthlySpend: number
}

async function checkBudget(userId: string): Promise<boolean> {
  const budget = await redis.get<UserBudget>(`budget:${userId}`)

  if (!budget) {
    // Initialize budget for new user
    await redis.set(`budget:${userId}`, {
      dailyLimit: 1.0,    // $1/day for free tier
      monthlyLimit: 20.0, // $20/month
      currentDailySpend: 0,
      currentMonthlySpend: 0
    })
    return true
  }

  // Check if over budget
  if (budget.currentDailySpend >= budget.dailyLimit) {
    throw new Error('Daily budget exceeded. Upgrade to Pro for higher limits.')
  }

  if (budget.currentMonthlySpend >= budget.monthlyLimit) {
    throw new Error('Monthly budget exceeded.')
  }

  return true
}

async function incrementBudget(userId: string, cost: number) {
  const budget = await redis.get<UserBudget>(`budget:${userId}`)

  budget!.currentDailySpend += cost
  budget!.currentMonthlySpend += cost

  await redis.set(`budget:${userId}`, budget)
}

// Usage in API route
export async function POST(request: Request) {
  const userId = request.headers.get('x-user-id')!

  // Check budget before processing
  await checkBudget(userId)

  const response = await callAPI(...)

  const cost = await trackCost(userId, '/api/chat', response.usage, 'claude-sonnet-4.5')

  // Update budget
  await incrementBudget(userId, cost)

  return Response.json({ reply: response.content[0].text })
}
```

## The Cost Optimization Decision Tree

Use this framework to make ROI-driven architectural decisions:

```
┌─────────────────────────────────────┐
│ New AI Feature Request              │
└──────────────┬──────────────────────┘
               │
               v
      ┌────────────────────┐
      │ What's the volume? │
      └────────┬───────────┘
               │
       ┌───────┴───────┐
       │               │
       v               v
   <1K req/day    >10K req/day
       │               │
       │               v
       │      ┌──────────────────────┐
       │      │ Run cost analysis:   │
       │      │ - Tokens per request │
       │      │ - Model needed       │
       │      │ - Monthly projection │
       │      └──────────┬───────────┘
       │                 │
       │                 v
       │        ┌────────────────────┐
       │        │ Cost > $10K/month? │
       │        └─────┬──────────────┘
       │              │
       │      ┌───────┴───────┐
       │      │               │
       │     YES              NO
       │      │               │
       v      v               v
   ┌───────────────┐  ┌─────────────────────┐
   │ Start simple: │  │ Optimize strategy:  │
   │ - Use Sonnet  │  │ - Tier system       │
   │ - No caching  │  │ - Input compression │
   │ - Optimize    │  │ - Caching           │
   │   if needed   │  │ - Cheaper models    │
   └───────────────┘  └─────────────────────┘
```

### Decision Framework by Feature Type

| Feature Type | Volume | Strategy | Expected Cost | Model Choice |
|--------------|--------|----------|---------------|--------------|
| **FAQ Bot** | High (100K+/day) | Cache + Haiku | $100-500/mo | Haiku 4.5 |
| **Customer Support** | Medium (10K/day) | Summarize history + Sonnet | $500-2K/mo | Sonnet 4.5 |
| **Code Review** | Low (1K/day) | Quality-first + Opus | $500-1K/mo | Opus 4.5 |
| **Content Generation** | Medium (5K/day) | Tier by user + Sonnet/Haiku | $200-1K/mo | Mixed |
| **Data Extraction** | Very High (1M+/day) | Batch + Haiku | $250-500/mo | Haiku 4.5 |

## Practical Exercises

**Exercise 1: Cost Projection**
Calculate monthly costs for a chatbot with:
- 50,000 users
- Average 20 conversations/month per user
- 5 turns per conversation
- 2,000 input tokens per turn (including history)
- 500 output tokens per turn

Compare costs for Haiku, Sonnet, and Opus. What's the breakeven subscription price for each model?

**Exercise 2: Optimization Impact**
Given the above chatbot:
- Implement truncation (keep last 3 turns): What's the cost savings?
- Implement summarization (summarize turns 1-2, keep turns 3-5 verbatim): What's the cost savings including summarization cost?
- Which strategy has better ROI?

**Exercise 3: Tiered Quality System**
Design a 3-tier pricing model (Free, Pro, Enterprise) with:
- Different models per tier
- Budget limits per tier
- Subscription prices that provide 70% margin

## Key Takeaways

**The Unit Economics Mindset:**
- Every architectural decision has a **cost multiplier**
- Opus costs **60x more** than Haiku—justify the difference with revenue impact
- Input tokens grow unbounded—**truncate or summarize** to cap costs

**The Efficiency Frontier:**
- **Quality threshold** > **Minimum viable model**
- Haiku at 85% quality beats Sonnet at 92% if the 7% gain doesn't drive $18K/month in value
- Run **evals** to map task quality to models, then choose the cheapest model above threshold

**Cost Optimization Patterns:**
1. **Model Selection Matrix**: Route by task complexity, not by default
2. **Truncate vs. Summarize**: Truncate for short sessions, summarize for long ones
3. **Tiered Quality**: Free users get Haiku, paid users get Sonnet
4. **Caching**: 20% duplicate requests = $8K/month savings
5. **Batching**: Non-urgent tasks use cheaper models

**Cost Attribution:**
- **Track costs per user/endpoint/feature**—you can't optimize what you don't measure
- **Anomaly detection**: Alert when users exceed $100/day (infinite loops, abuse)
- **Budget enforcement**: Cap free tier at $1/day to prevent runaway costs

**The ROI Formula:**
```typescript
// For any architectural choice:
const qualityGain = newApproach.quality - currentApproach.quality
const costDelta = newApproach.cost - currentApproach.cost
const revenueImpact = qualityGain * conversionRate * avgOrderValue

// Only upgrade if:
revenueImpact > costDelta
```

**The Principle: Cheapest Model Above Threshold**

Don't default to the best model. Start with the **cheapest model that passes your quality bar**, then upgrade only when revenue impact justifies the cost delta.

1. **Define quality threshold** (e.g., 85% accuracy)
2. **Run evals** on Haiku/Sonnet/Opus for your task
3. **Select cheapest model** that meets threshold
4. **Monitor** costs and quality in production
5. **Optimize** based on real data, not assumptions
