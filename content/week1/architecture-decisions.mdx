# Architectural ROI: Unit Economics & Model Selection Matrix

Engineering for **cost-performance efficiency** at scaleâ€”because every token has a price, and every model choice has an ROI.

> **Architect Perspective**: AI architecture isn't about "which is best"â€”it's about **maximizing value per dollar** while meeting quality thresholds. The right model is the **cheapest one that passes your quality bar**.

## The Unit Economics Problem

**Reality Check**: AI costs scale linearly with usage
- Production chatbot: 10K users Ã— 100 msgs/day Ã— 500 tokens/msg = **500M tokens/day**
- At Opus pricing ($15/MTok input): **$7,500/day** = **$225K/month**
- At Sonnet pricing ($3/MTok input): **$1,500/day** = **$45K/month**
- At Haiku pricing ($0.25/MTok input): **$125/day** = **$3.75K/month**

**Architectural Mandate**: Your model selection directly determines whether your AI product is **profitable or a cost center**.

## The Efficiency Frontier: 2026 Model Pricing Reality

**The Physics of Cost**: Every model sits on a cost-performance curve. Your job is to find the **minimum viable quality** at the **lowest cost**.

### Claude 4.5 Series: The 2026 Price-Performance Landscape

| Model | Input $/MTok | Output $/MTok | Latency (p95) | Quality Tier | Best For |
|-------|-------------|--------------|---------------|--------------|----------|
| **Opus 4.5** | $15 | $75 | 4-8s | Tier 1 (Frontier) | Complex reasoning, research, code generation |
| **Sonnet 4.5** | $3 | $15 | 1-3s | Tier 1 (Production) | General chat, summarization, most tasks |
| **Haiku 4.5** | $0.25 | $1.25 | 0.3-0.8s | Tier 2 (Fast) | Classification, extraction, high-volume |

**The Cost Multiplier Effect**:
- Opus is **60x more expensive** than Haiku
- Sonnet is **12x more expensive** than Haiku
- At 500M tokens/day, the difference between Haiku and Opus is **$221K/month**

### The Model Selection Matrix: ROI-Driven Decisions

**Framework**: Start with the cheapest model, upgrade only when quality metrics fail.

```typescript
interface ModelTier {
  name: string
  costPerMTok: { input: number; output: number }
  latency: number
  qualityScore: number  // 0-100, measured on your eval set
}

const TIER_SYSTEM: ModelTier[] = [
  {
    name: 'claude-haiku-4.5',
    costPerMTok: { input: 0.25, output: 1.25 },
    latency: 500,      // ms p95
    qualityScore: 75   // Your evals
  },
  {
    name: 'claude-sonnet-4.5',
    costPerMTok: { input: 3, output: 15 },
    latency: 2000,
    qualityScore: 92
  },
  {
    name: 'claude-opus-4.5',
    costPerMTok: { input: 15, output: 75 },
    latency: 6000,
    qualityScore: 98
  }
]

// Decision Logic: Cost-First Selection
function selectModel(
  taskType: string,
  qualityThreshold: number = 85
): string {
  // Try tiers in cost order
  for (const tier of TIER_SYSTEM) {
    const taskQuality = getTaskQuality(taskType, tier.name)

    if (taskQuality &gt;= qualityThreshold) {
      console.log(`Selected ${tier.name} (quality: ${taskQuality}, cost: $${tier.costPerMTok.input}/MTok)`)
      return tier.name
    }
  }

  // Fallback to highest quality if nothing passes
  return TIER_SYSTEM[TIER_SYSTEM.length - 1].name
}

// Example: Task-based quality mapping
function getTaskQuality(task: string, model: string): number {
  const qualityMatrix: Record<string, Record<string, number>> = {
    'classification': {
      'claude-haiku-4.5': 95,   // âœ… Haiku excels at this
      'claude-sonnet-4.5': 97,
      'claude-opus-4.5': 98
    },
    'summarization': {
      'claude-haiku-4.5': 78,   // âš ï¸  Below threshold for critical use
      'claude-sonnet-4.5': 93,  // âœ… Sonnet hits 85%+ threshold
      'claude-opus-4.5': 97
    },
    'code-generation': {
      'claude-haiku-4.5': 65,   // âŒ Fails threshold
      'claude-sonnet-4.5': 88,  // âœ… Acceptable
      'claude-opus-4.5': 96     // âœ… Best, but is it worth 5x cost?
    }
  }

  return qualityMatrix[task]?.[model] ?? 0
}
```

**Result**:
- Classification: **Always use Haiku** (95% quality, $0.25/MTok)
- Summarization: **Use Sonnet** (93% quality, $3/MTok) - Haiku fails threshold
- Code Gen: **Use Sonnet** (88% quality, $3/MTok) - Opus's 8-point improvement doesn't justify 5x cost

### ROI Calculation: The Cost-Per-Conversation Economics

**Framework**: Calculate unit economics to justify model selection.

```typescript
interface ConversationCost {
  model: string
  avgInputTokens: number
  avgOutputTokens: number
  conversationsPerDay: number
  monthlyCost: number
  costPerConversation: number
}

function calculateCosts(
  model: string,
  inputPrice: number,
  outputPrice: number,
  avgInputTokens: number,
  avgOutputTokens: number,
  dailyConversations: number
): ConversationCost {
  // Cost per single conversation
  const inputCost = (avgInputTokens / 1_000_000) * inputPrice
  const outputCost = (avgOutputTokens / 1_000_000) * outputPrice
  const costPerConvo = inputCost + outputCost

  // Monthly cost at scale
  const monthlyCost = costPerConvo * dailyConversations * 30

  return {
    model,
    avgInputTokens,
    avgOutputTokens,
    conversationsPerDay: dailyConversations,
    monthlyCost,
    costPerConversation: costPerConvo
  }
}

// Example: Customer support chatbot
const DAILY_CONVERSATIONS = 50_000
const AVG_INPUT_TOKENS = 2_000   // System prompt + history + question
const AVG_OUTPUT_TOKENS = 500    // Response length

const scenarios = [
  calculateCosts('Opus 4.5', 15, 75, AVG_INPUT_TOKENS, AVG_OUTPUT_TOKENS, DAILY_CONVERSATIONS),
  calculateCosts('Sonnet 4.5', 3, 15, AVG_INPUT_TOKENS, AVG_OUTPUT_TOKENS, DAILY_CONVERSATIONS),
  calculateCosts('Haiku 4.5', 0.25, 1.25, AVG_INPUT_TOKENS, AVG_OUTPUT_TOKENS, DAILY_CONVERSATIONS)
]

/* Results:
Opus 4.5:   $0.0675/conversation Ã— 50K/day = $101,250/month
Sonnet 4.5: $0.0135/conversation Ã— 50K/day = $20,250/month
Haiku 4.5:  $0.00113/conversation Ã— 50K/day = $1,695/month

ROI Analysis:
- Opus costs 60x more than Haiku
- Sonnet costs 12x more than Haiku
- If Haiku quality is 85% and Sonnet is 92%:
  â†’ Is 7% quality improvement worth $18,555/month?
  â†’ Only if customer retention impact > $18,555/month
*/
```

**Decision Framework**:
```typescript
// The ROI Formula
const qualityGain = sonnetQuality - haikuQuality  // e.g., 92 - 85 = 7%
const costDelta = sonnetCost - haikuCost          // e.g., $20,250 - $1,695 = $18,555
const breakEvenLTV = costDelta / (conversionRate * qualityGain)

// Example: If 7% quality improvement increases conversions by 3%
const additionalRevenue = dailyConversions * 0.03 * avgOrderValue
// Use Sonnet only if additionalRevenue > $18,555/month
```

## Optimization Strategies: Input Token Cost Management

**The Input Token Problem**: In conversational AI, input tokens (context) grow unbounded, but **you pay for every token on every request**.

### Cost Growth Pattern

```typescript
// Conversation turn costs
interface TurnCost {
  turn: number
  inputTokens: number
  cost: number
}

// âŒ Naive approach: Send full history every time
function calculateNaiveCosts(): TurnCost[] {
  const SYSTEM_PROMPT = 1_000  // tokens
  const TURN_SIZE = 500        // tokens per turn (user + assistant)

  const costs: TurnCost[] = []
  let cumulativeTokens = SYSTEM_PROMPT

  for (let turn = 1; turn &lt;= 20; turn++) {
    cumulativeTokens += TURN_SIZE
    costs.push({
      turn,
      inputTokens: cumulativeTokens,
      cost: (cumulativeTokens / 1_000_000) * 3  // Sonnet pricing
    })
  }

  return costs
}

/* Result: Exponential cost growth
Turn 1:  1,500 tokens  = $0.0045
Turn 5:  3,500 tokens  = $0.0105
Turn 10: 6,000 tokens  = $0.0180
Turn 20: 11,000 tokens = $0.0330

20-turn conversation cost: 20 turns Ã— avg $0.0195 = $0.39
At 50K conversations/day: $585K/month (unsustainable!)
*/
```

### Strategy 1: Truncate (Sliding Window)

**Pattern**: Keep only the last N turns, discard old context.

```typescript
// âœ… Truncation: Fixed token budget
const MAX_HISTORY_TURNS = 10  // Last 10 turns only

function truncateHistory(
  messages: Message[],
  maxTurns: number = MAX_HISTORY_TURNS
): Message[] {
  // Always keep system prompt
  const systemMessage = messages.find(m => m.role === 'system')

  // Take last N user/assistant turns
  const conversationTurns = messages.filter(m => m.role !== 'system')
  const recentTurns = conversationTurns.slice(-maxTurns * 2)  // *2 for user+assistant pairs

  return systemMessage
    ? [systemMessage, ...recentTurns]
    : recentTurns
}

// Cost impact: Caps at ~6K tokens regardless of conversation length
// Turn 20 cost: $0.018 (instead of $0.033)
// Monthly savings: $585K â†’ $270K (54% reduction)
```

**Pros:**
- âœ… Simple to implement
- âœ… Predictable costs
- âœ… No additional API calls

**Cons:**
- âŒ Loses context from early conversation
- âŒ Poor for long-running sessions (e.g., multi-day support tickets)

### Strategy 2: Summarize (Context Compression)

**Pattern**: Summarize old turns into a condensed context block.

```typescript
// âœ… Summarization: Compress old context
async function summarizeAndCompress(
  messages: Message[],
  turnThreshold: number = 10
): Promise<Message[]> {
  if (messages.length &lt;= turnThreshold * 2) {
    return messages  // Not long enough to summarize
  }

  const systemMessage = messages.find(m => m.role === 'system')
  const conversationTurns = messages.filter(m => m.role !== 'system')

  // Split into old (to summarize) and recent (keep verbatim)
  const oldTurns = conversationTurns.slice(0, -turnThreshold * 2)
  const recentTurns = conversationTurns.slice(-turnThreshold * 2)

  // Summarize old turns using Haiku (cheap summarization)
  const summary = await anthropic.messages.create({
    model: 'claude-haiku-4.5',  // $0.25/MTok for summarization
    max_tokens: 500,              // Cap summary length
    messages: [
      {
        role: 'user',
        content: `Summarize this conversation history into key points (max 500 tokens):

${oldTurns.map(m => `${m.role}: ${m.content}`).join('\n\n')}`
      }
    ]
  })

  // Build compressed context
  return [
    systemMessage!,
    { role: 'system', content: `Previous context: ${summary.content[0].text}` },
    ...recentTurns
  ]
}

/* Cost Analysis:
Original 20-turn conversation: 11,000 input tokens
After summarization:
  - System prompt: 1,000 tokens
  - Summary of turns 1-10: 500 tokens (compressed from 5,000)
  - Recent turns 11-20: 5,000 tokens
  - Total: 6,500 tokens (vs. 11,000 original)

Savings: 41% input token reduction
Summarization cost: ~2,500 tokens @ $0.25/MTok = $0.000625 (negligible)
*/
```

**Pros:**
- âœ… Preserves context from entire conversation
- âœ… Suitable for long-running sessions
- âœ… Quality degradation minimal

**Cons:**
- âŒ Additional API call for summarization
- âŒ Adds latency (~500ms for summary)
- âŒ More complex implementation

### Decision Matrix: Truncate vs. Summarize

| Factor | Truncate | Summarize |
|--------|----------|-----------|
| **Cost Savings** | 54% | 41% + summary cost |
| **Context Retention** | Poor (loses history) | Good (compresses history) |
| **Complexity** | Low | Medium |
| **Latency** | None | +500ms per summarization |
| **Best For** | Short sessions (&lt;10 turns), FAQ bots | Long sessions, customer support, research |

**Production Pattern: Hybrid Approach**

```typescript
// âœ… Best of both worlds
async function optimizeContext(
  messages: Message[],
  sessionType: 'short' | 'long'
): Promise<Message[]> {
  const turnCount = messages.filter(m => m.role !== 'system').length / 2

  if (sessionType === 'short' || turnCount &lt;= 15) {
    // Short sessions: Truncate (simpler, faster)
    return truncateHistory(messages, 10)
  } else {
    // Long sessions: Summarize (preserve context)
    return await summarizeAndCompress(messages, 10)
  }
}
```

## Production Cost Optimization Patterns

### Pattern 1: Tiered Quality System

**Strategy**: Route tasks to different model tiers based on complexity and user tier.

```typescript
interface UserTier {
  tier: 'free' | 'pro' | 'enterprise'
  model: string
  maxTokens: number
  monthlyCost: number
}

const USER_TIER_CONFIG: Record<string, UserTier> = {
  free: {
    tier: 'free',
    model: 'claude-haiku-4.5',
    maxTokens: 500,
    monthlyCost: 0  // Target: break even with ads/upsell
  },
  pro: {
    tier: 'pro',
    model: 'claude-sonnet-4.5',
    maxTokens: 2000,
    monthlyCost: 20  // $20/month subscription
  },
  enterprise: {
    tier: 'enterprise',
    model: 'claude-opus-4.5',
    maxTokens: 4000,
    monthlyCost: 200  // $200/month subscription
  }
}

async function routeByUserTier(
  userTier: string,
  message: string
): Promise<string> {
  const config = USER_TIER_CONFIG[userTier]

  const response = await anthropic.messages.create({
    model: config.model,
    max_tokens: config.maxTokens,
    messages: [{ role: 'user', content: message }]
  })

  return response.content[0].text
}

/* Unit Economics by Tier:
Free tier:
  - Haiku @ $0.25/MTok input, ~2K tokens/request = $0.0005/request
  - Target: 40K requests/month breakeven (via ads/upsell)

Pro tier ($20/month):
  - Sonnet @ $3/MTok input, ~2K tokens/request = $0.006/request
  - Breakeven: 3,333 requests/month
  - Average user: ~500 requests/month â†’ $17 margin/user

Enterprise tier ($200/month):
  - Opus @ $15/MTok input, ~2K tokens/request = $0.030/request
  - Breakeven: 6,667 requests/month
  - Average user: ~2,000 requests/month â†’ $140 margin/user
*/
```

### Pattern 2: Intelligent Caching

**Strategy**: Cache common responses to avoid redundant API calls.

```typescript
import { createHash } from 'crypto'

interface CachedResponse {
  response: string
  timestamp: number
  hits: number
}

const responseCache = new Map<string, CachedResponse>()

function getCacheKey(prompt: string): string {
  return createHash('sha256').update(prompt).digest('hex')
}

async function getCachedOrGenerate(
  prompt: string,
  cacheTTL: number = 3600000  // 1 hour
): Promise<{ response: string; cached: boolean }> {
  const cacheKey = getCacheKey(prompt)
  const cached = responseCache.get(cacheKey)

  // Check cache
  if (cached && Date.now() - cached.timestamp < cacheTTL) {
    cached.hits++
    console.log(`Cache hit (saved $${calculateSavings(prompt)})`)
    return { response: cached.response, cached: true }
  }

  // Cache miss - call API
  const response = await anthropic.messages.create({
    model: 'claude-sonnet-4.5',
    max_tokens: 1024,
    messages: [{ role: 'user', content: prompt }]
  })

  const responseText = response.content[0].text

  // Cache response
  responseCache.set(cacheKey, {
    response: responseText,
    timestamp: Date.now(),
    hits: 1
  })

  return { response: responseText, cached: false }
}

/* ROI Analysis:
FAQ bot with 100K requests/day:
  - 20% of requests are duplicates (20K/day)
  - Avg request: 2K tokens input + 500 tokens output
  - Cost per request: (2000/1M Ã— $3) + (500/1M Ã— $15) = $0.0135
  - Savings: 20K requests Ã— $0.0135 = $270/day = $8,100/month

Redis cache cost: ~$50/month
Net savings: $8,050/month (99.4% savings on cached requests)
*/
```

### Pattern 3: Batching and Asynchronous Processing

**Strategy**: Batch non-urgent requests to optimize throughput.

```typescript
interface BatchRequest {
  id: string
  prompt: string
  priority: 'urgent' | 'normal' | 'low'
  callback: (response: string) => void
}

class BatchProcessor {
  private queue: BatchRequest[] = []
  private processing = false

  async add(request: BatchRequest) {
    this.queue.push(request)

    // Urgent requests process immediately
    if (request.priority === 'urgent') {
      return this.processNow(request)
    }

    // Batch normal/low priority requests
    if (!this.processing && this.queue.length &gt;= 10) {
      this.processBatch()
    }
  }

  private async processBatch() {
    this.processing = true
    const batch = this.queue.splice(0, 10)

    // Process in parallel (respect rate limits)
    const results = await Promise.allSettled(
      batch.map(req => this.callAPI(req.prompt))
    )

    results.forEach((result, i) => {
      if (result.status === 'fulfilled') {
        batch[i].callback(result.value)
      }
    })

    this.processing = false

    // Process next batch if queue has items
    if (this.queue.length &gt;= 10) {
      this.processBatch()
    }
  }

  private async callAPI(prompt: string): Promise<string> {
    const response = await anthropic.messages.create({
      model: 'claude-haiku-4.5',  // Use cheaper model for batched tasks
      max_tokens: 512,
      messages: [{ role: 'user', content: prompt }]
    })
    return response.content[0].text
  }
}

/* Cost Optimization:
Batch processing allows:
  - Using cheaper models (Haiku) for non-urgent tasks
  - Rate limit optimization (fewer API calls during peak)
  - Better utilization of concurrent request limits

Example: Email classification system
  - Urgent emails: Sonnet in real-time (~$0.006/email)
  - Normal emails: Haiku in 30s batches (~$0.0005/email)
  - Savings: 92% on 80% of traffic = 73% overall cost reduction
*/
```

## Cost Attribution and Monitoring

**Architect Perspective**: You can't optimize what you don't measure. Track costs per user, per feature, per endpoint.

### Pattern 1: Per-Request Cost Tracking

```typescript
interface RequestCost {
  userId: string
  endpoint: string
  model: string
  inputTokens: number
  outputTokens: number
  cost: number
  timestamp: Date
}

async function trackCost(
  userId: string,
  endpoint: string,
  usage: { input_tokens: number; output_tokens: number },
  model: string
) {
  const pricing = {
    'claude-haiku-4.5': { input: 0.25, output: 1.25 },
    'claude-sonnet-4.5': { input: 3, output: 15 },
    'claude-opus-4.5': { input: 15, output: 75 }
  }

  const price = pricing[model]
  const cost =
    (usage.input_tokens / 1_000_000) * price.input +
    (usage.output_tokens / 1_000_000) * price.output

  await prisma.aiCost.create({
    data: {
      userId,
      endpoint,
      model,
      inputTokens: usage.input_tokens,
      outputTokens: usage.output_tokens,
      cost,
      timestamp: new Date()
    }
  })

  return cost
}

// Usage in API route
export async function POST(request: Request) {
  const { message } = await request.json()
  const userId = request.headers.get('x-user-id')

  const response = await anthropic.messages.create({
    model: 'claude-sonnet-4.5',
    max_tokens: 1024,
    messages: [{ role: 'user', content: message }]
  })

  // Track cost
  await trackCost(
    userId!,
    '/api/chat',
    response.usage,
    'claude-sonnet-4.5'
  )

  return Response.json({ reply: response.content[0].text })
}
```

### Pattern 2: Cost Anomaly Detection

```typescript
// Detect users/features with abnormally high costs
async function detectCostAnomalies() {
  const anomalies = await prisma.$queryRaw`
    SELECT
      userId,
      endpoint,
      SUM(cost) as total_cost,
      COUNT(*) as request_count,
      AVG(cost) as avg_cost
    FROM ai_costs
    WHERE timestamp > NOW() - INTERVAL '24 hours'
    GROUP BY userId, endpoint
    HAVING SUM(cost) &gt; 100  -- Alert if user costs > $100/day
    ORDER BY total_cost DESC
  `

  return anomalies
}

/* Use cases:
1. Infinite loop bugs (user making 10K requests/min)
2. Abuse detection (free tier user exceeding quota)
3. Feature optimization (which endpoints are most expensive?)

Example output:
[
  { userId: 'user123', endpoint: '/api/code-review', total_cost: 250, request_count: 5000 },
  { userId: 'user456', endpoint: '/api/chat', total_cost: 180, request_count: 12000 }
]

Actions:
- Rate limit user123's code-review requests
- Investigate why user456 is making 12K chat requests/day
*/
```

### Pattern 3: Budget Enforcement

```typescript
interface UserBudget {
  dailyLimit: number
  monthlyLimit: number
  currentDailySpend: number
  currentMonthlySpend: number
}

async function checkBudget(userId: string): Promise<boolean> {
  const budget = await redis.get<UserBudget>(`budget:${userId}`)

  if (!budget) {
    // Initialize budget for new user
    await redis.set(`budget:${userId}`, {
      dailyLimit: 1.0,    // $1/day for free tier
      monthlyLimit: 20.0, // $20/month
      currentDailySpend: 0,
      currentMonthlySpend: 0
    })
    return true
  }

  // Check if over budget
  if (budget.currentDailySpend &gt;= budget.dailyLimit) {
    throw new Error('Daily budget exceeded. Upgrade to Pro for higher limits.')
  }

  if (budget.currentMonthlySpend &gt;= budget.monthlyLimit) {
    throw new Error('Monthly budget exceeded.')
  }

  return true
}

async function incrementBudget(userId: string, cost: number) {
  const budget = await redis.get<UserBudget>(`budget:${userId}`)

  budget!.currentDailySpend += cost
  budget!.currentMonthlySpend += cost

  await redis.set(`budget:${userId}`, budget)
}

// Usage in API route
export async function POST(request: Request) {
  const userId = request.headers.get('x-user-id')!

  // Check budget before processing
  await checkBudget(userId)

  const response = await callAPI(...)

  const cost = await trackCost(userId, '/api/chat', response.usage, 'claude-sonnet-4.5')

  // Update budget
  await incrementBudget(userId, cost)

  return Response.json({ reply: response.content[0].text })
}
```

## The Cost Optimization Decision Tree

Use this framework to make ROI-driven architectural decisions:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ New AI Feature Request              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               v
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ What's the volume? â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚
       v               v
   &lt;1K req/day    &gt;10K req/day
       â”‚               â”‚
       â”‚               v
       â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚      â”‚ Run cost analysis:   â”‚
       â”‚      â”‚ - Tokens per request â”‚
       â”‚      â”‚ - Model needed       â”‚
       â”‚      â”‚ - Monthly projection â”‚
       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚
       â”‚                 v
       â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚        â”‚ Cost > $10K/month? â”‚
       â”‚        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚
       â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
       â”‚      â”‚               â”‚
       â”‚     YES              NO
       â”‚      â”‚               â”‚
       v      v               v
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Start simple: â”‚  â”‚ Optimize strategy:  â”‚
   â”‚ - Use Sonnet  â”‚  â”‚ - Tier system       â”‚
   â”‚ - No caching  â”‚  â”‚ - Input compression â”‚
   â”‚ - Optimize    â”‚  â”‚ - Caching           â”‚
   â”‚   if needed   â”‚  â”‚ - Cheaper models    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Decision Framework by Feature Type

| Feature Type | Volume | Strategy | Expected Cost | Model Choice |
|--------------|--------|----------|---------------|--------------|
| **FAQ Bot** | High (100K+/day) | Cache + Haiku | $100-500/mo | Haiku 4.5 |
| **Customer Support** | Medium (10K/day) | Summarize history + Sonnet | $500-2K/mo | Sonnet 4.5 |
| **Code Review** | Low (1K/day) | Quality-first + Opus | $500-1K/mo | Opus 4.5 |
| **Content Generation** | Medium (5K/day) | Tier by user + Sonnet/Haiku | $200-1K/mo | Mixed |
| **Data Extraction** | Very High (1M+/day) | Batch + Haiku | $250-500/mo | Haiku 4.5 |

---

## Real-World Industry Application

### The Multi-Tier Triage System: Digital Health Platform

**The Challenge**: A global telehealth platform receives **50,000 patient queries per day**. Some are simple ("How do I reset my password?"), others are complex medical symptom questions requiring careful analysis. Using Opus 4.5 for all queries costs **$225K/month**â€”making the product unprofitable.

**Business Context:**
- **Volume**: 50,000 queries/day (1.5M/month)
- **Quality Requirement**: 100% accuracy on medical safety queries (no hallucinations on drug interactions, symptoms)
- **Cost Target**: &lt;$30K/month to maintain 70% gross margin
- **Latency SLA**: &lt;3 seconds p95 (user abandonment threshold)

**The Architectural Decision**: Implement an intelligent **multi-tier triage system** that routes queries to the cheapest model capable of handling them safely.

#### Solution Architecture

```typescript
interface TriageResult {
  classification: 'simple' | 'complex' | 'critical'
  confidence: number          // 0-1, confidence in classification
  routedTo: 'haiku' | 'opus' | 'human'
  response?: string
  cost: number                // Cost in dollars for this query
  latency: number             // Response time in ms
}

interface QueryMetrics {
  totalCost: number
  avgLatency: number
  routingBreakdown: {
    haiku: number            // % routed to Haiku
    opus: number             // % routed to Opus
    human: number            // % routed to human review
  }
}

async function triageQuery(userQuery: string): Promise<TriageResult> {
  const startTime = Date.now()

  // TIER 1: Fast classifier (Haiku 4.5) - determines complexity
  const classification = await classifyQueryComplexity(userQuery)

  if (classification.type === 'simple' && classification.confidence &gt; 0.9) {
    // Handle with Haiku 4.5: password resets, appointment booking, basic FAQs
    const response = await callHaiku(userQuery)

    return {
      classification: 'simple',
      confidence: classification.confidence,
      routedTo: 'haiku',
      response,
      cost: calculateCost('haiku', userQuery, response),
      latency: Date.now() - startTime
    }
  }

  if (classification.type === 'critical' || classification.confidence < 0.7) {
    // Safety-critical or uncertain: escalate to human
    await notifyHumanReviewer(userQuery, classification)

    return {
      classification: 'critical',
      confidence: classification.confidence,
      routedTo: 'human',
      cost: 0,  // Human review is separate cost center
      latency: Date.now() - startTime
    }
  }

  // TIER 2: Complex medical query - route to Opus 4.5
  const response = await callOpus(userQuery, {
    systemPrompt: MEDICAL_SAFETY_PROMPT,
    temperature: 0.0,  // Deterministic for medical advice
    maxTokens: 2048
  })

  // Validate medical response for safety
  const safetyCheck = await validateMedicalResponse(response)

  if (!safetyCheck.passed) {
    // Failed safety check - escalate to human
    await notifyHumanReviewer(userQuery, { issue: safetyCheck.reason })

    return {
      classification: 'complex',
      confidence: classification.confidence,
      routedTo: 'human',
      cost: calculateCost('opus', userQuery, response),
      latency: Date.now() - startTime
    }
  }

  return {
    classification: 'complex',
    confidence: classification.confidence,
    routedTo: 'opus',
    response,
    cost: calculateCost('opus', userQuery, response),
    latency: Date.now() - startTime
  }
}

// Classifier: Fast Haiku call to determine query complexity
async function classifyQueryComplexity(query: string): Promise<{
  type: 'simple' | 'complex' | 'critical'
  confidence: number
  reasoning: string
}> {
  const prompt = `You are a medical query classifier. Analyze this patient query and classify it:

SIMPLE: Password resets, appointment scheduling, contact info requests
COMPLEX: Medical symptoms, drug interactions, treatment questions
CRITICAL: Emergency symptoms (chest pain, difficulty breathing), suicidal ideation

Query: "${query}"

Return JSON with: type (simple/complex/critical), confidence (0-1), reasoning.`

  const response = await anthropic.messages.create({
    model: 'claude-haiku-4.5',
    max_tokens: 256,
    temperature: 0.0,
    messages: [{ role: 'user', content: prompt }]
  })

  return JSON.parse(response.content[0].text)
}

// Cost calculation helper
function calculateCost(
  model: 'haiku' | 'opus',
  input: string,
  output: string
): number {
  const inputTokens = estimateTokens(input)
  const outputTokens = estimateTokens(output)

  const pricing = {
    haiku: { input: 0.25, output: 1.25 },
    opus: { input: 15, output: 75 }
  }

  const cost =
    (inputTokens / 1_000_000) * pricing[model].input +
    (outputTokens / 1_000_000) * pricing[model].output

  return cost
}
```

#### Production Implementation: Metrics Tracking

```typescript
class TriageMonitor {
  private metrics: QueryMetrics = {
    totalCost: 0,
    avgLatency: 0,
    routingBreakdown: { haiku: 0, opus: 0, human: 0 }
  }

  async processQueryWithTracking(query: string): Promise<TriageResult> {
    const result = await triageQuery(query)

    // Update cost metrics
    this.metrics.totalCost += result.cost

    // Update routing breakdown
    this.metrics.routingBreakdown[result.routedTo]++

    // Update latency (rolling average)
    const totalQueries = Object.values(this.metrics.routingBreakdown)
      .reduce((a, b) => a + b, 0)
    this.metrics.avgLatency =
      (this.metrics.avgLatency * (totalQueries - 1) + result.latency) / totalQueries

    // Alert on anomalies
    if (result.cost &gt; 0.50) {
      console.warn(`âš ï¸  High-cost query: $${result.cost.toFixed(4)} - "${query.substring(0, 50)}..."`)
    }

    if (result.latency &gt; 5000) {
      console.warn(`âš ï¸  Slow query: ${result.latency}ms - "${query.substring(0, 50)}..."`)
    }

    return result
  }

  getDailyReport(): string {
    const { haiku, opus, human } = this.metrics.routingBreakdown
    const total = haiku + opus + human

    return `
ğŸ“Š Daily Triage Report
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total Queries: ${total.toLocaleString()}
Total Cost: $${this.metrics.totalCost.toFixed(2)}
Avg Latency: ${this.metrics.avgLatency.toFixed(0)}ms

Routing Breakdown:
  ğŸŸ¢ Haiku:  ${((haiku/total) * 100).toFixed(1)}% (${haiku.toLocaleString()} queries)
  ğŸŸ¡ Opus:   ${((opus/total) * 100).toFixed(1)}% (${opus.toLocaleString()} queries)
  ğŸ”´ Human:  ${((human/total) * 100).toFixed(1)}% (${human.toLocaleString()} queries)

Cost per Query: $${(this.metrics.totalCost / total).toFixed(4)}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    `
  }
}
```

#### Outcome Metrics

**Before Triage System** (all queries â†’ Opus 4.5):
- **Cost**: $225,000/month (1.5M queries Ã— 3K avg tokens Ã— $15/MTok)
- **Latency**: 4.2s p95
- **Quality**: 98% accuracy

**After Triage System** (intelligent routing):
- **Cost**: $28,500/month (80% reduction)
  - 80% simple queries â†’ Haiku ($0.01/query)
  - 15% complex queries â†’ Opus ($0.15/query)
  - 5% critical queries â†’ Human review ($0/direct API cost)
- **Latency**: 1.8s p95 (57% improvement)
  - Haiku queries: 0.6s avg
  - Opus queries: 4.5s avg
  - Weighted average: 1.8s
- **Quality**: 100% on safety-critical queries (maintained)

**Cost Breakdown**:
```typescript
// 50,000 queries/day Ã— 30 days = 1,500,000 queries/month

// Simple queries (80% = 1,200,000)
const simpleCost = 1_200_000 * 0.01 = $12,000

// Complex queries (15% = 225,000)
const complexCost = 225_000 * 0.15 = $33,750

// Critical queries (5% = 75,000) - human review
const criticalCost = 0  // Separate budget

// Total API Cost
const totalCost = $12,000 + $33,750 = $45,750/month
```

**Actual Results** (after optimization):
- Implemented caching for FAQs (30% of simple queries): **$3,600/month savings**
- Fine-tuned Haiku confidence threshold (0.9 â†’ 0.85): **10% more queries to Haiku**
- **Final Cost**: **$28,500/month** (87% reduction from original)

**Business Impact**:
- **Gross Margin**: Increased from 30% â†’ 78%
- **SLA Compliance**: 99.2% of queries under 3s (vs 94% before)
- **Safety**: Zero medical accuracy incidents (100% HITL on critical)
- **ROI**: 3-month implementation, $196K/month savings = **22-day payback period**

#### Key Architectural Decisions

**Why Haiku 4.5 as Classifier**:
- **Speed**: 0.3-0.8s latency (vs 4-8s for Opus)
- **Cost**: $0.25/MTok (60x cheaper than Opus)
- **Accuracy**: 95% classification accuracy on test set (sufficient for routing)

**Why Confidence Threshold of 0.9**:
- **Safety**: Err on side of escalation (better to use Opus unnecessarily than miss critical symptoms)
- **Measured Impact**: Lowering to 0.85 increased Haiku routing by 10% but added 2% false negatives (unacceptable for medical)

**Why Human Escalation for < 0.7 Confidence**:
- **Edge Cases**: Ambiguous queries (e.g., "I feel weird") need human judgment
- **Compliance**: HIPAA requires human review for uncertain medical advice
- **Cost**: Human review is expensive but necessary for 5% of queries

**The ROI Formula in Practice**:
```typescript
// Original approach
const opusCost = 1_500_000 * 0.15 = $225_000/month
const opusLatency = 4.2

// Triage approach
const triageCost = $28_500/month
const triageLatency = 1.8

// Savings
const monthlySavings = $225_000 - $28_500 = $196_500
const latencyImprovement = ((4.2 - 1.8) / 4.2) * 100 = 57%

// Implementation cost
const engineeringCost = 40 hours Ã— $200/hr = $8,000
const paybackPeriod = $8,000 / $196_500 * 30 = 1.2 days
```

**The Architect's Principle**: Don't route everything to the best model. Build a **quality-aware routing system** that uses the cheapest model capable of meeting your quality threshold for each query type.

---

## Practical Exercises

**Exercise 1: Cost Projection**
Calculate monthly costs for a chatbot with:
- 50,000 users
- Average 20 conversations/month per user
- 5 turns per conversation
- 2,000 input tokens per turn (including history)
- 500 output tokens per turn

Compare costs for Haiku, Sonnet, and Opus. What's the breakeven subscription price for each model?

**Exercise 2: Optimization Impact**
Given the above chatbot:
- Implement truncation (keep last 3 turns): What's the cost savings?
- Implement summarization (summarize turns 1-2, keep turns 3-5 verbatim): What's the cost savings including summarization cost?
- Which strategy has better ROI?

**Exercise 3: Tiered Quality System**
Design a 3-tier pricing model (Free, Pro, Enterprise) with:
- Different models per tier
- Budget limits per tier
- Subscription prices that provide 70% margin

## Key Takeaways

**The Unit Economics Mindset:**
- Every architectural decision has a **cost multiplier**
- Opus costs **60x more** than Haikuâ€”justify the difference with revenue impact
- Input tokens grow unboundedâ€”**truncate or summarize** to cap costs

**The Efficiency Frontier:**
- **Quality threshold** > **Minimum viable model**
- Haiku at 85% quality beats Sonnet at 92% if the 7% gain doesn't drive $18K/month in value
- Run **evals** to map task quality to models, then choose the cheapest model above threshold

**Cost Optimization Patterns:**
1. **Model Selection Matrix**: Route by task complexity, not by default
2. **Truncate vs. Summarize**: Truncate for short sessions, summarize for long ones
3. **Tiered Quality**: Free users get Haiku, paid users get Sonnet
4. **Caching**: 20% duplicate requests = $8K/month savings
5. **Batching**: Non-urgent tasks use cheaper models

**Cost Attribution:**
- **Track costs per user/endpoint/feature**â€”you can't optimize what you don't measure
- **Anomaly detection**: Alert when users exceed $100/day (infinite loops, abuse)
- **Budget enforcement**: Cap free tier at $1/day to prevent runaway costs

**The ROI Formula:**
```typescript
// For any architectural choice:
const qualityGain = newApproach.quality - currentApproach.quality
const costDelta = newApproach.cost - currentApproach.cost
const revenueImpact = qualityGain * conversionRate * avgOrderValue

// Only upgrade if:
revenueImpact > costDelta
```

**The Principle: Cheapest Model Above Threshold**

Don't default to the best model. Start with the **cheapest model that passes your quality bar**, then upgrade only when revenue impact justifies the cost delta.

1. **Define quality threshold** (e.g., 85% accuracy)
2. **Run evals** on Haiku/Sonnet/Opus for your task
3. **Select cheapest model** that meets threshold
4. **Monitor** costs and quality in production
5. **Optimize** based on real data, not assumptions
