{
  "id": "data-analyzer",
  "name": "Data Analysis Assistant",
  "tagline": "Analyze CSV/JSON data and generate insights with AI",
  "overview": "Build an AI tool that analyzes structured data (CSV, JSON), generates insights, creates visualizations, and answers natural language questions about data. The core value: non-technical users can analyze data without SQL or Python, getting insights in seconds instead of hours.",
  "difficulty": "hard",
  "estimatedHours": 40,
  "problemSpace": {
    "commonProblems": [
      "Business users can't analyze data without engineering/analytics help",
      "Creating reports from raw data takes hours of manual work",
      "Non-technical teams blocked on simple data questions",
      "Excel/Google Sheets insufficient for complex analysis",
      "Data insights buried in spreadsheets, hard to communicate"
    ],
    "validationQuestions": [
      "How often do you work with CSV/data files?",
      "How long does it take to answer a data question?",
      "Do you know SQL/Python for data analysis?",
      "Would you pay for instant data insights from uploaded files?"
    ]
  },
  "suggestedTechniques": [
    {
      "technique": "Tool Use (Agent)",
      "use": "Let AI query/analyze data using tools",
      "complexity": "High",
      "example": "Tools: filter_data, aggregate, calculate_stats, create_chart"
    },
    {
      "technique": "Structured Output",
      "use": "Generate JSON with analysis results",
      "complexity": "Medium",
      "example": "Return { insights: [], statistics: {}, recommendations: [] }"
    },
    {
      "technique": "Few-Shot Examples",
      "use": "Show AI how to analyze similar datasets",
      "complexity": "Medium",
      "example": "Include 2-3 example analyses in prompt"
    },
    {
      "technique": "Data Summarization",
      "use": "Summarize large datasets before analysis",
      "complexity": "Medium",
      "example": "Generate schema, sample rows, statistics → send to LLM"
    }
  ],
  "coreFeatures": [
    {
      "feature": "File Upload & Parsing",
      "description": "Upload CSV/JSON, parse and validate",
      "priority": "must-have",
      "implementation": "File upload → parse with papaparse/csv-parser → store in memory/DB"
    },
    {
      "feature": "Data Preview",
      "description": "Show first 10 rows, column types, basic stats",
      "priority": "must-have",
      "implementation": "Calculate: row count, columns, data types, null counts"
    },
    {
      "feature": "Natural Language Query",
      "description": "Ask questions: 'What's the average sales by region?'",
      "priority": "must-have",
      "implementation": "User query → LLM generates analysis plan → execute → return answer"
    },
    {
      "feature": "Auto Insights",
      "description": "Generate insights automatically: trends, anomalies, correlations",
      "priority": "must-have",
      "implementation": "Send data summary to LLM → prompt for insights"
    },
    {
      "feature": "Visualizations",
      "description": "Create charts: bar, line, pie, scatter",
      "priority": "important",
      "implementation": "Use Recharts or Chart.js, LLM suggests chart type + data"
    },
    {
      "feature": "Export Results",
      "description": "Download analysis as PDF/report",
      "priority": "nice-to-have",
      "implementation": "Generate HTML → convert to PDF or download as Markdown"
    }
  ],
  "userStories": [
    "As a sales manager, I want to upload sales data and get regional insights so I can identify top performers",
    "As a product manager, I want to analyze user feedback CSV and find common themes without reading 1000 rows",
    "As a small business owner, I want to upload expenses and get cost-saving recommendations",
    "As a marketer, I want to analyze campaign data and visualize ROI by channel"
  ],
  "mvpScope": {
    "mustHave": [
      "CSV file upload (max 10MB)",
      "Data preview (first 10 rows + stats)",
      "Ask questions about data (natural language)",
      "Auto-generate 3-5 insights",
      "Display results in readable format"
    ],
    "v2Features": [
      "JSON support",
      "Database connections (PostgreSQL, MySQL)",
      "Chart/visualization generation",
      "Multi-file analysis",
      "Export to PDF",
      "Scheduled analysis",
      "API access"
    ]
  },
  "architectureGuidance": {
    "frontend": [
      "Next.js App Router",
      "File upload component (react-dropzone)",
      "Data table component (TanStack Table)",
      "Chart library (Recharts)",
      "Natural language input field"
    ],
    "backend": [
      "API route: /api/upload (handle file upload)",
      "API route: /api/analyze (process queries)",
      "CSV parser (papaparse)",
      "Data analysis service (calculate stats, filter, aggregate)",
      "LLM client (Claude with tool use)",
      "Storage: Store file in memory (small files) or S3 (large files)"
    ],
    "database": [
      "Optional: Store analysis history",
      "Schema: id, user_id, file_name, file_url, analysis_results, timestamp"
    ],
    "aiTools": [
      {
        "name": "filter_data",
        "description": "Filter rows based on condition",
        "parameters": "column, operator, value"
      },
      {
        "name": "aggregate",
        "description": "Group by column and calculate aggregates",
        "parameters": "groupBy, aggregateColumn, operation (sum/avg/count)"
      },
      {
        "name": "calculate_statistics",
        "description": "Calculate mean, median, mode, std dev",
        "parameters": "column"
      },
      {
        "name": "find_correlations",
        "description": "Find correlations between numeric columns",
        "parameters": "columns[]"
      }
    ]
  },
  "promptExamples": {
    "autoInsights": {
      "system": "You are a data analyst. Analyze datasets and provide actionable insights.",
      "user": "Dataset: {{fileName}}\nColumns: {{columns}}\nRow count: {{rowCount}}\n\nSample data:\n{{sampleRows}}\n\nStatistics:\n{{statistics}}\n\nGenerate 5 key insights:\n1. What trends do you see?\n2. Any anomalies or outliers?\n3. What correlations exist?\n4. What's surprising or noteworthy?\n5. What actions should be taken?",
      "variables": {
        "fileName": "sales_data.csv",
        "columns": "['date', 'region', 'product', 'revenue']",
        "rowCount": "1000",
        "sampleRows": "First 10 rows as JSON",
        "statistics": "Mean, median, etc. per column"
      }
    },
    "naturalLanguageQuery": {
      "system": "You are a data analyst with access to analysis tools. Answer questions about the dataset using tools.",
      "user": "Dataset: {{fileName}}\nColumns: {{columns}}\n\nUser question: {{userQuestion}}\n\nAvailable tools:\n- filter_data(column, operator, value)\n- aggregate(groupBy, aggregateColumn, operation)\n- calculate_statistics(column)\n\nUse tools to answer the question, then explain the answer.",
      "variables": {
        "userQuestion": "What's the average revenue by region?"
      }
    }
  },
  "integrationExamples": {
    "csvParsing": "import Papa from 'papaparse'\n\nfunction parseCSV(file: File): Promise<any[]> {\n  return new Promise((resolve, reject) => {\n    Papa.parse(file, {\n      header: true,\n      complete: (results) => resolve(results.data),\n      error: (error) => reject(error)\n    })\n  })\n}",
    "dataStatistics": "function calculateStats(data: any[], column: string) {\n  const values = data.map(row => row[column]).filter(v => v != null)\n  const numbers = values.filter(v => !isNaN(Number(v))).map(Number)\n\n  if (numbers.length === 0) return { type: 'string', unique: new Set(values).size }\n\n  return {\n    type: 'number',\n    mean: numbers.reduce((a, b) => a + b) / numbers.length,\n    median: numbers.sort()[Math.floor(numbers.length / 2)],\n    min: Math.min(...numbers),\n    max: Math.max(...numbers),\n    count: numbers.length\n  }\n}",
    "agentToolExecution": "const tools = [\n  {\n    name: 'aggregate',\n    description: 'Group data and calculate aggregates',\n    input_schema: {\n      type: 'object',\n      properties: {\n        groupBy: { type: 'string' },\n        aggregateColumn: { type: 'string' },\n        operation: { type: 'string', enum: ['sum', 'avg', 'count'] }\n      },\n      required: ['groupBy', 'aggregateColumn', 'operation']\n    }\n  }\n]\n\nconst response = await anthropic.messages.create({\n  model: 'claude-3-5-sonnet',\n  tools,\n  messages: [{ role: 'user', content: userQuery }]\n})\n\n// Execute tool if requested\nif (response.stop_reason === 'tool_use') {\n  const toolUse = response.content.find(c => c.type === 'tool_use')\n  const result = await executeTool(toolUse.name, toolUse.input)\n  // Continue conversation with result...\n}"
  },
  "successMetrics": [
    {
      "metric": "Time to Insight",
      "description": "Minutes from upload to actionable insight",
      "target": "<2 minutes for simple queries",
      "measurement": "Track timestamp from upload to first insight"
    },
    {
      "metric": "Insight Quality",
      "description": "User rating of insight usefulness (1-5)",
      "target": "4.0+ average",
      "measurement": "Thumbs up/down on each insight"
    },
    {
      "metric": "Query Success Rate",
      "description": "% of natural language queries that return useful answers",
      "target": "80%+",
      "measurement": "Track queries marked 'helpful' vs total"
    },
    {
      "metric": "Cost per Analysis",
      "description": "LLM cost per file analysis",
      "target": "<$0.10 per analysis",
      "measurement": "Track tokens + tool calls"
    }
  ],
  "costEstimate": {
    "development": {
      "hours": 40,
      "description": "30 hours core features + 10 hours polish/deploy (agent implementation is complex)"
    },
    "api": {
      "perAnalysis": "$0.05-0.20",
      "monthly": "$25-100 for 500 analyses",
      "optimization": "Summarize data before sending to LLM, cache insights for identical files"
    },
    "hosting": {
      "platform": "Vercel Pro ($20/mo) - need higher limits",
      "storage": "S3 or Vercel Blob for file storage ($5-10/mo)",
      "database": "Vercel Postgres or Supabase",
      "total": "$30-50/month initially"
    }
  },
  "differentiationIdeas": [
    "Focus on specific industry (e.g., only sales data analysis)",
    "Add predictive analytics (forecast next month)",
    "Connect to live data sources (Google Sheets, Stripe, Shopify)",
    "Collaborative analysis (share insights with team)",
    "Automated reporting (schedule daily/weekly insights)"
  ],
  "technicalChallenges": [
    {
      "challenge": "Handling large CSV files (>100MB)",
      "solution": "Stream processing, sample data for analysis, or upload to database first"
    },
    {
      "challenge": "Agent tool use reliability",
      "solution": "Extensive testing, clear tool descriptions, validate tool inputs"
    },
    {
      "challenge": "Complex queries requiring multiple tool calls",
      "solution": "Implement agent loop (up to 10 iterations), track tool call chain"
    },
    {
      "challenge": "Visualizing insights effectively",
      "solution": "LLM suggests chart type + data, use Recharts to render"
    }
  ],
  "inspirationProjects": [
    "Julius AI (data analysis chat)",
    "DataChat (natural language analytics)",
    "Patterns (data analysis + viz)",
    "Akkio (no-code ML on data)"
  ]
}
