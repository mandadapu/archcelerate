{
  "id": "lab-3-success-metrics",
  "title": "Define Success Metrics",
  "description": "Create SMART metrics to track your AI product's success",
  "difficulty": "advanced",
  "estimatedMinutes": 40,
  "language": "javascript",
  "starterCode": "/**\n * Define success metrics for your AI product\n * Return metrics with tracking implementation\n */\nfunction defineSuccessMetrics() {\n  return {\n    northStarMetric: {\n      name: '',\n      description: '',\n      target: 0,\n      timeframe: ''\n    },\n    primaryMetrics: [\n      {\n        name: '',\n        specific: '',\n        measurable: '',\n        achievable: true,\n        relevant: '',\n        timeBound: '',\n        target: 0,\n        current: 0,\n        trackingMethod: ''\n      }\n    ],\n    aiMetrics: [\n      {\n        metric: '',\n        target: 0,\n        trackingMethod: ''\n      }\n    ],\n    trackingImplementation: {\n      events: [],\n      database: '',\n      alertThresholds: []\n    }\n  }\n}\n",
  "instructions": "Define comprehensive success metrics for your AI product:\n\n1. North Star Metric:\n   - One metric that represents core value\n   - Example: 'Hours saved per user per week'\n\n2. Primary Metrics (3-5 SMART metrics):\n   - Specific: Exactly what you're measuring\n   - Measurable: How to quantify\n   - Achievable: Realistic given constraints\n   - Relevant: Ties to user value\n   - Time-bound: When you'll measure\n\n3. AI-Specific Metrics:\n   - Quality score (user ratings)\n   - Cost per request\n   - Latency (p95)\n   - Adoption rate (% using AI feature)\n\n4. Tracking Implementation:\n   - What events to track\n   - Where to store data (database table)\n   - Alert thresholds (e.g., cost >$100/day)",
  "testCases": [
    {
      "input": "defineSuccessMetrics().northStarMetric.name.length > 0",
      "expectedOutput": "true",
      "description": "Has North Star metric defined"
    },
    {
      "input": "defineSuccessMetrics().primaryMetrics.length >= 3 && defineSuccessMetrics().primaryMetrics.length <= 5",
      "expectedOutput": "true",
      "description": "Has 3-5 primary metrics"
    },
    {
      "input": "defineSuccessMetrics().primaryMetrics.every(m => m.specific && m.measurable && m.relevant && m.timeBound)",
      "expectedOutput": "true",
      "description": "All metrics are SMART"
    },
    {
      "input": "defineSuccessMetrics().aiMetrics.length >= 3",
      "expectedOutput": "true",
      "description": "Has at least 3 AI-specific metrics"
    },
    {
      "input": "defineSuccessMetrics().trackingImplementation.events.length > 0",
      "expectedOutput": "true",
      "description": "Has tracking events defined"
    },
    {
      "input": "defineSuccessMetrics().trackingImplementation.alertThresholds.length > 0",
      "expectedOutput": "true",
      "description": "Has alert thresholds configured"
    }
  ],
  "hints": [
    "North Star should represent core user value (time saved, quality improved, etc.)",
    "Each metric should have clear target and timeframe",
    "Track both user metrics (adoption, satisfaction) and AI metrics (cost, latency)",
    "Include tracking method (e.g., 'Track via database event log')",
    "Set alert thresholds for critical metrics (cost spike, error rate, etc.)"
  ]
}
