{
  "id": "lab-4-rag-pipeline",
  "title": "RAG Pipeline Exercise",
  "description": "Build a complete retrieval-augmented generation pipeline",
  "difficulty": "advanced",
  "estimatedMinutes": 60,
  "language": "javascript",
  "starterCode": "/**\n * Complete RAG pipeline\n * @param {string} query - User question\n * @param {string[]} documents - Array of documents\n * @returns {Object} - {answer: string, sources: string[]}\n */\nasync function ragPipeline(query, documents) {\n  // Step 1: Chunk documents\n  const chunks = []\n  // Your code here\n  \n  // Step 2: Generate embeddings\n  const embeddings = []\n  // Your code here\n  \n  // Step 3: Search for relevant chunks\n  const relevant = []\n  // Your code here\n  \n  // Step 4: Generate answer (mock for this exercise)\n  const answer = ''\n  // Your code here\n  \n  return {\n    answer,\n    sources: relevant.map(r => r.content.slice(0, 50) + '...')\n  }\n}\n\n// Helper: Mock LLM generation\nfunction generateAnswer(context, query) {\n  return `Based on the context, here's the answer to \"${query}\": ${context.slice(0, 100)}...`\n}\n",
  "instructions": "Build a complete RAG pipeline that:\n1. Chunks input documents (use 200 char chunks, 20 char overlap)\n2. Generates embeddings for each chunk\n3. Embeds the user query\n4. Finds top-3 most similar chunks\n5. Generates an answer using the relevant chunks\n6. Returns answer with source attributions\n\nUse the helper functions from previous labs.",
  "testCases": [
    {
      "input": "ragPipeline('test query', ['doc1', 'doc2']).sources.length",
      "expectedOutput": "3",
      "description": "Returns top-3 sources"
    },
    {
      "input": "ragPipeline('question', ['The answer is 42']).answer.includes('answer')",
      "expectedOutput": "true",
      "description": "Answer relates to retrieved content"
    }
  ],
  "hints": [
    "Reuse chunkDocument() from Lab 1",
    "Reuse generateEmbedding() from Lab 2",
    "Reuse cosineSimilarity() and findSimilar() from Lab 3",
    "Combine retrieved chunks into context string",
    "Call generateAnswer() with context and query"
  ]
}
