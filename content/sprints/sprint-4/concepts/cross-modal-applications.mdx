---
id: cross-modal-applications
title: Cross-Modal Applications & Use Cases
description: Build real-world applications that leverage multimodal AI
difficulty: advanced
estimatedMinutes: 90
order: 3
prerequisites: [multimodal-prompting]
tags: [applications, multimodal, vision, production, advanced]
---

# Cross-Modal Applications & Use Cases

Multimodal AI transforms theoretical capabilities into production applications that solve real-world problems. This lesson explores production-ready architectures, system design patterns, and complete implementations of cross-modal applications across industries—from visual Q&A systems to medical imaging assistance.

## Learning Objectives

By the end of this lesson, you'll master:
- Real-world multimodal application architectures
- Production patterns for visual Q&A systems
- Document intelligence and OCR pipelines
- Product catalog automation systems
- Accessibility application development
- Content moderation frameworks
- Medical imaging assistance patterns
- Deployment strategies and production considerations
- Performance optimization techniques
- Monitoring and observability for multimodal systems

## Real-World Multimodal Use Cases

### Industry Applications Overview

Multimodal AI powers applications across every major industry:

| Industry | Use Case | Primary Capability |
|----------|----------|-------------------|
| E-commerce | Product catalog enrichment | Vision + text generation |
| Healthcare | Medical image analysis | Vision + diagnostic reasoning |
| Finance | Document processing (checks, forms) | OCR + structured extraction |
| Retail | Visual inventory management | Object detection + counting |
| Media | Content moderation | Vision + safety classification |
| Accessibility | Screen reader enhancement | Vision + descriptive text |
| Real Estate | Property listing automation | Vision + market analysis |
| Manufacturing | Quality control inspection | Vision + defect detection |
| Education | Homework assistance | Vision + tutoring |
| Legal | Contract analysis | OCR + clause extraction |

### The Multimodal Application Stack

```typescript
interface MultimodalStack {
  // Data Layer
  ingestion: {
    imageStorage: 'S3' | 'CloudStorage' | 'CDN'
    metadata: 'PostgreSQL' | 'MongoDB'
    caching: 'Redis' | 'Memcached'
  }

  // Processing Layer
  ai: {
    vision: 'Claude' | 'GPT-4V'
    embeddings: 'CLIP' | 'Custom'
    ocr: 'Claude Vision' | 'Tesseract'
  }

  // Application Layer
  api: {
    framework: 'Express' | 'FastAPI' | 'Next.js'
    authentication: 'JWT' | 'OAuth'
    rateLimit: 'Redis-based'
  }

  // Monitoring Layer
  observability: {
    logs: 'CloudWatch' | 'Datadog'
    metrics: 'Prometheus' | 'Grafana'
    tracing: 'OpenTelemetry'
  }
}
```

## Visual Q&A Systems

### Architecture Pattern

A production Visual Q&A system handles user questions about images with context awareness, conversation history, and intelligent caching.

```typescript
import Anthropic from '@anthropic-ai/sdk'
import { Redis } from 'ioredis'
import fs from 'fs'
import crypto from 'crypto'

interface Message {
  role: 'user' | 'assistant'
  content: string | Array<{
    type: 'text' | 'image'
    text?: string
    source?: {
      type: 'base64'
      media_type: string
      data: string
    }
  }>
}

interface Conversation {
  id: string
  messages: Message[]
  imageHash?: string
  metadata: {
    createdAt: Date
    updatedAt: Date
    totalQuestions: number
  }
}

class VisualQASystem {
  private client: Anthropic
  private redis: Redis
  private conversations: Map<string, Conversation>

  constructor(apiKey: string, redisUrl?: string) {
    this.client = new Anthropic({ apiKey })
    this.redis = redisUrl ? new Redis(redisUrl) : new Redis()
    this.conversations = new Map()
  }

  /**
   * Start a new conversation about an image
   */
  async startConversation(
    imagePath: string,
    initialContext?: string
  ): Promise<string> {
    const conversationId = crypto.randomUUID()
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const imageHash = crypto.createHash('md5').update(imageData).digest('hex')

    // Determine media type
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const conversation: Conversation = {
      id: conversationId,
      messages: [],
      imageHash,
      metadata: {
        createdAt: new Date(),
        updatedAt: new Date(),
        totalQuestions: 0,
      },
    }

    // Add system context if provided
    if (initialContext) {
      conversation.messages.push({
        role: 'user',
        content: [
          {
            type: 'image',
            source: {
              type: 'base64',
              media_type: mediaType,
              data: base64Image,
            },
          },
          {
            type: 'text',
            text: initialContext,
          },
        ],
      })

      const response = await this.client.messages.create({
        model: 'claude-3-5-sonnet-20250129',
        max_tokens: 1024,
        messages: conversation.messages,
      })

      conversation.messages.push({
        role: 'assistant',
        content: response.content[0].text,
      })
    }

    this.conversations.set(conversationId, conversation)

    // Cache in Redis for 1 hour
    await this.redis.setex(
      `conversation:${conversationId}`,
      3600,
      JSON.stringify(conversation)
    )

    return conversationId
  }

  /**
   * Ask a question about the image in context
   */
  async askQuestion(
    conversationId: string,
    question: string
  ): Promise<string> {
    let conversation = this.conversations.get(conversationId)

    // Try to load from Redis if not in memory
    if (!conversation) {
      const cached = await this.redis.get(`conversation:${conversationId}`)
      if (cached) {
        try {
          conversation = JSON.parse(cached)
          this.conversations.set(conversationId, conversation!)
        } catch (error) {
          console.error('Failed to parse cached conversation:', error)
          throw new Error('Conversation data corrupted')
        }
      } else {
        throw new Error('Conversation not found')
      }
    }

    // Add user question
    conversation!.messages.push({
      role: 'user',
      content: question,
    })

    // Get response from Claude
    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 1024,
      messages: conversation!.messages as any,
    })

    const answer = response.content[0].text

    // Add assistant response
    conversation!.messages.push({
      role: 'assistant',
      content: answer,
    })

    // Update metadata
    conversation!.metadata.updatedAt = new Date()
    conversation!.metadata.totalQuestions++

    // Update cache
    await this.redis.setex(
      `conversation:${conversationId}`,
      3600,
      JSON.stringify(conversation)
    )

    return answer
  }

  /**
   * Get conversation history
   */
  async getHistory(conversationId: string): Promise<Message[]> {
    const conversation = this.conversations.get(conversationId)
    if (!conversation) {
      const cached = await this.redis.get(`conversation:${conversationId}`)
      if (!cached) throw new Error('Conversation not found')
      try {
        return JSON.parse(cached).messages
      } catch (error) {
        console.error('Failed to parse cached conversation:', error)
        throw new Error('Conversation data corrupted')
      }
    }
    return conversation.messages
  }

  /**
   * Clear old conversations (cleanup)
   */
  async cleanup(olderThanHours: number = 24) {
    const cutoff = new Date(Date.now() - olderThanHours * 60 * 60 * 1000)

    for (const [id, conv] of this.conversations.entries()) {
      if (conv.metadata.createdAt < cutoff) {
        this.conversations.delete(id)
        await this.redis.del(`conversation:${id}`)
      }
    }
  }
}

// Example usage
async function visualQAExample() {
  const qa = new VisualQASystem(process.env.ANTHROPIC_API_KEY!)

  // Start conversation about a product image
  const conversationId = await qa.startConversation(
    './product-photo.jpg',
    'This is a product image. Help me answer customer questions about it.'
  )

  // Ask multiple questions
  const q1 = await qa.askQuestion(conversationId, 'What color is the product?')
  console.log('A:', q1)

  const q2 = await qa.askQuestion(conversationId, 'What material does it appear to be made of?')
  console.log('A:', q2)

  const q3 = await qa.askQuestion(conversationId, 'Based on the previous details, what is a good product description?')
  console.log('A:', q3)

  // Get full history
  const history = await qa.getHistory(conversationId)
  console.log('Conversation had', history.length / 2, 'exchanges')
}
```

### Advanced: Multi-Image Visual Q&A

```typescript
class MultiImageQASystem extends VisualQASystem {
  /**
   * Start conversation with multiple images
   */
  async startMultiImageConversation(
    imagePaths: string[],
    imageLabels: string[],
    initialContext?: string
  ): Promise<string> {
    const conversationId = crypto.randomUUID()

    const content: any[] = []

    if (initialContext) {
      content.push({ type: 'text', text: initialContext })
    }

    // Add all images with labels
    for (let i = 0; i < imagePaths.length; i++) {
      const imageData = fs.readFileSync(imagePaths[i])
      const base64Image = imageData.toString('base64')
      const extension = imagePaths[i].split('.').pop()?.toLowerCase()
      const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

      content.push({
        type: 'image',
        source: {
          type: 'base64',
          media_type: mediaType,
          data: base64Image,
        },
      })

      content.push({
        type: 'text',
        text: `Image ${i + 1}: ${imageLabels[i]}`,
      })
    }

    const conversation: Conversation = {
      id: conversationId,
      messages: [
        {
          role: 'user',
          content,
        },
      ],
      metadata: {
        createdAt: new Date(),
        updatedAt: new Date(),
        totalQuestions: 0,
      },
    }

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 1024,
      messages: conversation.messages as any,
    })

    conversation.messages.push({
      role: 'assistant',
      content: response.content[0].text,
    })

    this.conversations.set(conversationId, conversation)
    await this.redis.setex(
      `conversation:${conversationId}`,
      3600,
      JSON.stringify(conversation)
    )

    return conversationId
  }
}

// Example: Comparing product versions
async function productComparisonQA() {
  const qa = new MultiImageQASystem(process.env.ANTHROPIC_API_KEY!)

  const conversationId = await qa.startMultiImageConversation(
    ['./product-v1.jpg', './product-v2.jpg', './product-v3.jpg'],
    ['Version 1 (2022)', 'Version 2 (2023)', 'Version 3 (2024)'],
    'These are three versions of our product over time. Help analyze the evolution.'
  )

  const q1 = await qa.askQuestion(
    conversationId,
    'What are the major design changes across versions?'
  )

  const q2 = await qa.askQuestion(
    conversationId,
    'Which version has the best visual appeal for premium positioning?'
  )

  console.log('Design changes:', q1)
  console.log('Best version:', q2)
}
```

## Document Intelligence & OCR Pipelines

### Production Document Processing System

```typescript
interface Document {
  id: string
  type: 'receipt' | 'invoice' | 'form' | 'id' | 'contract' | 'other'
  status: 'pending' | 'processing' | 'completed' | 'failed' | 'review_needed'
  extractedData: any
  confidence: number
  processingTime: number
  createdAt: Date
  reviewedAt?: Date
}

interface ExtractionResult {
  success: boolean
  documentType: string
  data: any
  confidence: number
  requiresReview: boolean
  processingTimeMs: number
}

class DocumentIntelligenceSystem {
  private client: Anthropic
  private redis: Redis
  private documents: Map<string, Document>

  constructor(apiKey: string, redisUrl?: string) {
    this.client = new Anthropic({ apiKey })
    this.redis = redisUrl ? new Redis(redisUrl) : new Redis()
    this.documents = new Map()
  }

  /**
   * Process a document end-to-end
   */
  async processDocument(imagePath: string): Promise<ExtractionResult> {
    const startTime = Date.now()

    try {
      // Step 1: Classify document type
      const docType = await this.classifyDocument(imagePath)

      // Step 2: Extract data based on type
      const extractedData = await this.extractByType(imagePath, docType)

      // Step 3: Validate and calculate confidence
      const validation = this.validateExtraction(docType, extractedData)

      // Step 4: Store document
      const document: Document = {
        id: crypto.randomUUID(),
        type: docType,
        status: validation.requiresReview ? 'review_needed' : 'completed',
        extractedData,
        confidence: validation.confidence,
        processingTime: Date.now() - startTime,
        createdAt: new Date(),
      }

      this.documents.set(document.id, document)
      await this.redis.setex(
        `document:${document.id}`,
        86400, // 24 hours
        JSON.stringify(document)
      )

      return {
        success: true,
        documentType: docType,
        data: extractedData,
        confidence: validation.confidence,
        requiresReview: validation.requiresReview,
        processingTimeMs: Date.now() - startTime,
      }
    } catch (error) {
      return {
        success: false,
        documentType: 'unknown',
        data: null,
        confidence: 0,
        requiresReview: true,
        processingTimeMs: Date.now() - startTime,
      }
    }
  }

  /**
   * Classify document type
   */
  private async classifyDocument(imagePath: string): Promise<Document['type']> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 128,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Classify this document. Reply with ONLY one of these words:
receipt, invoice, form, id, contract, other

No explanation, just the classification.`,
            },
          ],
        },
      ],
    })

    const classification = response.content[0].text.toLowerCase().trim()
    return classification as Document['type']
  }

  /**
   * Extract data based on document type
   */
  private async extractByType(
    imagePath: string,
    docType: Document['type']
  ): Promise<any> {
    const extractors: Record<Document['type'], (path: string) => Promise<any>> = {
      receipt: this.extractReceipt.bind(this),
      invoice: this.extractInvoice.bind(this),
      form: this.extractForm.bind(this),
      id: this.extractID.bind(this),
      contract: this.extractContract.bind(this),
      other: this.extractGeneric.bind(this),
    }

    return await extractors[docType](imagePath)
  }

  /**
   * Extract receipt data
   */
  private async extractReceipt(imagePath: string): Promise<any> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 2048,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Extract all data from this receipt. Return ONLY valid JSON:
{
  "merchant": "store name",
  "merchantAddress": "full address if visible",
  "date": "YYYY-MM-DD",
  "time": "HH:MM if visible",
  "items": [
    {
      "name": "item name",
      "quantity": number,
      "unitPrice": number,
      "totalPrice": number
    }
  ],
  "subtotal": number,
  "tax": number,
  "tip": number (if applicable),
  "total": number,
  "paymentMethod": "cash|credit|debit|other",
  "lastFourDigits": "last 4 of card if visible",
  "confidence": "high|medium|low"
}

Use null for fields that are not visible or unclear.`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return { error: 'Invalid JSON response', raw: response.content[0].text }
    }
  }

  /**
   * Extract invoice data
   */
  private async extractInvoice(imagePath: string): Promise<any> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 3000,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Extract all data from this invoice. Return ONLY valid JSON:
{
  "invoiceNumber": "string",
  "date": "YYYY-MM-DD",
  "dueDate": "YYYY-MM-DD",
  "vendor": {
    "name": "string",
    "address": "string",
    "phone": "string",
    "email": "string"
  },
  "billTo": {
    "name": "string",
    "address": "string",
    "phone": "string",
    "email": "string"
  },
  "lineItems": [
    {
      "description": "string",
      "quantity": number,
      "unitPrice": number,
      "total": number
    }
  ],
  "subtotal": number,
  "tax": number,
  "discount": number,
  "total": number,
  "paymentTerms": "string",
  "confidence": "high|medium|low"
}

Use null for fields not present.`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return { error: 'Invalid JSON response', raw: response.content[0].text }
    }
  }

  /**
   * Extract form data
   */
  private async extractForm(imagePath: string): Promise<any> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 2048,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Extract all filled fields from this form. Return JSON:
{
  "formType": "description of form type",
  "fields": [
    {
      "label": "field label/name",
      "value": "filled value",
      "fieldType": "text|checkbox|radio|date|signature|other"
    }
  ],
  "signatures": ["description of signature locations"],
  "dates": ["any dates found"],
  "confidence": "high|medium|low"
}`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return { error: 'Invalid JSON response', raw: response.content[0].text }
    }
  }

  /**
   * Extract ID/License data
   */
  private async extractID(imagePath: string): Promise<any> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 1024,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Extract data from this ID document. Return JSON:
{
  "idType": "drivers_license|passport|national_id|other",
  "name": "full name",
  "dateOfBirth": "YYYY-MM-DD",
  "idNumber": "ID number",
  "issueDate": "YYYY-MM-DD",
  "expiryDate": "YYYY-MM-DD",
  "issuingAuthority": "string",
  "address": "if visible",
  "confidence": "high|medium|low"
}

IMPORTANT: Do not extract sensitive data if this is a privacy concern.`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return { error: 'Invalid JSON response', raw: response.content[0].text }
    }
  }

  /**
   * Extract contract data
   */
  private async extractContract(imagePath: string): Promise<any> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 3000,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Analyze this contract page. Return JSON:
{
  "contractType": "description",
  "parties": ["party names"],
  "effectiveDate": "YYYY-MM-DD if visible",
  "keyTerms": ["important clauses or terms"],
  "signatures": ["signature block descriptions"],
  "pageNumber": "if visible",
  "confidence": "high|medium|low"
}`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return { error: 'Invalid JSON response', raw: response.content[0].text }
    }
  }

  /**
   * Generic extraction for unknown document types
   */
  private async extractGeneric(imagePath: string): Promise<any> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 2048,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Extract all text and structured data from this document. Return JSON:
{
  "documentDescription": "brief description",
  "extractedText": "all visible text",
  "structuredData": {
    "dates": [],
    "numbers": [],
    "names": [],
    "addresses": []
  },
  "confidence": "high|medium|low"
}`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return { error: 'Invalid JSON response', raw: response.content[0].text }
    }
  }

  /**
   * Validate extraction and calculate confidence
   */
  private validateExtraction(
    docType: Document['type'],
    data: any
  ): { confidence: number; requiresReview: boolean } {
    // Check for confidence field
    const reportedConfidence = data.confidence || 'low'

    // Check for null/missing critical fields
    let nullCount = 0
    let totalFields = 0

    const countNulls = (obj: any) => {
      for (const key in obj) {
        if (typeof obj[key] === 'object' && obj[key] !== null) {
          countNulls(obj[key])
        } else {
          totalFields++
          if (obj[key] === null || obj[key] === undefined) {
            nullCount++
          }
        }
      }
    }

    countNulls(data)

    const completeness = totalFields > 0 ? (totalFields - nullCount) / totalFields : 0

    // Calculate overall confidence score
    const confidenceMap = { high: 1.0, medium: 0.7, low: 0.4 }
    const baseConfidence = confidenceMap[reportedConfidence as keyof typeof confidenceMap] || 0.4

    const finalConfidence = Math.round((baseConfidence * 0.6 + completeness * 0.4) * 100)

    // Require review if confidence is low
    const requiresReview = finalConfidence < 70 || nullCount > totalFields * 0.3

    return {
      confidence: finalConfidence,
      requiresReview,
    }
  }

  /**
   * Get document by ID
   */
  async getDocument(documentId: string): Promise<Document | null> {
    let document = this.documents.get(documentId)

    if (!document) {
      const cached = await this.redis.get(`document:${documentId}`)
      if (cached) {
        try {
          document = JSON.parse(cached)
        } catch (error) {
          console.error('Failed to parse cached document:', error)
          return null
        }
      }
    }

    return document || null
  }

  /**
   * Mark document as reviewed
   */
  async markReviewed(documentId: string, reviewedData: any) {
    const document = await this.getDocument(documentId)
    if (!document) throw new Error('Document not found')

    document.status = 'completed'
    document.extractedData = reviewedData
    document.reviewedAt = new Date()
    document.confidence = 100 // Human-verified

    this.documents.set(documentId, document)
    await this.redis.setex(
      `document:${documentId}`,
      86400,
      JSON.stringify(document)
    )
  }
}

// Example usage
async function documentProcessingExample() {
  const system = new DocumentIntelligenceSystem(process.env.ANTHROPIC_API_KEY!)

  // Process a receipt
  const result = await system.processDocument('./receipt.jpg')

  console.log('Document Type:', result.documentType)
  console.log('Confidence:', result.confidence, '%')
  console.log('Requires Review:', result.requiresReview)
  console.log('Processing Time:', result.processingTimeMs, 'ms')
  console.log('Extracted Data:', JSON.stringify(result.data, null, 2))

  if (result.requiresReview) {
    console.log('⚠️  Document flagged for human review')
  }
}
```

## Product Catalog Automation

### E-commerce Product Data Enrichment System

```typescript
interface ProductData {
  id: string
  title: string
  description: string
  category: string
  subcategory?: string
  brand?: string
  color: string[]
  material?: string[]
  features: string[]
  condition: 'new' | 'like-new' | 'good' | 'fair' | 'worn'
  estimatedPrice?: {
    min: number
    max: number
    currency: string
  }
  tags: string[]
  seo: {
    metaTitle: string
    metaDescription: string
    keywords: string[]
  }
  quality: {
    imageQuality: 'excellent' | 'good' | 'fair' | 'poor'
    completeness: number
    confidence: number
  }
}

class ProductCatalogSystem {
  private client: Anthropic

  constructor(apiKey: string) {
    this.client = new Anthropic({ apiKey })
  }

  /**
   * Enrich product listing from single image
   */
  async enrichProduct(imagePath: string): Promise<ProductData> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 3000,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Analyze this product image and generate complete e-commerce listing data.

Return ONLY valid JSON:
{
  "title": "descriptive product title (50-70 chars, include key features)",
  "description": "detailed description (150-200 words, highlight benefits)",
  "category": "primary category",
  "subcategory": "specific subcategory",
  "brand": "brand name if visible",
  "color": ["primary color", "secondary colors"],
  "material": ["materials visible or inferred"],
  "features": ["feature 1", "feature 2", "feature 3"],
  "condition": "new|like-new|good|fair|worn",
  "estimatedPrice": {
    "min": number,
    "max": number,
    "currency": "USD"
  },
  "tags": ["searchable", "tags", "keywords"],
  "seo": {
    "metaTitle": "SEO-optimized title (60 chars max)",
    "metaDescription": "SEO description (155 chars max)",
    "keywords": ["keyword1", "keyword2"]
  },
  "quality": {
    "imageQuality": "excellent|good|fair|poor",
    "completeness": 0-100 (how complete is visible product info),
    "confidence": 0-100 (confidence in analysis)
  }
}

Focus on what makes this product valuable and searchable.`,
            },
          ],
        },
      ],
    })

    let data
    try {
      data = JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return {
        id: crypto.randomUUID(),
        error: 'Invalid JSON response',
        raw: response.content[0].text,
      } as any
    }

    return {
      id: crypto.randomUUID(),
      ...data,
    }
  }

  /**
   * Enrich product from multiple images
   */
  async enrichProductMultiImage(imagePaths: string[]): Promise<ProductData> {
    const content: any[] = [
      {
        type: 'text',
        text: 'I will show you multiple images of the same product from different angles.',
      },
    ]

    // Add all images
    for (let i = 0; i < imagePaths.length; i++) {
      const imageData = fs.readFileSync(imagePaths[i])
      const base64Image = imageData.toString('base64')
      const extension = imagePaths[i].split('.').pop()?.toLowerCase()
      const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

      content.push({
        type: 'text',
        text: `Image ${i + 1}:`,
      })

      content.push({
        type: 'image',
        source: {
          type: 'base64',
          media_type: mediaType,
          data: base64Image,
        },
      })
    }

    content.push({
      type: 'text',
      text: `Analyze ALL images together to generate complete e-commerce listing data.

Use information from all images to create the most accurate and comprehensive listing.

Return the same JSON format as before, but with higher confidence since you have multiple views.`,
    })

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 3000,
      messages: [
        {
          role: 'user',
          content,
        },
      ],
    })

    let data
    try {
      data = JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return {
        id: crypto.randomUUID(),
        error: 'Invalid JSON response',
        raw: response.content[0].text,
      } as any
    }

    return {
      id: crypto.randomUUID(),
      ...data,
    }
  }

  /**
   * Generate product variants analysis
   */
  async analyzeProductVariants(
    imagePaths: string[]
  ): Promise<{
    baseProduct: string
    variants: Array<{
      id: string
      differences: string[]
      recommendedTitle: string
    }>
  }> {
    const content: any[] = [
      {
        type: 'text',
        text: 'These images show different variants of the same product (different colors, sizes, or configurations).',
      },
    ]

    for (let i = 0; i < imagePaths.length; i++) {
      const imageData = fs.readFileSync(imagePaths[i])
      const base64Image = imageData.toString('base64')
      const extension = imagePaths[i].split('.').pop()?.toLowerCase()
      const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

      content.push({
        type: 'text',
        text: `Variant ${i + 1}:`,
      })

      content.push({
        type: 'image',
        source: {
          type: 'base64',
          media_type: mediaType,
          data: base64Image,
        },
      })
    }

    content.push({
      type: 'text',
      text: `Analyze these product variants. Return JSON:
{
  "baseProduct": "common product name/description",
  "variants": [
    {
      "id": "variant-1",
      "differences": ["what makes this variant unique"],
      "recommendedTitle": "specific title for this variant"
    }
  ]
}`,
    })

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 2048,
      messages: [
        {
          role: 'user',
          content,
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return { error: 'Invalid JSON response', raw: response.content[0].text }
    }
  }
}

// Example usage
async function productCatalogExample() {
  const system = new ProductCatalogSystem(process.env.ANTHROPIC_API_KEY!)

  // Single image enrichment
  const product = await system.enrichProduct('./product-main.jpg')

  console.log('Title:', product.title)
  console.log('Description:', product.description)
  console.log('Category:', product.category, '>', product.subcategory)
  console.log('Price Range: $', product.estimatedPrice?.min, '-', product.estimatedPrice?.max)
  console.log('SEO Title:', product.seo.metaTitle)
  console.log('Confidence:', product.quality.confidence, '%')

  // Multi-image enrichment (better accuracy)
  const productMulti = await system.enrichProductMultiImage([
    './product-front.jpg',
    './product-back.jpg',
    './product-detail.jpg',
  ])

  console.log('\nMulti-image analysis confidence:', productMulti.quality.confidence, '%')

  // Variant analysis
  const variants = await system.analyzeProductVariants([
    './shoe-black.jpg',
    './shoe-white.jpg',
    './shoe-red.jpg',
  ])

  console.log('\nBase Product:', variants.baseProduct)
  variants.variants.forEach((v, i) => {
    console.log(`Variant ${i + 1}:`, v.recommendedTitle)
    console.log('  Differences:', v.differences)
  })
}
```

## Accessibility Applications

### Image Description Service for Screen Readers

```typescript
interface AccessibilityDescription {
  altText: string // Short alt text (125 chars max)
  longDescription: string // Detailed description
  objectsDetected: string[]
  textContent?: string // Any text in image
  context?: string // Contextual information
  warnings?: string[] // Important info (e.g., "contains text")
}

class AccessibilityService {
  private client: Anthropic

  constructor(apiKey: string) {
    this.client = new Anthropic({ apiKey })
  }

  /**
   * Generate comprehensive accessibility descriptions
   */
  async describeForAccessibility(
    imagePath: string,
    context?: string
  ): Promise<AccessibilityDescription> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const contextPrompt = context
      ? `Context: This image is from ${context}.\n\n`
      : ''

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 1500,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `${contextPrompt}Create accessibility descriptions for this image for screen reader users.

Return JSON:
{
  "altText": "concise alt text (max 125 chars) focusing on most important info",
  "longDescription": "detailed description (2-4 sentences) describing scene, objects, actions, and important details",
  "objectsDetected": ["object 1", "object 2"],
  "textContent": "any text visible in the image (null if none)",
  "context": "additional context that helps understand the image",
  "warnings": ["important info like: contains text, has charts/graphs, shows data, etc"]
}

Guidelines:
- Alt text should be concise but informative
- Long description should paint a clear mental picture
- Include important visual details (colors, positions, emotions)
- Note any text, charts, or data visualizations
- Be objective and factual`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return {
        altText: 'Image description unavailable',
        longDescription: 'Failed to parse response',
        objectsDetected: [],
        error: 'Invalid JSON response',
        raw: response.content[0].text
      }
    }
  }

  /**
   * Generate alt text for batch of images
   */
  async batchGenerateAltText(
    imagePaths: string[]
  ): Promise<Map<string, string>> {
    const results = new Map<string, string>()

    // Process in parallel (with concurrency limit)
    const concurrency = 5
    for (let i = 0; i < imagePaths.length; i += concurrency) {
      const batch = imagePaths.slice(i, i + concurrency)

      const promises = batch.map(async (path) => {
        try {
          const desc = await this.describeForAccessibility(path)
          return { path, altText: desc.altText }
        } catch (error) {
          console.error(`Failed to process ${path}:`, error)
          return { path, altText: 'Image description unavailable' }
        }
      })

      const batchResults = await Promise.all(promises)
      batchResults.forEach(({ path, altText }) => {
        results.set(path, altText)
      })

      // Rate limiting pause
      if (i + concurrency < imagePaths.length) {
        await new Promise(resolve => setTimeout(resolve, 1000))
      }
    }

    return results
  }

  /**
   * Describe UI screenshot for accessibility
   */
  async describeUIForAccessibility(imagePath: string): Promise<{
    pageTitle: string
    mainContent: string
    interactiveElements: Array<{
      type: string
      label: string
      location: string
    }>
    navigationStructure: string
  }> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 2048,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Describe this UI screenshot for screen reader users. Return JSON:
{
  "pageTitle": "inferred page title/purpose",
  "mainContent": "description of main content area",
  "interactiveElements": [
    {
      "type": "button|link|input|dropdown|etc",
      "label": "button text or aria-label",
      "location": "position description (top-right, main nav, etc)"
    }
  ],
  "navigationStructure": "description of navigation and page structure"
}

Help users understand the layout and how to navigate the interface.`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return {
        pageTitle: 'Unknown',
        mainContent: 'Failed to parse response',
        interactiveElements: [],
        navigationStructure: '',
        error: 'Invalid JSON response',
        raw: response.content[0].text
      }
    }
  }
}

// Example usage
async function accessibilityExample() {
  const service = new AccessibilityService(process.env.ANTHROPIC_API_KEY!)

  // Generate accessibility description
  const desc = await service.describeForAccessibility(
    './hero-image.jpg',
    'homepage hero section'
  )

  console.log('Alt Text:', desc.altText)
  console.log('\nLong Description:', desc.longDescription)
  console.log('\nObjects:', desc.objectsDetected.join(', '))

  if (desc.textContent) {
    console.log('\nText in Image:', desc.textContent)
  }

  if (desc.warnings && desc.warnings.length > 0) {
    console.log('\nWarnings:', desc.warnings.join(', '))
  }

  // Batch process images for alt text
  const imagePaths = [
    './gallery/image1.jpg',
    './gallery/image2.jpg',
    './gallery/image3.jpg',
  ]

  console.log('\nGenerating alt text for', imagePaths.length, 'images...')
  const altTexts = await service.batchGenerateAltText(imagePaths)

  altTexts.forEach((altText, path) => {
    console.log(`\n${path}:`)
    console.log(`  "${altText}"`)
  })

  // UI screenshot accessibility
  const uiDesc = await service.describeUIForAccessibility('./app-screenshot.png')
  console.log('\nUI Page:', uiDesc.pageTitle)
  console.log('Interactive Elements:', uiDesc.interactiveElements.length)
}
```

## Content Moderation

### Automated Content Moderation System

```typescript
interface ModerationResult {
  safe: boolean
  categories: Array<{
    name: string
    detected: boolean
    severity: 'none' | 'low' | 'medium' | 'high' | 'critical'
    confidence: number
  }>
  overallRisk: 'safe' | 'review' | 'block'
  explanation: string
  requiresHumanReview: boolean
  moderatedAt: Date
}

interface ModerationPolicy {
  categories: string[]
  blockThreshold: number // 0-100
  reviewThreshold: number // 0-100
  autoBlock: string[] // Categories that auto-block
}

class ContentModerationSystem {
  private client: Anthropic
  private policy: ModerationPolicy

  constructor(apiKey: string, policy?: ModerationPolicy) {
    this.client = new Anthropic({ apiKey })
    this.policy = policy || {
      categories: [
        'violence',
        'explicit_content',
        'hate_speech',
        'harassment',
        'dangerous_activities',
        'illegal_content',
        'spam',
        'misinformation',
      ],
      blockThreshold: 80,
      reviewThreshold: 50,
      autoBlock: ['explicit_content', 'illegal_content', 'hate_speech'],
    }
  }

  /**
   * Moderate image content
   */
  async moderateImage(imagePath: string): Promise<ModerationResult> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 1500,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
            {
              type: 'text',
              text: `Evaluate this image for content policy violations.

Check for these categories: ${this.policy.categories.join(', ')}

Return JSON:
{
  "categories": [
    {
      "name": "category name",
      "detected": boolean,
      "severity": "none|low|medium|high|critical",
      "confidence": 0-100
    }
  ],
  "explanation": "brief explanation of findings",
  "suggestedAction": "approve|review|block"
}

Be objective and err on the side of caution.`,
            },
          ],
        },
      ],
    })

    let analysis
    try {
      analysis = JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return {
        safe: false,
        categories: [],
        overallRisk: 'review' as const,
        explanation: 'Failed to parse moderation response',
        requiresHumanReview: true,
        moderatedAt: new Date(),
      }
    }

    // Calculate overall risk
    const detected = analysis.categories.filter((c: any) => c.detected)
    const maxSeverity = detected.reduce((max: number, c: any) => {
      const severityMap = { none: 0, low: 25, medium: 50, high: 75, critical: 100 }
      return Math.max(max, severityMap[c.severity as keyof typeof severityMap])
    }, 0)

    // Determine action based on policy
    let overallRisk: ModerationResult['overallRisk'] = 'safe'
    let requiresHumanReview = false

    if (maxSeverity >= this.policy.blockThreshold) {
      overallRisk = 'block'
    } else if (maxSeverity >= this.policy.reviewThreshold) {
      overallRisk = 'review'
      requiresHumanReview = true
    }

    // Check auto-block categories
    const autoBlockDetected = detected.some((c: any) =>
      this.policy.autoBlock.includes(c.name)
    )

    if (autoBlockDetected && maxSeverity >= 50) {
      overallRisk = 'block'
    }

    return {
      safe: overallRisk === 'safe',
      categories: analysis.categories,
      overallRisk,
      explanation: analysis.explanation,
      requiresHumanReview,
      moderatedAt: new Date(),
    }
  }

  /**
   * Moderate batch of images
   */
  async moderateBatch(
    imagePaths: string[]
  ): Promise<Map<string, ModerationResult>> {
    const results = new Map<string, ModerationResult>()

    for (const path of imagePaths) {
      try {
        const result = await this.moderateImage(path)
        results.set(path, result)

        // Rate limiting
        await new Promise(resolve => setTimeout(resolve, 500))
      } catch (error) {
        console.error(`Failed to moderate ${path}:`, error)
        // Default to review on error
        results.set(path, {
          safe: false,
          categories: [],
          overallRisk: 'review',
          explanation: 'Moderation failed - requires manual review',
          requiresHumanReview: true,
          moderatedAt: new Date(),
        })
      }
    }

    return results
  }

  /**
   * Get moderation statistics
   */
  getModerationStats(
    results: Map<string, ModerationResult>
  ): {
    total: number
    safe: number
    review: number
    blocked: number
    topCategories: Array<{ category: string; count: number }>
  } {
    const stats = {
      total: results.size,
      safe: 0,
      review: 0,
      blocked: 0,
      topCategories: new Map<string, number>(),
    }

    for (const result of results.values()) {
      if (result.overallRisk === 'safe') stats.safe++
      else if (result.overallRisk === 'review') stats.review++
      else if (result.overallRisk === 'block') stats.blocked++

      // Count detected categories
      result.categories
        .filter(c => c.detected)
        .forEach(c => {
          stats.topCategories.set(c.name, (stats.topCategories.get(c.name) || 0) + 1)
        })
    }

    // Convert to sorted array
    const topCategories = Array.from(stats.topCategories.entries())
      .map(([category, count]) => ({ category, count }))
      .sort((a, b) => b.count - a.count)
      .slice(0, 5)

    return {
      ...stats,
      topCategories,
    }
  }
}

// Example usage
async function contentModerationExample() {
  const system = new ContentModerationSystem(process.env.ANTHROPIC_API_KEY!)

  // Moderate single image
  const result = await system.moderateImage('./user-upload.jpg')

  console.log('Safe:', result.safe)
  console.log('Action:', result.overallRisk)
  console.log('Explanation:', result.explanation)
  console.log('Requires Review:', result.requiresHumanReview)

  console.log('\nDetected Issues:')
  result.categories
    .filter(c => c.detected)
    .forEach(c => {
      console.log(`  - ${c.name}: ${c.severity} (${c.confidence}% confidence)`)
    })

  // Batch moderation
  const imagePaths = [
    './uploads/image1.jpg',
    './uploads/image2.jpg',
    './uploads/image3.jpg',
  ]

  const batchResults = await system.moderateBatch(imagePaths)
  const stats = system.getModerationStats(batchResults)

  console.log('\nBatch Moderation Stats:')
  console.log('Total:', stats.total)
  console.log('Safe:', stats.safe)
  console.log('Need Review:', stats.review)
  console.log('Blocked:', stats.blocked)
  console.log('Top Issues:', stats.topCategories)
}
```

## Medical Imaging Assistance

### Medical Image Analysis System

**IMPORTANT**: This is for educational and research purposes only. Production medical systems require FDA approval, certified algorithms, and human radiologist oversight.

```typescript
interface MedicalImageAnalysis {
  imageType: string // X-ray, CT, MRI, etc.
  anatomicalRegion: string
  observations: Array<{
    finding: string
    location: string
    characteristics: string
    significance: 'normal' | 'benign' | 'attention' | 'urgent'
  }>
  measurements?: Array<{
    structure: string
    measurement: string
    unit: string
  }>
  comparison?: string // If prior images provided
  recommendations: string[]
  disclaimer: string
  confidence: number
}

class MedicalImagingAssistant {
  private client: Anthropic

  constructor(apiKey: string) {
    this.client = new Anthropic({ apiKey })
  }

  /**
   * Analyze medical image (EDUCATIONAL USE ONLY)
   */
  async analyzeMedicalImage(
    imagePath: string,
    imageType: string,
    clinicalContext?: string
  ): Promise<MedicalImageAnalysis> {
    const imageData = fs.readFileSync(imagePath)
    const base64Image = imageData.toString('base64')
    const extension = imagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const contextPrompt = clinicalContext
      ? `Clinical Context: ${clinicalContext}\n\n`
      : ''

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 3000,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `You are a medical imaging AI assistant for educational purposes only.

CRITICAL DISCLAIMER: This analysis is for educational/research purposes only and should NOT be used for clinical diagnosis. All findings must be verified by licensed medical professionals.

${contextPrompt}Analyze this ${imageType} image and return JSON:
{
  "imageType": "${imageType}",
  "anatomicalRegion": "which body part/region",
  "observations": [
    {
      "finding": "what you observe",
      "location": "anatomical location",
      "characteristics": "size, shape, density, etc",
      "significance": "normal|benign|attention|urgent"
    }
  ],
  "measurements": [
    {
      "structure": "what is measured",
      "measurement": "value",
      "unit": "mm/cm/etc"
    }
  ],
  "recommendations": ["suggest next steps for medical professional"],
  "disclaimer": "This is an AI-generated analysis for educational purposes only...",
  "confidence": 0-100
}

Focus on objective observations. Do not make definitive diagnoses.`,
            },
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: base64Image,
              },
            },
          ],
        },
      ],
    })

    let analysis
    try {
      analysis = JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return {
        imageType,
        anatomicalRegion: 'Unknown',
        observations: [],
        recommendations: ['Failed to analyze image - please consult a medical professional'],
        disclaimer: 'This AI-generated analysis failed. All medical imaging must be interpreted by qualified, licensed medical professionals.',
        confidence: 0,
        error: 'Invalid JSON response',
        raw: response.content[0].text
      } as any
    }

    // Ensure disclaimer is present
    if (!analysis.disclaimer) {
      analysis.disclaimer =
        'This AI-generated analysis is for educational and research purposes only. It should NOT be used for clinical diagnosis or treatment decisions. All medical imaging must be interpreted by qualified, licensed medical professionals.'
    }

    return analysis
  }

  /**
   * Compare current image with prior (progression analysis)
   */
  async compareWithPrior(
    currentImagePath: string,
    priorImagePath: string,
    imageType: string
  ): Promise<{
    changes: Array<{
      finding: string
      changeType: 'new' | 'resolved' | 'progressed' | 'stable' | 'regressed'
      significance: string
    }>
    overallAssessment: string
    recommendations: string[]
    disclaimer: string
  }> {
    const currentImage = fs.readFileSync(currentImagePath).toString('base64')
    const priorImage = fs.readFileSync(priorImagePath).toString('base64')
    const extension = currentImagePath.split('.').pop()?.toLowerCase()
    const mediaType = extension === 'png' ? 'image/png' : 'image/jpeg'

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 2500,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `Compare these two ${imageType} images (prior and current) for progression analysis.

EDUCATIONAL USE ONLY - Not for clinical decisions.

Prior image:`,
            },
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: priorImage,
              },
            },
            {
              type: 'text',
              text: 'Current image:',
            },
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: mediaType,
                data: currentImage,
              },
            },
            {
              type: 'text',
              text: `Analyze changes between images. Return JSON:
{
  "changes": [
    {
      "finding": "what changed",
      "changeType": "new|resolved|progressed|stable|regressed",
      "significance": "clinical significance"
    }
  ],
  "overallAssessment": "summary of progression",
  "recommendations": ["for medical professional consideration"],
  "disclaimer": "educational use disclaimer"
}`,
            },
          ],
        },
      ],
    })

    try {
      return JSON.parse(response.content[0].text)
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      return {
        changes: [],
        overallAssessment: 'Failed to analyze comparison',
        recommendations: ['Unable to parse comparison results - please consult a medical professional'],
        disclaimer: 'This AI-generated comparison failed. All medical imaging must be interpreted by qualified, licensed medical professionals.',
        error: 'Invalid JSON response',
        raw: response.content[0].text
      }
    }
  }

  /**
   * Generate structured radiology report template
   */
  async generateReportTemplate(
    analysis: MedicalImageAnalysis
  ): Promise<string> {
    return `MEDICAL IMAGING REPORT (AI-ASSISTED DRAFT - REQUIRES PHYSICIAN REVIEW)

EXAMINATION: ${analysis.imageType}
ANATOMICAL REGION: ${analysis.anatomicalRegion}

FINDINGS:
${analysis.observations
  .map(
    (obs, i) => `${i + 1}. ${obs.finding}
   Location: ${obs.location}
   Characteristics: ${obs.characteristics}
   Significance: ${obs.significance.toUpperCase()}`
  )
  .join('\n\n')}

${
  analysis.measurements && analysis.measurements.length > 0
    ? `MEASUREMENTS:
${analysis.measurements.map(m => `- ${m.structure}: ${m.measurement} ${m.unit}`).join('\n')}`
    : ''
}

RECOMMENDATIONS:
${analysis.recommendations.map((r, i) => `${i + 1}. ${r}`).join('\n')}

ANALYSIS CONFIDENCE: ${analysis.confidence}%

${analysis.disclaimer}

---
AI Assistant Note: This report requires review and signature by a licensed radiologist.
Date Generated: ${new Date().toISOString()}
`
  }
}

// Example usage
async function medicalImagingExample() {
  const assistant = new MedicalImagingAssistant(process.env.ANTHROPIC_API_KEY!)

  // Analyze chest X-ray
  const analysis = await assistant.analyzeMedicalImage(
    './chest-xray.jpg',
    'Chest X-Ray',
    'Patient presents with persistent cough for 2 weeks'
  )

  console.log('Image Type:', analysis.imageType)
  console.log('Region:', analysis.anatomicalRegion)
  console.log('\nFindings:')
  analysis.observations.forEach((obs, i) => {
    console.log(`${i + 1}. ${obs.finding}`)
    console.log(`   Significance: ${obs.significance}`)
  })

  console.log('\nRecommendations:')
  analysis.recommendations.forEach((r, i) => {
    console.log(`${i + 1}. ${r}`)
  })

  console.log('\nConfidence:', analysis.confidence, '%')
  console.log('\n' + analysis.disclaimer)

  // Generate report
  const report = await assistant.generateReportTemplate(analysis)
  console.log('\n=== DRAFT REPORT ===\n')
  console.log(report)

  // Compare with prior
  const comparison = await assistant.compareWithPrior(
    './chest-xray-current.jpg',
    './chest-xray-6mo-prior.jpg',
    'Chest X-Ray'
  )

  console.log('\n=== PROGRESSION ANALYSIS ===')
  console.log('Changes Detected:')
  comparison.changes.forEach(change => {
    console.log(`- ${change.finding} (${change.changeType})`)
    console.log(`  ${change.significance}`)
  })
  console.log('\nOverall:', comparison.overallAssessment)
}
```

## Architecture Patterns for Multimodal Apps

### Pattern 1: Pipeline Architecture

```typescript
/**
 * Pipeline pattern for sequential multimodal processing
 */
interface PipelineStage<TInput, TOutput> {
  name: string
  process: (input: TInput) => Promise<TOutput>
}

class MultimodalPipeline<TInput, TOutput> {
  private stages: PipelineStage<any, any>[] = []

  addStage<TStageInput, TStageOutput>(
    stage: PipelineStage<TStageInput, TStageOutput>
  ): this {
    this.stages.push(stage)
    return this
  }

  async execute(input: TInput): Promise<TOutput> {
    let result: any = input

    for (const stage of this.stages) {
      console.log(`Executing stage: ${stage.name}`)
      const stageStart = Date.now()

      result = await stage.process(result)

      const stageDuration = Date.now() - stageStart
      console.log(`  Completed in ${stageDuration}ms`)
    }

    return result as TOutput
  }
}

// Example: Document processing pipeline
interface DocumentInput {
  imagePath: string
  metadata?: Record<string, any>
}

interface ClassifiedDocument extends DocumentInput {
  documentType: string
}

interface ExtractedDocument extends ClassifiedDocument {
  extractedData: any
}

interface ValidatedDocument extends ExtractedDocument {
  validated: boolean
  confidence: number
  errors: string[]
}

async function documentPipelineExample() {
  const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY! })

  const pipeline = new MultimodalPipeline<DocumentInput, ValidatedDocument>()

  // Stage 1: Classification
  pipeline.addStage<DocumentInput, ClassifiedDocument>({
    name: 'Document Classification',
    process: async (input) => {
      const imageData = fs.readFileSync(input.imagePath).toString('base64')
      const response = await client.messages.create({
        model: 'claude-3-5-sonnet-20250129',
        max_tokens: 128,
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'image',
                source: {
                  type: 'base64',
                  media_type: 'image/jpeg',
                  data: imageData,
                },
              },
              {
                type: 'text',
                text: 'Classify: receipt, invoice, form, id, contract, other',
              },
            ],
          },
        ],
      })

      return {
        ...input,
        documentType: response.content[0].text.trim(),
      }
    },
  })

  // Stage 2: Extraction
  pipeline.addStage<ClassifiedDocument, ExtractedDocument>({
    name: 'Data Extraction',
    process: async (input) => {
      const imageData = fs.readFileSync(input.imagePath).toString('base64')
      const response = await client.messages.create({
        model: 'claude-3-5-sonnet-20250129',
        max_tokens: 2048,
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'image',
                source: {
                  type: 'base64',
                  media_type: 'image/jpeg',
                  data: imageData,
                },
              },
              {
                type: 'text',
                text: `Extract data from this ${input.documentType}. Return JSON.`,
              },
            ],
          },
        ],
      })

      let extractedData
      try {
        extractedData = JSON.parse(response.content[0].text)
      } catch (error) {
        console.error('Failed to parse extraction response:', error)
        extractedData = { error: 'Invalid JSON response', raw: response.content[0].text }
      }

      return {
        ...input,
        extractedData,
      }
    },
  })

  // Stage 3: Validation
  pipeline.addStage<ExtractedDocument, ValidatedDocument>({
    name: 'Data Validation',
    process: async (input) => {
      const errors: string[] = []
      let confidence = 100

      // Check for nulls
      const checkNulls = (obj: any, path = '') => {
        for (const key in obj) {
          const value = obj[key]
          const currentPath = path ? `${path}.${key}` : key

          if (value === null || value === undefined) {
            errors.push(`Missing value at ${currentPath}`)
            confidence -= 10
          } else if (typeof value === 'object' && value !== null) {
            checkNulls(value, currentPath)
          }
        }
      }

      checkNulls(input.extractedData)

      return {
        ...input,
        validated: errors.length === 0,
        confidence: Math.max(0, confidence),
        errors,
      }
    },
  })

  // Execute pipeline
  const result = await pipeline.execute({
    imagePath: './document.jpg',
    metadata: { source: 'user-upload' },
  })

  console.log('Final result:', result)
}
```

### Pattern 2: Event-Driven Architecture

```typescript
/**
 * Event-driven pattern for asynchronous multimodal processing
 */
type EventType =
  | 'image.uploaded'
  | 'image.analyzed'
  | 'data.extracted'
  | 'processing.completed'
  | 'processing.failed'

interface Event {
  type: EventType
  timestamp: Date
  data: any
}

type EventHandler = (event: Event) => Promise<void>

class EventDrivenMultimodalSystem {
  private handlers: Map<EventType, EventHandler[]> = new Map()
  private eventLog: Event[] = []

  on(eventType: EventType, handler: EventHandler): void {
    if (!this.handlers.has(eventType)) {
      this.handlers.set(eventType, [])
    }
    this.handlers.get(eventType)!.push(handler)
  }

  async emit(event: Event): Promise<void> {
    this.eventLog.push(event)
    console.log(`Event: ${event.type}`)

    const handlers = this.handlers.get(event.type) || []
    await Promise.all(handlers.map(handler => handler(event)))
  }

  getEventLog(): Event[] {
    return this.eventLog
  }
}

// Example usage
async function eventDrivenExample() {
  const system = new EventDrivenMultimodalSystem()
  const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY! })

  // Register handlers
  system.on('image.uploaded', async (event) => {
    console.log('Processing uploaded image:', event.data.imagePath)

    const imageData = fs.readFileSync(event.data.imagePath).toString('base64')
    const response = await client.messages.create({
      model: 'claude-3-5-sonnet-20250129',
      max_tokens: 1024,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: 'image/jpeg',
                data: imageData,
              },
            },
            {
              type: 'text',
              text: 'Analyze this image and extract key information as JSON.',
            },
          ],
        },
      ],
    })

    await system.emit({
      type: 'image.analyzed',
      timestamp: new Date(),
      data: {
        imagePath: event.data.imagePath,
        analysis: response.content[0].text,
      },
    })
  })

  system.on('image.analyzed', async (event) => {
    console.log('Extracting structured data...')

    try {
      const extractedData = JSON.parse(event.data.analysis)

      await system.emit({
        type: 'data.extracted',
        timestamp: new Date(),
        data: {
          imagePath: event.data.imagePath,
          extractedData,
        },
      })
    } catch (error) {
      console.error('Failed to parse JSON response:', error)
      await system.emit({
        type: 'processing.failed',
        timestamp: new Date(),
        data: {
          imagePath: event.data.imagePath,
          error: 'Failed to parse analysis',
          raw: event.data.analysis,
        },
      })
    }
  })

  system.on('data.extracted', async (event) => {
    console.log('Data extracted successfully')
    console.log('Extracted:', event.data.extractedData)

    await system.emit({
      type: 'processing.completed',
      timestamp: new Date(),
      data: event.data,
    })
  })

  system.on('processing.failed', async (event) => {
    console.error('Processing failed:', event.data.error)
    // Could trigger retry logic, notifications, etc.
  })

  system.on('processing.completed', async (event) => {
    console.log('✓ Processing completed for:', event.data.imagePath)
    // Could trigger storage, notifications, etc.
  })

  // Trigger processing
  await system.emit({
    type: 'image.uploaded',
    timestamp: new Date(),
    data: { imagePath: './test-image.jpg' },
  })
}
```

## Production Considerations

### 1. Performance Optimization

```typescript
/**
 * Image optimization before API calls
 */
import sharp from 'sharp'

async function optimizeImage(
  imagePath: string,
  maxWidth: number = 1920,
  maxHeight: number = 1920,
  quality: number = 85
): Promise<string> {
  const optimizedPath = imagePath.replace(/\.(jpg|jpeg|png)$/, '-optimized.$1')

  await sharp(imagePath)
    .resize(maxWidth, maxHeight, {
      fit: 'inside',
      withoutEnlargement: true,
    })
    .jpeg({ quality })
    .toFile(optimizedPath)

  return optimizedPath
}

// Example usage
async function optimizedAnalysis(imagePath: string) {
  const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY! })

  // Optimize before sending
  const optimizedPath = await optimizeImage(imagePath)

  const imageData = fs.readFileSync(optimizedPath).toString('base64')

  const response = await client.messages.create({
    model: 'claude-3-5-sonnet-20250129',
    max_tokens: 1024,
    messages: [
      {
        role: 'user',
        content: [
          {
            type: 'image',
            source: {
              type: 'base64',
              media_type: 'image/jpeg',
              data: imageData,
            },
          },
          {
            type: 'text',
            text: 'Analyze this image.',
          },
        ],
      },
    ],
  })

  // Cleanup
  fs.unlinkSync(optimizedPath)

  return response.content[0].text
}
```

### 2. Error Handling & Retry Logic

```typescript
/**
 * Robust error handling for production
 */
class MultimodalErrorHandler {
  static async withRetry<T>(
    operation: () => Promise<T>,
    maxRetries: number = 3,
    backoffMs: number = 1000
  ): Promise<T> {
    let lastError: Error | null = null

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        return await operation()
      } catch (error: any) {
        lastError = error
        console.error(`Attempt ${attempt} failed:`, error.message)

        // Don't retry on client errors (400s)
        if (error.status && error.status >= 400 && error.status < 500) {
          throw error
        }

        if (attempt < maxRetries) {
          const delay = backoffMs * Math.pow(2, attempt - 1)
          console.log(`Retrying in ${delay}ms...`)
          await new Promise(resolve => setTimeout(resolve, delay))
        }
      }
    }

    throw new Error(
      `Operation failed after ${maxRetries} attempts: ${lastError?.message}`
    )
  }

  static async withTimeout<T>(
    operation: () => Promise<T>,
    timeoutMs: number = 30000
  ): Promise<T> {
    return Promise.race([
      operation(),
      new Promise<T>((_, reject) =>
        setTimeout(() => reject(new Error('Operation timed out')), timeoutMs)
      ),
    ])
  }
}

// Example usage
async function robustImageAnalysis(imagePath: string): Promise<string> {
  return MultimodalErrorHandler.withRetry(
    async () =>
      MultimodalErrorHandler.withTimeout(async () => {
        const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY! })
        const imageData = fs.readFileSync(imagePath).toString('base64')

        const response = await client.messages.create({
          model: 'claude-3-5-sonnet-20250129',
          max_tokens: 1024,
          messages: [
            {
              role: 'user',
              content: [
                {
                  type: 'image',
                  source: {
                    type: 'base64',
                    media_type: 'image/jpeg',
                    data: imageData,
                  },
                },
                {
                  type: 'text',
                  text: 'Analyze this image.',
                },
              ],
            },
          ],
        })

        return response.content[0].text
      }, 30000),
    3
  )
}
```

### 3. Monitoring & Observability

```typescript
/**
 * Monitoring system for production multimodal apps
 */
interface Metrics {
  totalRequests: number
  successfulRequests: number
  failedRequests: number
  averageLatencyMs: number
  totalCost: number
  requestsByType: Record<string, number>
}

class MultimodalMonitoring {
  private metrics: Metrics = {
    totalRequests: 0,
    successfulRequests: 0,
    failedRequests: 0,
    averageLatencyMs: 0,
    totalCost: 0,
    requestsByType: {},
  }

  private latencies: number[] = []

  async trackRequest<T>(
    requestType: string,
    operation: () => Promise<T>,
    estimatedCost: number = 0
  ): Promise<T> {
    this.metrics.totalRequests++
    this.metrics.requestsByType[requestType] =
      (this.metrics.requestsByType[requestType] || 0) + 1

    const startTime = Date.now()

    try {
      const result = await operation()

      this.metrics.successfulRequests++
      this.metrics.totalCost += estimatedCost

      return result
    } catch (error) {
      this.metrics.failedRequests++
      throw error
    } finally {
      const latency = Date.now() - startTime
      this.latencies.push(latency)

      // Calculate rolling average
      this.metrics.averageLatencyMs =
        this.latencies.reduce((a, b) => a + b, 0) / this.latencies.length
    }
  }

  getMetrics(): Metrics {
    return { ...this.metrics }
  }

  getHealthStatus(): {
    status: 'healthy' | 'degraded' | 'unhealthy'
    details: any
  } {
    const errorRate =
      this.metrics.failedRequests / Math.max(this.metrics.totalRequests, 1)

    let status: 'healthy' | 'degraded' | 'unhealthy' = 'healthy'

    if (errorRate > 0.2) {
      status = 'unhealthy'
    } else if (errorRate > 0.05 || this.metrics.averageLatencyMs > 10000) {
      status = 'degraded'
    }

    return {
      status,
      details: {
        errorRate: `${(errorRate * 100).toFixed(2)}%`,
        averageLatency: `${this.metrics.averageLatencyMs.toFixed(0)}ms`,
        totalRequests: this.metrics.totalRequests,
        estimatedCost: `$${this.metrics.totalCost.toFixed(4)}`,
      },
    }
  }
}

// Example usage
async function monitoredApplication() {
  const monitor = new MultimodalMonitoring()
  const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY! })

  // Tracked request
  const result = await monitor.trackRequest(
    'product-analysis',
    async () => {
      const imageData = fs.readFileSync('./product.jpg').toString('base64')
      const response = await client.messages.create({
        model: 'claude-3-5-sonnet-20250129',
        max_tokens: 1024,
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'image',
                source: {
                  type: 'base64',
                  media_type: 'image/jpeg',
                  data: imageData,
                },
              },
              {
                type: 'text',
                text: 'Analyze product.',
              },
            ],
          },
        ],
      })
      return response.content[0].text
    },
    0.015 // Estimated cost
  )

  // Check health
  const health = monitor.getHealthStatus()
  console.log('System Health:', health.status)
  console.log('Details:', health.details)

  // Get metrics
  const metrics = monitor.getMetrics()
  console.log('Metrics:', metrics)
}
```

## Summary and Key Takeaways

### Production Application Patterns

1. **Visual Q&A Systems**: Conversational interfaces with context and memory
2. **Document Intelligence**: End-to-end OCR and data extraction pipelines
3. **Product Catalogs**: Automated listing generation and enrichment
4. **Accessibility**: Alt text and descriptive content generation
5. **Content Moderation**: Policy-based image filtering and safety
6. **Medical Imaging**: Analysis assistance with proper disclaimers

### Architecture Best Practices

- **Pipeline Pattern**: Sequential processing with clear stages
- **Event-Driven**: Asynchronous, scalable processing
- **Error Handling**: Retries, timeouts, graceful degradation
- **Monitoring**: Track metrics, costs, and system health
- **Caching**: Redis/memory caching for duplicate requests
- **Optimization**: Image compression before API calls

### Production Checklist

- [ ] Implement retry logic with exponential backoff
- [ ] Add request timeouts (30s recommended)
- [ ] Set up monitoring and alerting
- [ ] Implement rate limiting
- [ ] Cache frequently analyzed images
- [ ] Optimize images before processing
- [ ] Validate all extracted data
- [ ] Handle edge cases gracefully
- [ ] Track costs and usage
- [ ] Add human review workflows
- [ ] Implement proper error logging
- [ ] Set up health check endpoints

### Performance Optimization

1. **Image optimization**: Resize and compress before API calls
2. **Caching**: Cache results for duplicate images/prompts
3. **Batch processing**: Process multiple images efficiently
4. **Concurrent requests**: Use Promise.all with rate limiting
5. **CDN usage**: Serve images from CDN when possible

### Security & Privacy

- Never log sensitive image content
- Implement proper access controls
- Encrypt images in transit and at rest
- Follow data retention policies
- Add watermarking for tracking
- Implement audit logs

## Practice Exercises

Build these production applications to master multimodal AI:

1. **Document Processing Service**: Build a complete document intelligence API with classification, extraction, validation, and review workflows

2. **E-commerce Catalog Builder**: Create an automated system that enriches product listings from images with SEO optimization

3. **Accessibility Platform**: Build a service that generates alt text, long descriptions, and ARIA labels for web images

4. **Content Moderation Dashboard**: Create a moderation system with custom policies, batch processing, and review queues

5. **Visual Search Engine**: Build a reverse image search using vision analysis and semantic matching

6. **Quality Inspection System**: Create a manufacturing quality control system that detects defects from images

Remember: Production multimodal applications require robust error handling, monitoring, optimization, and human oversight. Always design for scale, reliability, and cost efficiency from day one.
