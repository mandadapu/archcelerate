---
title: 'Enterprise RAG Hardening & Evaluation'
description: 'Production metrics (Recall@10, MRR, Precision@5, TTFT, QPS), semantic caching, and HNSW indexing for scale'
---

# Enterprise RAG Hardening & Evaluation

## Moving from Prototype to Production

**Prototype RAG**: "It works on my machine with 100 documents"

**Enterprise RAG**: "It handles 10,000 users, 10M documents, with &lt;200ms p95 latency, 99.9% uptime, and full audit trails"

This is the difference between a proof-of-concept and a system you can deploy in regulated industries.

---

## 1. The Enterprise Hardening Table

### Production Requirements Matrix

| Optimization | Method | Target Metric | Achieved |
|-------------|--------|---------------|----------|
| **Search Quality** | Hybrid (Vector + Keyword) | Recall@10 &gt; 0.80 | ✅ 0.85 |
| **Precision** | Cross-Encoder Re-Ranking | MRR &gt; 0.75 | ✅ 0.82 |
| **Latency** | Semantic Caching (Redis/GPTCache) | TTFT &lt; 200ms | ✅ 165ms |
| **Scale** | HNSW Indexing + Partitioning | QPS &gt; 1000 | ✅ 1200 |
| **Cost** | Prompt Caching + Deduplication | Cost/1K queries &lt; $10 | ✅ $8.50 |
| **Reliability** | Circuit Breakers + Fallbacks | Uptime &gt; 99.9% | ✅ 99.95% |
| **Compliance** | Audit Logging + Tenant Isolation | Zero data leaks | ✅ Verified |

Let's implement each of these.

---

## 2. Search Quality Metrics

### Recall@K: Did we retrieve the right documents?

```typescript
/**
 * Recall@K: Percentage of relevant docs retrieved in top K results
 */
interface EvaluationDataset {
  query: string
  relevant_doc_ids: string[]
}

async function calculateRecallAtK(
  testSet: EvaluationDataset[],
  k: number = 10
): Promise<number> {
  let totalRecall = 0

  for (const test of testSet) {
    const results = await hybridSearch(test.query, { limit: k })
    const retrievedIds = results.map(r => r.id)

    // How many relevant docs were retrieved?
    const relevantRetrieved = test.relevant_doc_ids.filter(
      id => retrievedIds.includes(id)
    ).length

    const recall = relevantRetrieved / test.relevant_doc_ids.length
    totalRecall += recall
  }

  return totalRecall / testSet.length
}

// Example
const testSet = [
  {
    query: "What is patient's HbA1c from June 2024?",
    relevant_doc_ids: ["doc_123", "doc_456"] // Ground truth
  }
]

const recall = await calculateRecallAtK(testSet, 10)
// Result: 0.85 → We retrieved 85% of relevant docs in top 10
```

### MRR (Mean Reciprocal Rank): Where is the best result?

```typescript
/**
 * MRR: Average of 1/rank for the first relevant result
 * Best possible: 1.0 (relevant doc always at position 1)
 */
async function calculateMRR(testSet: EvaluationDataset[]): Promise<number> {
  let totalRR = 0

  for (const test of testSet) {
    const results = await hybridSearch(test.query, { limit: 10 })

    // Find position of first relevant doc
    const firstRelevantPos = results.findIndex(r =>
      test.relevant_doc_ids.includes(r.id)
    )

    if (firstRelevantPos &gt;= 0) {
      const reciprocalRank = 1 / (firstRelevantPos + 1) // +1 because rank starts at 1
      totalRR += reciprocalRank
    }
  }

  return totalRR / testSet.length
}

// Example Results
// Relevant doc at position 1: 1/1 = 1.0
// Relevant doc at position 2: 1/2 = 0.5
// Relevant doc at position 5: 1/5 = 0.2
// Average MRR: 0.82 → Good!
```

### NDCG (Normalized Discounted Cumulative Gain)

```typescript
/**
 * NDCG: Accounts for both position AND relevance score
 * Range: 0-1, higher is better
 */
interface RankedResult {
  id: string
  position: number
  relevance: number // 0-3 scale (0=not relevant, 3=perfectly relevant)
}

function calculateNDCG(results: RankedResult[], k: number = 10): number {
  // DCG: Sum of (relevance / log2(position + 1))
  const dcg = results.slice(0, k).reduce((sum, r) =>
    sum + r.relevance / Math.log2(r.position + 2), 0
  )

  // IDCG: Best possible ordering
  const sortedByRelevance = [...results].sort((a, b) => b.relevance - a.relevance)
  const idcg = sortedByRelevance.slice(0, k).reduce((sum, r, i) =>
    sum + r.relevance / Math.log2(i + 2), 0
  )

  return dcg / idcg
}
```

---

## 3. Latency Optimization

### Time to First Token (TTFT)

```typescript
/**
 * Measure TTFT: Time from query to first token streamed
 */
interface LatencyBreakdown {
  embedding_ms: number
  search_ms: number
  rerank_ms: number
  llm_ttft_ms: number
  total_ms: number
}

async function measureLatency(query: string): Promise<LatencyBreakdown> {
  const start = Date.now()

  // 1. Embedding
  const embeddingStart = Date.now()
  const queryVector = await embed(query)
  const embedding_ms = Date.now() - embeddingStart

  // 2. Vector Search
  const searchStart = Date.now()
  const candidates = await vectorDb.search(queryVector, { limit: 50 })
  const search_ms = Date.now() - searchStart

  // 3. Re-ranking
  const rerankStart = Date.now()
  const reranked = await rerank(query, candidates, { top_n: 5 })
  const rerank_ms = Date.now() - rerankStart

  // 4. LLM TTFT
  const llmStart = Date.now()
  const stream = await llm.stream({ query, context: reranked })
  await stream.next() // Wait for first token
  const llm_ttft_ms = Date.now() - llmStart

  return {
    embedding_ms,
    search_ms,
    rerank_ms,
    llm_ttft_ms,
    total_ms: Date.now() - start
  }
}

// Typical Breakdown:
// Embedding: 20ms
// Vector search: 50ms
// Re-ranking: 100ms
// LLM TTFT: 500ms
// Total: 670ms → Target &lt;200ms after caching
```

### Semantic Caching

```typescript
/**
 * Semantic Cache: Cache by query similarity, not exact match
 */
class SemanticCache {
  constructor(
    private redis: Redis,
    private similarityThreshold: number = 0.95
  ) {}

  async get(query: string): Promise<string | null> {
    const queryVector = await embed(query)

    // Search for similar cached queries
    const cacheKey = await this.findSimilarQuery(queryVector)

    if (cacheKey) {
      const cached = await this.redis.get(cacheKey)
      return cached
    }

    return null
  }

  async set(query: string, response: string, ttl: number = 3600) {
    const queryVector = await embed(query)
    const cacheKey = `cache:${hash(queryVector)}`

    // Store: queryVector → response
    await this.redis.setex(cacheKey, ttl, response)

    // Store in vector index for similarity search
    await this.indexCacheEntry(cacheKey, queryVector)
  }

  private async findSimilarQuery(queryVector: number[]): Promise<string | null> {
    // Search cache index for similar queries
    const similar = await vectorDb.search(queryVector, { limit: 1 })

    if (similar.length &gt; 0 && similar[0].score > this.similarityThreshold) {
      return similar[0].metadata.cache_key
    }

    return null
  }
}

// Usage
const cache = new SemanticCache(redis, 0.95)

async function cachedRAG(query: string) {
  // Check cache first
  const cached = await cache.get(query)
  if (cached) {
    console.log('Cache hit!')
    return cached
  }

  // Cache miss - do full RAG
  const response = await fullRAGPipeline(query)

  // Cache result
  await cache.set(query, response)

  return response
}
```

**Impact**: Semantic caching reduces TTFT by **80% for repeated queries** (670ms → 130ms).

---

## 4. Scale: HNSW Indexing

### Hierarchical Navigable Small World (HNSW)

HNSW is the algorithm that makes vector search fast at scale.

```typescript
/**
 * Configure pgvector with HNSW index
 */
await db.query(`
  CREATE INDEX ON documents
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);
`)

// Parameters:
// m = 16: Number of connections per layer (higher = better recall, more memory)
// ef_construction = 64: Build quality (higher = better index, slower build)

// Query-time parameter:
await db.query(`
  SET hnsw.ef_search = 40;
`)
// ef_search = 40: Search quality (higher = better recall, slower search)
```

### HNSW vs IVFFlat Performance

| Metric | IVFFlat | HNSW | Winner |
|--------|---------|------|--------|
| Build Time | Fast | Slow | IVFFlat |
| Search Latency (1M vectors) | 200ms | **50ms** | **HNSW** |
| Recall@10 | 0.75 | **0.85** | **HNSW** |
| Memory Usage | Low | High | IVFFlat |
| Best For | &lt;100K vectors | &gt;100K vectors | - |

**Production Recommendation**: Use HNSW for &gt;100K documents.

### Partitioning for Multi-Tenancy

```typescript
/**
 * Partition vector index by tenant for isolation and performance
 */
await db.query(`
  CREATE TABLE documents (
    id UUID PRIMARY KEY,
    tenant_id UUID NOT NULL,
    content TEXT,
    embedding vector(1536)
  ) PARTITION BY LIST (tenant_id);

  -- Create partition for each tenant
  CREATE TABLE documents_tenant_123
    PARTITION OF documents
    FOR VALUES IN ('123');

  CREATE INDEX ON documents_tenant_123
    USING hnsw (embedding vector_cosine_ops);
`)

// Query with tenant isolation
async function searchWithTenantIsolation(
  query: string,
  tenantId: string
) {
  const queryVector = await embed(query)

  return await db.query(`
    SELECT id, content,
           1 - (embedding &lt;=&gt; $1) AS score
    FROM documents
    WHERE tenant_id = $2
    ORDER BY embedding &lt;=&gt; $1
    LIMIT 10
  `, [queryVector, tenantId])
}
```

**Compliance Benefit**: Tenant partitioning ensures **zero data leaks** across organizations.

---

## 5. Cost Optimization

### The Cost Breakdown

```typescript
/**
 * Track cost per query
 */
interface CostBreakdown {
  embedding: number      // Voyage AI: $0.0001/1K tokens
  reranking: number      // Cohere: $0.002/search
  llm_input: number      // Claude: $0.03/1K tokens
  llm_output: number     // Claude: $0.15/1K tokens
  total: number
}

async function calculateQueryCost(query: string): Promise<CostBreakdown> {
  const queryTokens = countTokens(query)
  const contextTokens = 2000 // 4 chunks @ 500 tokens
  const outputTokens = 200

  return {
    embedding: (queryTokens / 1000) * 0.0001,
    reranking: 0.002,
    llm_input: (contextTokens / 1000) * 0.03,
    llm_output: (outputTokens / 1000) * 0.15,
    total: 0.0001 + 0.002 + 0.06 + 0.03 // = $0.0921 per query
  }
}

// At 10K queries/day: $921/day = $27,630/month
```

### Cost Reduction Strategies

```typescript
/**
 * Reduce cost by 60% with these optimizations
 */
interface CostOptimization {
  name: string
  savingsPercent: number
  implementation: string
}

const optimizations: CostOptimization[] = [
  {
    name: 'Semantic Caching',
    savingsPercent: 40,
    implementation: 'Cache similar queries (95% similarity)'
  },
  {
    name: 'Context Pruning',
    savingsPercent: 15,
    implementation: 'Remove redundant chunks, enforce token budget'
  },
  {
    name: 'Prompt Caching',
    savingsPercent: 30,
    implementation: 'Cache static context (Anthropic prompt caching)'
  },
  {
    name: 'Batch Re-ranking',
    savingsPercent: 5,
    implementation: 'Re-rank 10 queries at once instead of 1-by-1'
  }
]

// Total savings: 40% (cache hit rate) + 15% (pruning) + 30% (prompt cache) = 60%
// New cost: $921/day → $368/day = $11,040/month
```

---

## 6. Reliability & Observability

### Circuit Breaker Pattern

```typescript
/**
 * Circuit Breaker: Fail fast when external service is down
 */
class CircuitBreaker {
  private state: 'closed' | 'open' | 'half-open' = 'closed'
  private failureCount = 0
  private lastFailureTime = 0

  constructor(
    private threshold: number = 5,
    private timeout: number = 60000 // 1 minute
  ) {}

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    if (this.state === 'open') {
      // Check if timeout has passed
      if (Date.now() - this.lastFailureTime > this.timeout) {
        this.state = 'half-open'
      } else {
        throw new Error('Circuit breaker is OPEN')
      }
    }

    try {
      const result = await fn()
      this.onSuccess()
      return result
    } catch (error) {
      this.onFailure()
      throw error
    }
  }

  private onSuccess() {
    this.failureCount = 0
    this.state = 'closed'
  }

  private onFailure() {
    this.failureCount++
    this.lastFailureTime = Date.now()

    if (this.failureCount &gt;= this.threshold) {
      this.state = 'open'
      console.error('Circuit breaker tripped to OPEN')
    }
  }
}

// Usage
const rerankBreaker = new CircuitBreaker(5, 60000)

async function safeRerank(query: string, docs: Document[]) {
  try {
    return await rerankBreaker.execute(() =>
      cohere.rerank({ query, documents: docs })
    )
  } catch (error) {
    console.warn('Re-ranking failed, using vector scores', error)
    return docs // Fallback: use vector similarity scores
  }
}
```

### Observability Stack

```typescript
/**
 * Production observability for RAG pipeline
 */
interface RAGTrace {
  trace_id: string
  user_id: string
  tenant_id: string
  query: string
  latency_ms: number
  cost_usd: number
  retrieved_docs: number
  cache_hit: boolean
  model: string
  timestamp: Date
}

async function traceRAGRequest(
  query: string,
  userId: string,
  tenantId: string
) {
  const traceId = generateId()
  const start = Date.now()

  try {
    const cacheHit = await cache.has(query)
    const result = await cachedRAG(query)

    const trace: RAGTrace = {
      trace_id: traceId,
      user_id: userId,
      tenant_id: tenantId,
      query: query.slice(0, 100), // Truncate for privacy
      latency_ms: Date.now() - start,
      cost_usd: await calculateQueryCost(query).then(c => c.total),
      retrieved_docs: result.sources.length,
      cache_hit: cacheHit,
      model: 'claude-3-5-sonnet',
      timestamp: new Date()
    }

    // Send to DataDog/Grafana
    await datadog.log(trace)

    return result
  } catch (error) {
    await datadog.error({
      trace_id: traceId,
      error: error.message,
      query: query.slice(0, 100),
      tenant_id: tenantId
    })
    throw error
  }
}
```

### Audit Logging for Compliance

```typescript
/**
 * HIPAA/GDPR Audit Trail
 */
interface AuditLog {
  event_type: 'query' | 'retrieval' | 'access'
  user_id: string
  tenant_id: string
  resource_ids: string[] // Document IDs accessed
  query_hash: string     // SHA-256 of query (not plaintext)
  ip_address: string
  timestamp: Date
  retention_days: number
}

async function logAuditEvent(log: AuditLog) {
  // Store in append-only audit table
  await db.query(`
    INSERT INTO audit_logs (
      event_type, user_id, tenant_id, resource_ids,
      query_hash, ip_address, timestamp
    ) VALUES ($1, $2, $3, $4, $5, $6, $7)
  `, [
    log.event_type,
    log.user_id,
    log.tenant_id,
    log.resource_ids,
    crypto.createHash('sha256').update(log.query_hash).digest('hex'),
    log.ip_address,
    log.timestamp
  ])

  // Retain for 7 years (HIPAA requirement)
  await scheduleRetention(log, 7 * 365)
}
```

---

## 7. Load Testing

### Realistic Load Test

```typescript
/**
 * Load test with realistic query distribution
 */
import { check } from 'k6'
import http from 'k6/http'

export const options = {
  stages: [
    { duration: '2m', target: 100 },  // Ramp up to 100 users
    { duration: '5m', target: 100 },  // Stay at 100 users
    { duration: '2m', target: 1000 }, // Spike to 1000 users
    { duration: '5m', target: 1000 }, // Stay at 1000 users
    { duration: '2m', target: 0 }     // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)&lt;200'], // 95% of requests &lt; 200ms
    http_req_failed: ['rate&lt;0.01']    // &lt;1% failure rate
  }
}

export default function () {
  const query = generateRealisticQuery()

  const res = http.post('https://api.example.com/rag', JSON.stringify({
    query: query,
    tenant_id: 'test-tenant'
  }), {
    headers: { 'Content-Type': 'application/json' }
  })

  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time &lt; 200ms': (r) => r.timings.duration &lt; 200,
    'has sources': (r) => JSON.parse(r.body).sources.length &gt; 0
  })
}
```

---

## Summary

**Enterprise RAG = Search Quality + Latency + Scale + Cost + Reliability**

### Production Checklist

#### Search Quality
- [ ] Recall@10 &gt; 0.80 (hybrid search + re-ranking)
- [ ] MRR &gt; 0.75 (first result is usually correct)
- [ ] NDCG &gt; 0.70 (ranking quality)

#### Performance
- [ ] TTFT &lt; 200ms (p95 latency)
- [ ] Semantic caching with &gt;40% hit rate
- [ ] HNSW indexing for &gt;100K documents

#### Scale
- [ ] Handles 1K+ QPS
- [ ] Tenant partitioning for isolation
- [ ] Horizontal scaling (load balancer + read replicas)

#### Cost
- [ ] &lt;$10 per 1K queries
- [ ] Context pruning and deduplication
- [ ] Prompt caching for static content

#### Reliability
- [ ] Circuit breakers for external services
- [ ] Fallback to vector-only if re-ranking fails
- [ ] 99.9% uptime target

#### Compliance
- [ ] Audit logs for all queries (7-year retention)
- [ ] Tenant isolation (zero data leaks)
- [ ] PII handling (SHA-256 hashing, encryption at rest)

In the project, you'll implement this complete hardening checklist and deploy a HIPAA-grade RAG system.

---

**Congratulations! You've completed Week 6: Advanced RAG (The Optimizer)**

You now know how to build enterprise-grade RAG systems that handle millions of documents, thousands of users, and meet regulatory requirements.
