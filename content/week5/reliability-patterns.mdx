---
title: "Reliability Patterns: Self-Reflection and HITL"
week: 5
concept: 3
description: "Hardening non-deterministic agentic systems with self-critique loops and human approval gates for enterprise deployment"
estimatedMinutes: 50
objectives:
  - Engineer self-reflection loops where agents critique their own work
  - Implement Human-in-the-Loop interrupt points for high-stakes actions
  - Build automated quality gates with validation criteria
---

# Reliability Patterns

Hardening non-deterministic systems for the enterprise.

## The Core Problem

**Agents are non-deterministic**: Same input can produce different outputs. In production, this means:

1. **Quality variance**: Agent produces excellent output 90% of the time, garbage 10%
2. **High-stakes errors**: Agent approves a $10K refund when it should have escalated
3. **No audit trail**: When agent makes a mistake, you can't explain why

**Architect's Challenge**: How do you deploy systems that **sometimes make mistakes** to production?

**Solution**: Build reliability patterns that catch errors before they cause damage.

---

## Pattern 1: Self-Reflection (Agent as its Own Critic)

**The Pattern**: Force the agent to critique its own work **before** submitting. If critique identifies issues, agent revises.

**Why It Works**: LLMs are better at **evaluating** than **generating**. Reflection catches lazy outputs, factual errors, and incomplete reasoning.

### Self-Reflection Architecture

```typescript
import Anthropic from '@anthropic-ai/sdk'

const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })

interface ReflectionCriteria {
  dimension: string        // "Accuracy", "Completeness", "Safety"
  question: string         // "Does this answer cite verifiable sources?"
  threshold: number        // 0-10 scale, minimum score to pass
}

interface ReflectionResult {
  initialOutput: string
  critique: {
    dimension: string
    score: number          // 0-10
    issues: string[]
    passedThreshold: boolean
  }[]
  revisedOutput: string | null
  finalQuality: 'approved' | 'needs_human_review'
}

async function reflectiveAgent(
  task: string,
  criteria: ReflectionCriteria[],
  maxRevisions: number = 2
): Promise<ReflectionResult> {
  let currentOutput: string
  let attempt = 0
  const result: ReflectionResult = {
    initialOutput: '',
    critique: [],
    revisedOutput: null,
    finalQuality: 'needs_human_review'
  }

  // Step 1: Generate initial output
  console.log('ü§ñ Generating initial output...')
  const initialResponse = await anthropic.messages.create({
    model: 'claude-4.5-sonnet',
    max_tokens: 2048,
    messages: [{ role: 'user', content: task }]
  })

  currentOutput = initialResponse.content[0].text
  result.initialOutput = currentOutput

  // Step 2: Reflection loop
  while (attempt < maxRevisions) {
    attempt++
    console.log(`\nüîç Reflection attempt ${attempt}...`)

    // Critique current output
    const critiquePrompt = `You are a quality assurance reviewer. Evaluate this output against specific criteria.

Task: ${task}

Output to review:
${currentOutput}

Evaluate on these dimensions:
${criteria.map((c, i) => `${i + 1}. ${c.dimension}: ${c.question} (Score 0-10, must score ‚â•${c.threshold})`).join('\n')}

Output JSON:
{
  "critiques": [
    {
      "dimension": "Accuracy",
      "score": 8,
      "issues": ["Issue 1", "Issue 2"],
      "passedThreshold": true
    },
    ...
  ],
  "overallQuality": "approved" or "needs_revision"
}`

    const critiqueResponse = await anthropic.messages.create({
      model: 'claude-4.5-sonnet',
      max_tokens: 1500,
      messages: [{ role: 'user', content: critiquePrompt }]
    })

    const critiqueText = critiqueResponse.content[0].text
    const jsonMatch = critiqueText.match(/\{[\s\S]*\}/)
    if (!jsonMatch) throw new Error('Critique failed to generate valid JSON')

    const critique = JSON.parse(jsonMatch[0])
    result.critique = critique.critiques

    // Check if all criteria passed
    const allPassed = critique.critiques.every((c: any) => c.passedThreshold)

    if (allPassed || critique.overallQuality === 'approved') {
      result.finalQuality = 'approved'
      result.revisedOutput = attempt &gt; 1 ? currentOutput : null
      console.log('‚úÖ Quality approved')
      break
    }

    if (attempt &gt;= maxRevisions) {
      console.log('‚ùå Max revisions reached, escalating to human review')
      result.finalQuality = 'needs_human_review'
      break
    }

    // Step 3: Revise based on critique
    console.log('‚öôÔ∏è  Revising output based on critique...')
    const revisionPrompt = `Improve your previous output based on this critique:

Original Task: ${task}

Your Previous Output:
${currentOutput}

Critique:
${critique.critiques.map((c: any) =>
  `${c.dimension} (score: ${c.score}/${c.threshold} required):
Issues: ${c.issues.join(', ')}`
).join('\n\n')}

Provide revised output that addresses all issues.`

    const revisionResponse = await anthropic.messages.create({
      model: 'claude-4.5-sonnet',
      max_tokens: 2048,
      messages: [{ role: 'user', content: revisionPrompt }]
    })

    currentOutput = revisionResponse.content[0].text
  }

  return result
}

/* Example Usage:

Task: "Write a technical explanation of how vector databases work"

Criteria:
1. Accuracy: Does it cite verifiable technical facts? (threshold: 8/10)
2. Completeness: Does it cover indexing, search, and storage? (threshold: 7/10)
3. Clarity: Can a software engineer without ML background understand it? (threshold: 7/10)

Execution:
ü§ñ Generating initial output...
üîç Reflection attempt 1...
  - Accuracy: 9/10 ‚úÖ
  - Completeness: 5/10 ‚ùå (missing storage layer explanation)
  - Clarity: 8/10 ‚úÖ
‚öôÔ∏è  Revising output based on critique...
üîç Reflection attempt 2...
  - Accuracy: 9/10 ‚úÖ
  - Completeness: 8/10 ‚úÖ
  - Clarity: 8/10 ‚úÖ
‚úÖ Quality approved
*/
```

### Self-Reflection: Production Benefits

| Without Reflection | With Reflection |
|--------------------|-----------------|
| Agent outputs "I think X" | Agent provides sources: "According to [source], X" |
| Incomplete answers (misses 30% of requirements) | Comprehensive (critique ensures all aspects covered) |
| Inconsistent quality (60-100% accuracy) | Consistent quality (85-100% accuracy) |
| Single LLM call: $0.02 | 3 calls (generate + critique + revise): $0.09 |

**Cost Trade-off**: 4.5x cost increase, but **prevents 80% of quality issues** that would require human review ($50/hour).

---

## Pattern 2: Human-in-the-Loop (HITL)

**The Pattern**: For high-stakes actions (bank transfers, database writes, email sends), agent **pauses execution** and waits for human approval.

**Critical Principle**: **Agents propose, humans approve.**

### HITL Architecture

```typescript
interface HITLRequest {
  requestId: string
  timestamp: Date
  agentId: string
  action: {
    type: 'database_write' | 'api_call' | 'email_send' | 'financial_transaction'
    description: string
    parameters: Record<string, any>
    estimatedImpact: string
    reversible: boolean
  }
  status: 'pending' | 'approved' | 'rejected' | 'expired'
  humanReviewer?: string
  reviewedAt?: Date
  rejectionReason?: string
}

interface HITLConfig {
  requireApproval: (action: any) => boolean  // Which actions need HITL?
  timeout: number                             // Auto-reject after X ms
  notificationChannel: 'email' | 'slack' | 'dashboard'
}

class HITLGate {
  private pendingRequests: Map<string, HITLRequest> = new Map()

  constructor(private config: HITLConfig) {}

  async requestApproval(
    agentId: string,
    action: HITLRequest['action']
  ): Promise<'approved' | 'rejected' | 'timeout'> {
    const request: HITLRequest = {
      requestId: `hitl_${Date.now()}_${Math.random().toString(36).slice(2)}`,
      timestamp: new Date(),
      agentId,
      action,
      status: 'pending'
    }

    this.pendingRequests.set(request.requestId, request)

    console.log(`\n‚è∏Ô∏è  HITL: Agent ${agentId} requesting approval for ${action.type}`)
    console.log(`   Description: ${action.description}`)
    console.log(`   Impact: ${action.estimatedImpact}`)
    console.log(`   Reversible: ${action.reversible ? 'Yes' : 'No'}`)
    console.log(`   Request ID: ${request.requestId}\n`)

    // Send notification to human (mock)
    await this.notifyHuman(request)

    // Wait for human approval or timeout
    const result = await this.waitForApproval(request.requestId)

    return result
  }

  private async notifyHuman(request: HITLRequest): Promise<void> {
    // In production: Send to Slack, email, or dashboard
    if (this.config.notificationChannel === 'slack') {
      // await slackClient.post({
      //   channel: '#agent-approvals',
      //   text: `Agent ${request.agentId} requests approval for ${request.action.type}`,
      //   blocks: [...]
      // })
    }
  }

  private async waitForApproval(requestId: string): Promise<'approved' | 'rejected' | 'timeout'> {
    const startTime = Date.now()

    return new Promise((resolve) => {
      const checkInterval = setInterval(() => {
        const request = this.pendingRequests.get(requestId)
        if (!request) {
          clearInterval(checkInterval)
          resolve('rejected')
          return
        }

        // Check for timeout
        if (Date.now() - startTime > this.config.timeout) {
          request.status = 'expired'
          clearInterval(checkInterval)
          console.log('‚è±Ô∏è  HITL timeout: Auto-rejecting action')
          resolve('timeout')
          return
        }

        // Check if human approved/rejected
        if (request.status === 'approved') {
          clearInterval(checkInterval)
          console.log('‚úÖ HITL: Human approved action')
          resolve('approved')
        } else if (request.status === 'rejected') {
          clearInterval(checkInterval)
          console.log(`‚ùå HITL: Human rejected action. Reason: ${request.rejectionReason}`)
          resolve('rejected')
        }
      }, 1000)
    })
  }

  // Called by human reviewer (via API or dashboard)
  approveRequest(requestId: string, reviewerId: string): void {
    const request = this.pendingRequests.get(requestId)
    if (request && request.status === 'pending') {
      request.status = 'approved'
      request.humanReviewer = reviewerId
      request.reviewedAt = new Date()
    }
  }

  rejectRequest(requestId: string, reviewerId: string, reason: string): void {
    const request = this.pendingRequests.get(requestId)
    if (request && request.status === 'pending') {
      request.status = 'rejected'
      request.humanReviewer = reviewerId
      request.reviewedAt = new Date()
      request.rejectionReason = reason
    }
  }
}

// HITL Configuration
const hitlConfig: HITLConfig = {
  requireApproval: (action) => {
    // Define which actions require human approval
    const highStakes = [
      'database_write',
      'financial_transaction',
      'email_send'
    ]
    return highStakes.includes(action.type) || !action.reversible
  },
  timeout: 300000,  // 5 minutes
  notificationChannel: 'slack'
}

const hitlGate = new HITLGate(hitlConfig)

// Agent Workflow with HITL
async function agentWithHITL(userRequest: string): Promise<string> {
  // Agent processes request and determines action
  const action = {
    type: 'database_write' as const,
    description: 'Delete 1,500 user records older than 2 years (GDPR compliance)',
    parameters: {
      table: 'users',
      condition: 'created_at < NOW() - INTERVAL \'2 years\' AND gdpr_deletion_requested = true'
    },
    estimatedImpact: '1,500 records deleted (irreversible)',
    reversible: false
  }

  // Check if HITL is required
  if (hitlConfig.requireApproval(action)) {
    const approval = await hitlGate.requestApproval('agent_cleanup_001', action)

    if (approval === 'approved') {
      console.log('üöÄ Executing action...')
      // Execute the action (mock)
      return 'Action executed successfully'
    } else if (approval === 'rejected') {
      return 'Action rejected by human reviewer'
    } else {
      return 'Action timed out waiting for approval'
    }
  } else {
    // Low-stakes action, execute immediately
    console.log('üöÄ Executing low-stakes action without approval...')
    return 'Action executed'
  }
}

/* Example Execution:

‚è∏Ô∏è  HITL: Agent agent_cleanup_001 requesting approval for database_write
   Description: Delete 1,500 user records older than 2 years (GDPR compliance)
   Impact: 1,500 records deleted (irreversible)
   Reversible: No
   Request ID: hitl_1738790123456_abc123

[Slack notification sent to #agent-approvals]

... Human reviews in Slack, clicks "Approve" ...

‚úÖ HITL: Human approved action
üöÄ Executing action...
Action executed successfully
*/
```

### HITL Decision Matrix

| Action Type | Reversible? | Cost | Human Approval? |
|-------------|-------------|------|-----------------|
| Database read | N/A | Free | ‚ùå No |
| Send email to 1 user | Yes (send apology) | $0.01 | ‚ùå No (agent can proceed) |
| Send email to 10K users | No (reputation damage) | $100 | ‚úÖ Yes (HITL required) |
| Approve $50 refund | Yes (can reverse transaction) | $50 | ‚ùå No (set threshold at $100) |
| Approve $500 refund | Partially (dispute risk) | $500 | ‚úÖ Yes (above threshold) |
| Delete user data | No (GDPR violation if wrong) | $10K+ fine | ‚úÖ Yes (irreversible) |
| Deploy code to production | Yes (can rollback) | $0 | ‚úÖ Yes (high stakes) |

**Architect's Rule**: If action is **irreversible** OR **cost &gt; $100** OR **affects &gt;100 users**, require HITL.

---

## Pattern 3: Automated Quality Gates

**The Pattern**: Define **explicit validation criteria** that agent output must pass before proceeding to next step.

**Why It Works**: Prevents cascading failures where bad output from Agent A becomes bad input for Agent B.

### Quality Gate Architecture

```typescript
interface ValidationRule {
  name: string
  check: (output: string) => boolean | Promise<boolean>
  errorMessage: string
  severity: 'error' | 'warning'
}

interface QualityGateResult {
  passed: boolean
  violations: {
    rule: string
    severity: 'error' | 'warning'
    message: string
  }[]
}

class QualityGate {
  constructor(private rules: ValidationRule[]) {}

  async validate(output: string): Promise<QualityGateResult> {
    const violations: QualityGateResult['violations'] = []

    for (const rule of this.rules) {
      const passed = await rule.check(output)
      if (!passed) {
        violations.push({
          rule: rule.name,
          severity: rule.severity,
          message: rule.errorMessage
        })
      }
    }

    const hasErrors = violations.some(v => v.severity === 'error')

    return {
      passed: !hasErrors,
      violations
    }
  }
}

// Example: Code generation quality gate
const codeQualityGate = new QualityGate([
  {
    name: 'no_placeholder_code',
    check: (output) => !output.match(/\/\/ TODO|\/\/ FIXME|\.\.\.$/gm),
    errorMessage: 'Code contains TODO/FIXME placeholders',
    severity: 'error'
  },
  {
    name: 'has_error_handling',
    check: (output) => output.includes('try') || output.includes('catch') || output.includes('throw'),
    errorMessage: 'Code lacks error handling',
    severity: 'error'
  },
  {
    name: 'has_types',
    check: (output) => output.includes('interface') || output.includes('type '),
    errorMessage: 'Code missing TypeScript type definitions',
    severity: 'warning'
  },
  {
    name: 'reasonable_length',
    check: (output) => output.length &gt; 100 && output.length &lt; 10000,
    errorMessage: 'Code is suspiciously short (&lt;100 chars) or long (&gt;10K chars)',
    severity: 'warning'
  }
])

// Usage in agent workflow
async function codeGeneratorAgentWithQualityGate(task: string): Promise<string> {
  const response = await anthropic.messages.create({
    model: 'claude-4.5-sonnet',
    max_tokens: 4000,
    messages: [{ role: 'user', content: `Generate TypeScript code for: ${task}` }]
  })

  const generatedCode = response.content[0].text

  // Validate through quality gate
  const validation = await codeQualityGate.validate(generatedCode)

  if (!validation.passed) {
    console.log('‚ùå Quality gate failed:')
    validation.violations.forEach(v => {
      console.log(`  [${v.severity.toUpperCase()}] ${v.rule}: ${v.message}`)
    })

    // Option 1: Auto-retry with feedback
    const revisionPrompt = `Your previous code failed quality checks:

${validation.violations.map(v => `- ${v.message}`).join('\n')}

Fix these issues and regenerate the code.`

    const revisionResponse = await anthropic.messages.create({
      model: 'claude-4.5-sonnet',
      max_tokens: 4000,
      messages: [
        { role: 'user', content: `Generate TypeScript code for: ${task}` },
        { role: 'assistant', content: generatedCode },
        { role: 'user', content: revisionPrompt }
      ]
    })

    return revisionResponse.content[0].text
  }

  console.log('‚úÖ Quality gate passed')
  return generatedCode
}

/* Example:

Task: "Create a function to fetch user data from API"

First attempt:
```typescript
async function fetchUser(id) {
  // TODO: Add error handling
  const response = await fetch(`/api/users/${id}`)
  return response.json()
}
```

‚ùå Quality gate failed:
  [ERROR] no_placeholder_code: Code contains TODO/FIXME placeholders
  [ERROR] has_error_handling: Code lacks error handling
  [WARNING] has_types: Code missing TypeScript type definitions

Agent revises:
```typescript
interface User {
  id: string
  name: string
  email: string
}

async function fetchUser(id: string): Promise<User> {
  try {
    const response = await fetch(`/api/users/${id}`)
    if (!response.ok) {
      throw new Error(`Failed to fetch user: ${response.statusText}`)
    }
    return await response.json()
  } catch (error) {
    console.error('Error fetching user:', error)
    throw error
  }
}
```

‚úÖ Quality gate passed
*/
```

---

## Key Takeaways

**Self-Reflection**:
- Agents critique their own output before submission
- Catches lazy reasoning, factual errors, incomplete answers
- Cost: 4.5x single-shot, but prevents 80% of quality issues
- Use for: High-stakes outputs (legal, medical, financial)

**Human-in-the-Loop (HITL)**:
- Agents pause execution for human approval on high-stakes actions
- Required for: Irreversible actions, cost >$100, affects &gt;100 users
- Timeout policy: Auto-reject after 5 minutes (prevents hanging agents)
- Notification channels: Slack, email, dashboard

**Automated Quality Gates**:
- Define explicit validation rules for agent output
- Prevents cascading failures (bad output ‚Üí bad input)
- Auto-retry with feedback if validation fails
- Use for: Code generation, data processing, content creation

**The Architect's Responsibility**:
You **own** reliability. If your agent sends 10K emails without HITL, **you failed to add approval gates**. If your code generator produces TODO placeholders in production, **you skipped quality gates**. If your agent makes a critical error and you can't explain why, **you didn't implement audit logging**.

**Cost Analysis**:
```typescript
// No reliability patterns
- Cost: $0.02 per agent call
- Quality: 70% (30% require human intervention)
- Human review cost: 30% √ó $50/hour = $15 per failed call
- Real cost: $0.02 + $15 = $15.02

// With reflection + quality gates
- Cost: $0.09 per agent call (4.5x increase)
- Quality: 95% (5% require human intervention)
- Human review cost: 5% √ó $50/hour = $2.50 per failed call
- Real cost: $0.09 + $2.50 = $2.59

// ROI: $0.07 extra prevents $12.43 in human review costs (177:1 ROI)
```

**Next Concept**: Now that your agents are reliable, Concept 4 covers **State Checkpointing** so agents can resume after crashes and **Time Travel Debugging** to rewind agent state when reasoning fails.
