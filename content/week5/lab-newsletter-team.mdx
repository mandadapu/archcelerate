---
title: "Lab: Auto-Research & Newsletter Team"
week: 5
lab: true
description: "Build a multi-agent newsroom using Supervisor pattern with state management, error routing, and self-healing"
estimatedMinutes: 180
objectives:
  - Implement three specialized agents (Hunter, Fact-Checker, Writer)
  - Build Supervisor with conditional routing and error handling
  - Add state management with checkpointing
  - Implement "zero-waste" execution with self-healing prompts
---

# Lab: The Auto-Research & Newsletter Team

Build a multi-agent newsroom that produces high-quality technical newsletters with **zero human intervention** while staying under budget.

## Lab Overview

Instead of a simple chatbot, you'll build a **Multi-Agent Newsroom** with three specialists:

1. **Agent 1 (The Hunter)**: Searches for the top 3 trending stories in AI Architecture
2. **Agent 2 (The Fact-Checker)**: Verifies the sources and filters out "hype" vs. "reality"
3. **Agent 3 (The Writer)**: Takes the verified data and writes a professional technical summary
4. **The Orchestrator**: Uses a Supervisor Pattern to manage handoffs between these three

### Success Criteria

‚úÖ Produces newsletter from topic in under 10 API calls
‚úÖ Never publishes unverified information
‚úÖ Self-corrects when Fact-Checker finds issues
‚úÖ Stays under $0.20 per newsletter
‚úÖ Full audit trail of all agent decisions

---

## Part 1: State Schema (The Foundation)

The State is the "Single Source of Truth" for the entire workflow.

### Exercise 1.1: Define the State Schema

```typescript
// src/lab5/types.ts
export interface NewsletterState {
  // Input
  topic: string

  // Hunter outputs
  raw_articles: Array<{
    title: string
    source: string
    summary: string
    url?: string
  }>
  hunter_iteration: number

  // Fact-Checker outputs
  fact_check_score: number
  verified_articles: Array<{
    title: string
    source: string
    summary: string
    credibility: 'high' | 'medium' | 'low'
  }>
  rejected_articles: string[]
  correction_prompt?: string

  // Writer outputs
  draft_newsletter: string
  final_newsletter: string

  // Orchestration
  iteration_count: number
  max_iterations: number
  total_cost: number
  audit_trail: Array<{
    step: string
    agent: string
    timestamp: Date
    tokens_used: number
  }>
}

export const createInitialState = (topic: string): NewsletterState => ({
  topic,
  raw_articles: [],
  hunter_iteration: 0,
  fact_check_score: 0,
  verified_articles: [],
  rejected_articles: [],
  draft_newsletter: '',
  final_newsletter: '',
  iteration_count: 0,
  max_iterations: 3,
  total_cost: 0,
  audit_trail: []
})
```

**‚úÖ Checkpoint**: Your state schema should have:
- Clear separation between agent outputs
- Iteration counters for cycle detection
- Cost tracking
- Audit trail

---

## Part 2: The Hunter Agent (The Researcher)

### Exercise 2.1: Implement the Hunter

```typescript
// src/lab5/agents/hunter.ts
import Anthropic from '@anthropic-ai/sdk'

const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })

export async function hunterAgent(
  state: NewsletterState
): Promise<Partial<NewsletterState>> {
  console.log(`\nüîç Hunter: Searching for articles on "${state.topic}"`)
  console.log(`Hunter iteration: ${state.hunter_iteration + 1}`)

  // Build prompt with feedback if this is a retry
  const prompt = state.correction_prompt
    ? `Find articles on "${state.topic}".

FEEDBACK from Fact-Checker:
${state.correction_prompt}

Adjust your search strategy based on this feedback. Find 3 high-quality sources.`
    : `Find the top 3 trending articles on "${state.topic}" in AI Architecture.

Focus on:
- Recent publications (2025-2026)
- Technical depth (not just marketing)
- Credible sources (academic, established tech companies, respected engineers)

Output JSON:
[
  {
    "title": "Article Title",
    "source": "Source Name",
    "summary": "Brief summary",
    "url": "https://..."
  }
]`

  const response = await anthropic.messages.create({
    model: 'claude-3-5-sonnet-20240620',
    max_tokens: 2048,
    messages: [{
      role: 'user',
      content: prompt
    }]
  })

  // Parse response
  const text = response.content[0].text
  const jsonMatch = text.match(/\[[\s\S]*\]/)
  const articles = jsonMatch ? JSON.parse(jsonMatch[0]) : []

  // Track cost
  const tokensUsed = response.usage.input_tokens + response.usage.output_tokens
  const cost = (response.usage.input_tokens * 0.000003) +
               (response.usage.output_tokens * 0.000015)

  console.log(`  Found ${articles.length} articles`)
  console.log(`  Cost: $${cost.toFixed(4)} (${tokensUsed} tokens)`)

  return {
    raw_articles: articles,
    hunter_iteration: state.hunter_iteration + 1,
    total_cost: state.total_cost + cost,
    audit_trail: [
      ...state.audit_trail,
      {
        step: 'hunter',
        agent: 'Hunter',
        timestamp: new Date(),
        tokens_used: tokensUsed
      }
    ],
    correction_prompt: undefined  // Clear feedback after using it
  }
}
```

**Key Features**:
- ‚úÖ Uses `correction_prompt` for self-healing retries
- ‚úÖ Tracks token usage and cost
- ‚úÖ Appends to audit trail
- ‚úÖ Clears correction prompt after use

**Test Your Hunter**:

```typescript
// src/lab5/test-hunter.ts
import { createInitialState } from './types'
import { hunterAgent } from './agents/hunter'

const state = createInitialState('RAG architecture patterns for production')
const result = await hunterAgent(state)

console.log('Raw Articles:', result.raw_articles)
console.log('Total Cost:', result.total_cost)
```

---

## Part 3: The Fact-Checker Agent (The Verifier)

### Exercise 3.1: Implement Quality Scoring

```typescript
// src/lab5/agents/fact-checker.ts
import Anthropic from '@anthropic-ai/sdk'

const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })

interface FactCheckResult {
  verified: any[]
  rejected: string[]
  score: number
  feedback: string
}

export async function factCheckerAgent(
  state: NewsletterState
): Promise<Partial<NewsletterState>> {
  console.log(`\n‚úÖ Fact-Checker: Verifying ${state.raw_articles.length} articles`)

  const prompt = `You are a technical fact-checker. Verify these articles for quality and credibility:

${JSON.stringify(state.raw_articles, null, 2)}

For each article, check:
1. Source credibility (is it a known, reputable source?)
2. Technical accuracy (does the summary make sense?)
3. Recency (is it relevant to 2025-2026?)
4. Hype detection (is it marketing fluff or real technical content?)

Output JSON:
{
  "verified": [
    {
      "title": "...",
      "source": "...",
      "summary": "...",
      "credibility": "high" | "medium" | "low"
    }
  ],
  "rejected": ["Title of rejected article"],
  "score": 0.0-1.0,
  "feedback": "Specific feedback on what was wrong with rejected articles"
}`

  const response = await anthropic.messages.create({
    model: 'claude-3-5-sonnet-20240620',
    max_tokens: 2048,
    messages: [{ role: 'user', content: prompt }]
  })

  const text = response.content[0].text
  const jsonMatch = text.match(/\{[\s\S]*\}/)
  const result: FactCheckResult = jsonMatch
    ? JSON.parse(jsonMatch[0])
    : { verified: [], rejected: [], score: 0, feedback: '' }

  // Track cost
  const tokensUsed = response.usage.input_tokens + response.usage.output_tokens
  const cost = (response.usage.input_tokens * 0.000003) +
               (response.usage.output_tokens * 0.000015)

  console.log(`  Verified: ${result.verified.length} articles`)
  console.log(`  Rejected: ${result.rejected.length} articles`)
  console.log(`  Quality Score: ${result.score}`)
  console.log(`  Cost: $${cost.toFixed(4)}`)

  return {
    fact_check_score: result.score,
    verified_articles: result.verified,
    rejected_articles: result.rejected,
    correction_prompt: result.score < 0.8 ? result.feedback : undefined,
    total_cost: state.total_cost + cost,
    audit_trail: [
      ...state.audit_trail,
      {
        step: 'fact_check',
        agent: 'Fact-Checker',
        timestamp: new Date(),
        tokens_used: tokensUsed
      }
    ]
  }
}
```

**Key Features**:
- ‚úÖ Scores article quality (0.0-1.0)
- ‚úÖ Provides specific feedback for rejected articles
- ‚úÖ Sets `correction_prompt` if score is low (< 0.8)

---

## Part 4: The Writer Agent (The Creator)

### Exercise 4.1: Token-Optimized Newsletter Generation

```typescript
// src/lab5/agents/writer.ts
import Anthropic from '@anthropic-ai/sdk'

const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })

export async function writerAgent(
  state: NewsletterState
): Promise<Partial<NewsletterState>> {
  console.log(`\n‚úçÔ∏è Writer: Creating newsletter from ${state.verified_articles.length} articles`)

  // ‚úÖ Token Trimming: Only pass verified articles, NOT raw_articles
  const articlesText = state.verified_articles
    .map((a, i) => `${i + 1}. ${a.title}\nSource: ${a.source}\n${a.summary}`)
    .join('\n\n')

  const prompt = `Write a professional technical newsletter for AI architects based on these verified articles:

${articlesText}

Requirements:
- 400-500 words
- Markdown format
- Technical depth (not marketing)
- Clear section headers
- Actionable insights

Title the newsletter: "${state.topic} - This Week"`

  const response = await anthropic.messages.create({
    model: 'claude-3-5-sonnet-20240620',
    max_tokens: 2048,
    messages: [{ role: 'user', content: prompt }]
  })

  const newsletter = response.content[0].text

  // Track cost
  const tokensUsed = response.usage.input_tokens + response.usage.output_tokens
  const cost = (response.usage.input_tokens * 0.000003) +
               (response.usage.output_tokens * 0.000015)

  console.log(`  Newsletter: ${newsletter.length} chars`)
  console.log(`  Cost: $${cost.toFixed(4)}`)

  return {
    final_newsletter: newsletter,
    total_cost: state.total_cost + cost,
    audit_trail: [
      ...state.audit_trail,
      {
        step: 'writer',
        agent: 'Writer',
        timestamp: new Date(),
        tokens_used: tokensUsed
      }
    ]
  }
}
```

**Token Optimization**:
```typescript
// ‚ùå DON'T DO THIS (wastes 3,000+ tokens)
const prompt = `
Raw articles: ${JSON.stringify(state.raw_articles)}
Verified articles: ${JSON.stringify(state.verified_articles)}
`

// ‚úÖ DO THIS (saves 60% tokens)
const prompt = `
Verified articles: ${state.verified_articles.map(a => a.summary).join('\n')}
`
```

---

## Part 5: The Supervisor (The Router)

### Exercise 5.1: Error Routing Table

```typescript
// src/lab5/supervisor.ts

type RoutingDecision =
  | 'to_hunter'
  | 'to_fact_checker'
  | 'to_writer'
  | 'to_human_escalation'
  | 'complete'

interface ErrorRoute {
  category: 'transient' | 'logic_quality' | 'budget_safety' | 'input_error'
  action: RoutingDecision
  reason: string
}

export function routeAfterHunter(state: NewsletterState): RoutingDecision {
  // Check if Hunter found articles
  if (state.raw_articles.length === 0) {
    if (state.hunter_iteration >= 2) {
      return 'to_human_escalation'  // Can't find articles after 2 tries
    }
    return 'to_hunter'  // Retry
  }

  // Proceed to fact-checking
  return 'to_fact_checker'
}

export function routeAfterFactCheck(state: NewsletterState): RoutingDecision {
  console.log(`\nüö¶ Supervisor: Routing decision`)
  console.log(`  Quality Score: ${state.fact_check_score}`)
  console.log(`  Iteration: ${state.iteration_count}`)

  // BUDGET/SAFETY: Max iterations reached
  if (state.iteration_count >= state.max_iterations) {
    console.log(`  ‚ùå Max iterations (${state.max_iterations}) reached`)
    return 'to_human_escalation'
  }

  // BUDGET/SAFETY: Cost exceeded
  if (state.total_cost > 0.20) {
    console.log(`  ‚ùå Budget exceeded ($${state.total_cost.toFixed(4)})`)
    return 'to_human_escalation'
  }

  // LOGIC/QUALITY: Score too low - State Reset needed
  if (state.fact_check_score < 0.8) {
    console.log(`  ‚ö†Ô∏è Low quality score - routing back to Hunter with feedback`)
    console.log(`  Feedback: ${state.correction_prompt}`)
    return 'to_hunter'  // ‚úÖ Self-healing: Retry with feedback
  }

  // SUCCESS: Proceed to Writer
  console.log(`  ‚úÖ High quality - proceeding to Writer`)
  return 'to_writer'
}

export function routeAfterWriter(state: NewsletterState): RoutingDecision {
  return 'complete'
}
```

### Exercise 5.2: The "Self-Healing" Prompt

**Key Pattern**: When routing back for retry, the Supervisor provides **specific feedback** via `correction_prompt`.

```typescript
// Example of correction_prompt from Fact-Checker:
{
  correction_prompt: "The previous articles were biased. Article 2 is from a marketing blog, not a technical source. Please find peer-reviewed or engineering blog sources instead."
}

// Hunter receives this and adjusts strategy:
// "Find articles on RAG architecture..."
// "FEEDBACK from Fact-Checker: The previous articles were biased..."
```

---

## Part 6: The Complete Orchestrator

### Exercise 6.1: Implement the Supervisor Workflow

```typescript
// src/lab5/orchestrator.ts
import { NewsletterState, createInitialState } from './types'
import { hunterAgent } from './agents/hunter'
import { factCheckerAgent } from './agents/fact-checker'
import { writerAgent } from './agents/writer'
import { routeAfterHunter, routeAfterFactCheck, routeAfterWriter } from './supervisor'

export async function runNewsletterWorkflow(topic: string): Promise<NewsletterState> {
  let state = createInitialState(topic)
  let currentStep: 'hunter' | 'fact_checker' | 'writer' | 'complete' = 'hunter'

  console.log(`\nüöÄ Starting Newsletter Workflow`)
  console.log(`Topic: ${topic}`)
  console.log(`Max Iterations: ${state.max_iterations}`)
  console.log(`Budget: $0.20`)
  console.log('=' .repeat(60))

  while (currentStep !== 'complete') {
    // Increment iteration counter
    if (currentStep === 'hunter') {
      state.iteration_count++
      console.log(`\nüìç Iteration ${state.iteration_count}/${state.max_iterations}`)
    }

    // Execute current step
    switch (currentStep) {
      case 'hunter': {
        const update = await hunterAgent(state)
        state = { ...state, ...update }

        const next = routeAfterHunter(state)
        if (next === 'to_human_escalation') {
          throw new Error('Hunter failed to find articles after retries')
        }
        currentStep = next === 'to_fact_checker' ? 'fact_checker' : 'hunter'
        break
      }

      case 'fact_checker': {
        const update = await factCheckerAgent(state)
        state = { ...state, ...update }

        const next = routeAfterFactCheck(state)
        if (next === 'to_human_escalation') {
          console.log('\n‚ö†Ô∏è Escalating to human:')
          console.log(`  Iterations: ${state.iteration_count}`)
          console.log(`  Cost: $${state.total_cost.toFixed(4)}`)
          console.log(`  Quality Score: ${state.fact_check_score}`)
          throw new Error('Workflow escalated to human')
        }

        if (next === 'to_hunter') {
          // ‚úÖ Self-Healing: Go back to Hunter with feedback
          currentStep = 'hunter'
        } else if (next === 'to_writer') {
          currentStep = 'writer'
        }
        break
      }

      case 'writer': {
        const update = await writerAgent(state)
        state = { ...state, ...update }

        currentStep = 'complete'
        break
      }
    }
  }

  console.log('\n' + '='.repeat(60))
  console.log('‚úÖ Workflow Complete!')
  console.log(`Total Cost: $${state.total_cost.toFixed(4)}`)
  console.log(`Total Iterations: ${state.iteration_count}`)
  console.log(`API Calls: ${state.audit_trail.length}`)

  return state
}
```

---

## Part 7: Checkpointing (State Persistence)

### Exercise 7.1: Add Database Checkpoints

```typescript
// src/lab5/checkpoint.ts
import { prisma } from '@/lib/db'
import { NewsletterState } from './types'

export async function saveCheckpoint(
  workflowId: string,
  step: string,
  state: NewsletterState
) {
  await prisma.workflowCheckpoint.create({
    data: {
      workflowId,
      step,
      state: state as any,  // Store as JSON
      timestamp: new Date()
    }
  })
  console.log(`üíæ Checkpoint saved: ${step}`)
}

export async function resumeWorkflow(workflowId: string): Promise<NewsletterState | null> {
  const checkpoint = await prisma.workflowCheckpoint.findFirst({
    where: { workflowId },
    orderBy: { timestamp: 'desc' }
  })

  if (!checkpoint) {
    return null
  }

  console.log(`üìÇ Resuming from checkpoint: ${checkpoint.step}`)
  return checkpoint.state as NewsletterState
}
```

### Exercise 7.2: Update Orchestrator with Checkpoints

```typescript
// In orchestrator.ts
import { saveCheckpoint } from './checkpoint'

export async function runNewsletterWorkflow(
  topic: string,
  workflowId: string = crypto.randomUUID()
): Promise<NewsletterState> {
  let state = createInitialState(topic)

  while (currentStep !== 'complete') {
    // ... execute step ...

    // Save checkpoint after each step
    await saveCheckpoint(workflowId, currentStep, state)
  }

  return state
}
```

---

## Part 8: Testing the Full System

### Exercise 8.1: Run End-to-End Test

```typescript
// src/lab5/test-workflow.ts
import { runNewsletterWorkflow } from './orchestrator'

async function main() {
  try {
    const result = await runNewsletterWorkflow(
      'Vector databases for production RAG systems'
    )

    console.log('\nüì∞ FINAL NEWSLETTER:')
    console.log('='.repeat(60))
    console.log(result.final_newsletter)
    console.log('='.repeat(60))

    console.log('\nüìä METRICS:')
    console.log(`Cost: $${result.total_cost.toFixed(4)}`)
    console.log(`Iterations: ${result.iteration_count}`)
    console.log(`API Calls: ${result.audit_trail.length}`)

    console.log('\nüîç AUDIT TRAIL:')
    result.audit_trail.forEach((entry, i) => {
      console.log(`${i + 1}. ${entry.agent} - ${entry.step} (${entry.tokens_used} tokens)`)
    })

  } catch (error) {
    console.error('‚ùå Workflow failed:', error.message)
  }
}

main()
```

### Expected Output (Success Case)

```
üöÄ Starting Newsletter Workflow
Topic: Vector databases for production RAG systems
Max Iterations: 3
Budget: $0.20
============================================================

üìç Iteration 1/3

üîç Hunter: Searching for articles on "Vector databases for production RAG systems"
Hunter iteration: 1
  Found 3 articles
  Cost: $0.0456 (1520 tokens)

‚úÖ Fact-Checker: Verifying 3 articles
  Verified: 3 articles
  Rejected: 0 articles
  Quality Score: 0.95
  Cost: $0.0412

üö¶ Supervisor: Routing decision
  Quality Score: 0.95
  Iteration: 1
  ‚úÖ High quality - proceeding to Writer

‚úçÔ∏è Writer: Creating newsletter from 3 articles
  Newsletter: 2456 chars
  Cost: $0.0523

============================================================
‚úÖ Workflow Complete!
Total Cost: $0.1391
Total Iterations: 1
API Calls: 3

üì∞ FINAL NEWSLETTER:
============================================================
# Vector Databases for Production RAG Systems - This Week
...
============================================================
```

### Expected Output (Self-Healing Case)

```
üìç Iteration 1/3

üîç Hunter: Searching for articles...
  Found 3 articles
  Cost: $0.0456

‚úÖ Fact-Checker: Verifying 3 articles
  Verified: 1 articles
  Rejected: 2 articles
  Quality Score: 0.45
  Cost: $0.0412

üö¶ Supervisor: Routing decision
  Quality Score: 0.45
  Iteration: 1
  ‚ö†Ô∏è Low quality score - routing back to Hunter with feedback
  Feedback: Articles 2 and 3 are from marketing blogs, not technical sources

üìç Iteration 2/3

üîç Hunter: Searching for articles on "Vector databases..."
Hunter iteration: 2

FEEDBACK from Fact-Checker:
Articles 2 and 3 are from marketing blogs, not technical sources

  Found 3 articles
  Cost: $0.0489

‚úÖ Fact-Checker: Verifying 3 articles
  Verified: 3 articles
  Rejected: 0 articles
  Quality Score: 0.88
  Cost: $0.0421

üö¶ Supervisor: Routing decision
  ‚úÖ High quality - proceeding to Writer

‚úçÔ∏è Writer: Creating newsletter...
  Cost: $0.0512

============================================================
‚úÖ Workflow Complete!
Total Cost: $0.1790
Total Iterations: 2
API Calls: 5
```

---

## Part 9: Lab Rubric (100 Points)

### 1. State Management & Architecture (25 points)

- [ ] **State schema includes all required fields** (5pts)
- [ ] **Atomic updates (agents only modify their fields)** (5pts)
- [ ] **Iteration counter and max_iterations** (5pts)
- [ ] **Cost tracking per agent** (5pts)
- [ ] **Audit trail with timestamps and tokens** (5pts)

### 2. Agent Implementation (30 points)

- [ ] **Hunter agent finds articles and handles feedback** (10pts)
- [ ] **Fact-Checker scores quality and provides specific feedback** (10pts)
- [ ] **Writer uses token-trimmed input (only verified articles)** (10pts)

### 3. Supervisor & Routing (25 points)

- [ ] **Error routing table with 4 categories** (5pts)
- [ ] **Self-healing: Routes back to Hunter with correction_prompt** (10pts)
- [ ] **Budget enforcement (max cost and max iterations)** (5pts)
- [ ] **Proper escalation to human when needed** (5pts)

### 4. Production Features (20 points)

- [ ] **Checkpointing to database** (5pts)
- [ ] **Token trimming (60%+ reduction)** (5pts)
- [ ] **Cycle detection prevents infinite loops** (5pts)
- [ ] **Complete audit trail** (5pts)

### Bonus Points (10 points)

- [ ] **Implement reflection on final newsletter** (+5pts)
- [ ] **Add forking to test multiple Writer styles** (+3pts)
- [ ] **Human-in-the-loop approval before publishing** (+2pts)

---

## Key Achievements ("Zero-Waste" Execution)

By the end of this lab, your system should be able to:

1. ‚úÖ **Identify a hallucination** (Fact-Checker detects low-quality sources)
2. ‚úÖ **Reset the state** to the last "Known Good" point (keep raw_articles, reset verified_data)
3. ‚úÖ **Correct the search strategy** (provide specific feedback to Hunter)
4. ‚úÖ **Produce the final result** without human intervention
5. ‚úÖ **Stay under budget** ($0.20 and 3 iterations max)

### Metrics to Track

| Metric | Target | Why It Matters |
|--------|--------|---------------|
| **Cost per newsletter** | < $0.20 | Production viability |
| **API calls** | < 10 | Efficiency |
| **Iterations** | 1-2 avg | Self-healing effectiveness |
| **Quality score** | > 0.8 | Content credibility |
| **Success rate** | > 90% | Reliability |

---

## Next Steps

After completing this lab:

1. **Week 5 Project**: Build a full-stack app development team (Frontend, Backend, Database specialists)
2. **Production deployment**: Add Redis checkpointing and horizontal scaling
3. **Advanced patterns**: Implement forking and A/B testing for Writer styles

---

## Troubleshooting

### Issue: Fact-Checker always rejects articles

**Diagnosis**: Prompt is too strict or Hunter is searching wrong sources

**Fix**: Adjust Fact-Checker prompt to be more lenient (score > 0.6 instead of 0.8)

### Issue: Infinite loop between Hunter and Fact-Checker

**Diagnosis**: `max_iterations` not enforced or correction_prompt not being used

**Fix**: Verify routing logic checks `iteration_count >= max_iterations`

### Issue: Cost exceeds $0.20

**Diagnosis**: Not using token trimming or too many iterations

**Fix**:
- Verify Writer only receives `verified_articles`, not `raw_articles`
- Reduce `max_iterations` to 2

### Issue: Hunter doesn't improve on retry

**Diagnosis**: `correction_prompt` not being passed or cleared too early

**Fix**: Verify Hunter prompt includes `state.correction_prompt` when present

---

## Further Reading

- [LangGraph Multi-Agent Tutorials](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/)
- [Anthropic Message Batching](https://docs.anthropic.com/claude/docs/batch-processing)
- [Production Agent Patterns](https://www.anthropic.com/index/building-effective-agents)
