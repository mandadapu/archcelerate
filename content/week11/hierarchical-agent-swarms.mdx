---
title: "Hierarchical Agent Swarms"
description: "Design manager-worker architectures with autonomous feedback loops and semantic circuit breakers for production multi-agent systems"
estimatedMinutes: 60
week: 11
concept: 4
difficulty: expert
objectives:
  - Build hierarchical agent architectures (manager supervising workers)
  - Implement semantic circuit breakers to prevent infinite loops
  - Design autonomous feedback loops for self-correction
  - Deploy production swarms with cost and latency monitoring
---

# Hierarchical Agent Swarms

## The Enterprise Multi-Agent Problem

**Simple agents:** One agent, one task (e.g., "summarize this document")
**Enterprise reality:** Complex workflows requiring specialization and coordination

**Example: Product Launch Campaign**
- Market research (requires web search + analysis)
- Competitive analysis (requires data gathering + comparison)
- Marketing copy (requires creative writing + brand consistency)
- Code generation (requires technical implementation)
- Budget planning (requires financial modeling)

**Problem:** A single agent can't master all these skills. You need a **swarm**.

---

## ğŸ”¬ Real-World Challenge: The Oncology Research Swarm

**The Problem**: A hospital's oncology department receives **3,000+ new cancer research papers per month** across journals, pre-print servers (ArXiv, bioRxiv), and clinical trial databases. Clinicians need a daily digest of scientifically sound, protocol-relevant breakthroughs, but the volume is impossible for a human team to filter.

**Current State**:
- Manual research: 2 clinical researchers spend 4 hours/day reviewing papers
- Coverage: Only 150 papers/month reviewed (5% of total)
- Quality issues: 30% of flagged papers have methodological flaws (small sample sizes, p-hacking)
- Cost: $240K/year in researcher salaries
- Missed discoveries: Critical breakthroughs in related oncology fields overlooked

**Business Impact of Failure**:
- Patients miss out on cutting-edge treatment options
- Hospital falls behind on latest clinical protocols
- Competitive disadvantage vs research-leading institutions

### Architectural Solution: Hierarchical Research Swarm

Deploy a 3-agent hierarchical swarm that autonomously processes all 3,000 papers/month, validates methodology, and generates clinician-ready research briefs.

**Agent Architecture**:
```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Supervisor Agent    â”‚
              â”‚  (Quality Gatekeeper) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
  â”‚ Agent A   â”‚   â”‚ Agent B   â”‚   â”‚ Agent C   â”‚
  â”‚ The Scout â”‚   â”‚Statisticianâ”‚   â”‚ Reviewer  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Agent A - The Scout**:
- Monitors ArXiv, PubMed, ClinicalTrials.gov
- Filters by oncology keywords (e.g., "CAR-T", "checkpoint inhibitors")
- Extracts: Title, abstract, journal, authors, DOI
- Output: List of potentially relevant papers

**Agent B - The Statistician**:
- Reviews methodology sections
- Checks P-values, sample sizes, study design (RCT vs observational)
- Flags methodological concerns (p-hacking, insufficient power, selection bias)
- Output: Quality score (1-10) + specific concerns

**Agent C - The Reviewer**:
- Compares findings against hospital's current protocols
- Identifies novel treatment approaches
- Assesses clinical applicability (patient population match)
- Output: Clinician-ready research brief

**Supervisor Agent**:
- Receives outputs from all 3 agents
- Makes final inclusion decision (Quality score â‰¥ 7)
- Aggregates insights into weekly digest
- Escalates contradictory findings to human review

#### Production Implementation

```typescript
interface OncologyPaper {
  doi: string
  title: string
  authors: string[]
  journal: string
  abstract: string
  full_text?: string
  publication_date: Date
  keywords: string[]
}

interface QualityAssessment {
  score: number  // 1-10
  sample_size?: number
  study_design: 'RCT' | 'Cohort' | 'Case-Control' | 'Meta-Analysis' | 'Review'
  p_value?: number
  confidence_interval?: string
  methodological_concerns: string[]
  statistical_power: 'adequate' | 'underpowered' | 'unknown'
  bias_risk: 'low' | 'medium' | 'high'
}

interface ClinicalRelevance {
  relevance_score: number  // 1-10
  treatment_area: string
  aligns_with_protocols: boolean
  actionable_insights: string[]
  patient_population_match: boolean
  novelty: 'breakthrough' | 'incremental' | 'confirmatory'
}

interface ResearchBrief {
  paper: OncologyPaper
  quality: QualityAssessment
  clinical: ClinicalRelevance
  supervisor_decision: 'include' | 'exclude' | 'human_review'
  reasoning: string
}

// Agent A: The Scout
async function scoutAgent(
  source: 'arxiv' | 'pubmed' | 'clinicaltrials',
  keywords: string[]
): Promise<OncologyPaper[]> {
  console.log(`\nğŸ” Scout: Searching ${source} for oncology papers`)

  // Step 1: Search external APIs
  let papers: OncologyPaper[] = []

  if (source === 'pubmed') {
    const query = keywords.map(k => `("${k}"[Title/Abstract])`).join(' OR ')
    papers = await searchPubMed(query, limit = 100)
  } else if (source === 'arxiv') {
    papers = await searchArXiv(keywords, category = 'q-bio.OT', limit = 50)
  }

  console.log(`  Found ${papers.length} papers from ${source}`)

  // Step 2: Filter by relevance (Claude Haiku fast classification)
  const prompt = `You are a clinical research scout. Review these ${papers.length} paper abstracts and identify which are relevant to oncology clinical research.

PAPERS:
${papers.map((p, i) => `${i + 1}. ${p.title}\n   Abstract: ${p.abstract.substring(0, 300)}...`).join('\n\n')}

Output JSON array of relevant paper indices:
{ "relevant": [1, 5, 12, ...], "reason": "Brief explanation per paper" }

**Relevance Criteria**:
- Novel cancer treatments or biomarkers
- Clinical trial results (Phase I, II, III)
- Systematic reviews or meta-analyses
- Exclude: Basic science (unless directly applicable), review articles without new data`

  const response = await anthropic.messages.create({
    model: 'claude-haiku-4-5-20250703',
    max_tokens: 1500,
    messages: [{ role: 'user', content: prompt }]
  })

  const { relevant } = JSON.parse(response.content[0].text)
  const filteredPapers = relevant.map(i => papers[i - 1])

  console.log(`  Filtered to ${filteredPapers.length} relevant papers`)

  return filteredPapers
}

// Agent B: The Statistician
async function statisticianAgent(
  paper: OncologyPaper
): Promise<QualityAssessment> {
  console.log(`\nğŸ“Š Statistician: Reviewing "${paper.title}"`)

  const prompt = `You are a biostatistician reviewing research methodology. Assess the statistical rigor of this oncology study.

PAPER:
Title: ${paper.title}
Abstract: ${paper.abstract}
${paper.full_text ? `Methodology: ${extractMethodology(paper.full_text)}` : ''}

Evaluate:
1. **Sample Size**: How many patients/subjects? Is it adequate for detecting effects?
2. **Study Design**: RCT, cohort, case-control, meta-analysis?
3. **P-values**: Are they reported? Any evidence of p-hacking (multiple testing without correction)?
4. **Statistical Power**: Can this study detect clinically meaningful differences?
5. **Bias Risk**: Selection bias, publication bias, confounding?

Output JSON:
{
  "score": 7,  // 1-10 (10 = gold standard RCT with large sample)
  "sample_size": 234,
  "study_design": "RCT",
  "p_value": 0.003,
  "confidence_interval": "95% CI: 1.2-3.8",
  "methodological_concerns": ["Small sample size for subgroup analysis"],
  "statistical_power": "adequate",
  "bias_risk": "low"
}

**Scoring Rubric**:
- 9-10: Multi-center RCT, n&gt;500, pre-registered, low bias
- 7-8: Single-center RCT, n=100-500, adequate power
- 5-6: Cohort study, n=50-100, moderate bias risk
- 3-4: Small observational study, underpowered
- 1-2: Case reports, high bias, methodological flaws`

  const response = await anthropic.messages.create({
    model: 'claude-sonnet-4-5-20250929',
    max_tokens: 1000,
    temperature: 0.1,  // Low temperature for factual assessment
    messages: [{ role: 'user', content: prompt }]
  })

  const assessment: QualityAssessment = JSON.parse(response.content[0].text)

  console.log(`  Quality Score: ${assessment.score}/10`)
  console.log(`  Concerns: ${assessment.methodological_concerns.join(', ')}`)

  return assessment
}

// Agent C: The Reviewer
async function reviewerAgent(
  paper: OncologyPaper,
  quality: QualityAssessment,
  hospitalProtocols: string[]
): Promise<ClinicalRelevance> {
  console.log(`\nğŸ‘¨â€âš•ï¸ Reviewer: Assessing clinical relevance`)

  const prompt = `You are a clinical oncologist reviewing research for protocol updates. Assess this paper's clinical relevance.

PAPER:
Title: ${paper.title}
Abstract: ${paper.abstract}
Quality Score: ${quality.score}/10
Study Design: ${quality.study_design}

HOSPITAL PROTOCOLS:
${hospitalProtocols.join('\n')}

Evaluate:
1. **Clinical Relevance**: How applicable is this to our patient population?
2. **Protocol Alignment**: Does this support or contradict our current protocols?
3. **Actionable Insights**: What specific changes should we consider?
4. **Novelty**: Is this a breakthrough, incremental improvement, or confirmatory?

Output JSON:
{
  "relevance_score": 8,  // 1-10
  "treatment_area": "Immunotherapy - CAR-T for B-cell lymphoma",
  "aligns_with_protocols": true,
  "actionable_insights": [
    "Consider expanding CAR-T eligibility to patients &gt;70 years",
    "Monitor for cytokine release syndrome more closely in elderly patients"
  ],
  "patient_population_match": true,
  "novelty": "incremental"
}`

  const response = await anthropic.messages.create({
    model: 'claude-sonnet-4-5-20250929',
    max_tokens: 1000,
    messages: [{ role: 'user', content: prompt }]
  })

  const relevance: ClinicalRelevance = JSON.parse(response.content[0].text)

  console.log(`  Relevance Score: ${relevance.relevance_score}/10`)
  console.log(`  Actionable Insights: ${relevance.actionable_insights.length}`)

  return relevance
}

// Supervisor Agent: Final Decision
async function supervisorAgent(
  paper: OncologyPaper,
  quality: QualityAssessment,
  clinical: ClinicalRelevance
): Promise<ResearchBrief> {
  console.log(`\nğŸ¯ Supervisor: Making final decision`)

  // Decision rules
  let decision: 'include' | 'exclude' | 'human_review' = 'exclude'
  let reasoning = ''

  if (quality.score &gt;= 8 && clinical.relevance_score &gt;= 7) {
    decision = 'include'
    reasoning = 'High-quality research with strong clinical relevance'
  } else if (quality.score &gt;= 7 && clinical.novelty === 'breakthrough') {
    decision = 'include'
    reasoning = 'Breakthrough finding despite moderate quality score'
  } else if (clinical.relevance_score &gt;= 9 && quality.score &gt;= 5) {
    decision = 'human_review'
    reasoning = 'Highly relevant but methodology concerns - flagging for expert review'
  } else if (quality.methodological_concerns.some(c => c.includes('bias') || c.includes('p-hacking'))) {
    decision = 'exclude'
    reasoning = 'Methodological red flags identified by statistician'
  } else {
    decision = 'exclude'
    reasoning = `Below threshold (Quality: ${quality.score}/10, Relevance: ${clinical.relevance_score}/10)`
  }

  console.log(`  Decision: ${decision.toUpperCase()}`)
  console.log(`  Reasoning: ${reasoning}`)

  return {
    paper,
    quality,
    clinical,
    supervisor_decision: decision,
    reasoning
  }
}

// Orchestration: Run Full Swarm
async function runOncologyResearchSwarm(
  dateSince: Date,
  hospitalProtocols: string[]
): Promise<ResearchBrief[]> {
  console.log('\nğŸš€ Starting Oncology Research Swarm')
  console.log(`Date Range: ${dateSince.toISOString()} to now`)
  console.log('='.repeat(60))

  // Step 1: Scout agents search in parallel
  const [arxivPapers, pubmedPapers] = await Promise.all([
    scoutAgent('arxiv', ['cancer', 'oncology', 'CAR-T', 'checkpoint inhibitor']),
    scoutAgent('pubmed', ['cancer treatment', 'immunotherapy', 'targeted therapy'])
  ])

  const allPapers = [...arxivPapers, ...pubmedPapers]
  console.log(`\nğŸ“š Total papers found: ${allPapers.length}`)

  // Step 2: Process each paper through the swarm
  const briefs: ResearchBrief[] = []

  for (const paper of allPapers) {
    // Parallel execution of Statistician + Reviewer
    const [quality, clinical] = await Promise.all([
      statisticianAgent(paper),
      reviewerAgent(paper, { score: 5 } as any, hospitalProtocols)  // Simplified
    ])

    // Supervisor makes final decision
    const brief = await supervisorAgent(paper, quality, clinical)

    briefs.push(brief)

    // Stop early if budget exceeded (circuit breaker)
    if (briefs.length &gt;= 100) {
      console.log('  âš ï¸ Budget limit reached, stopping early')
      break
    }
  }

  // Step 3: Generate summary report
  const included = briefs.filter(b => b.supervisor_decision === 'include')
  const humanReview = briefs.filter(b => b.supervisor_decision === 'human_review')

  console.log('\n' + '='.repeat(60))
  console.log('âœ… Swarm Complete!')
  console.log(`Papers processed: ${briefs.length}`)
  console.log(`Included in digest: ${included.length}`)
  console.log(`Flagged for human review: ${humanReview.length}`)
  console.log(`Average quality score: ${(briefs.reduce((sum, b) => sum + b.quality.score, 0) / briefs.length).toFixed(1)}`)

  return briefs
}

// Helper: Extract methodology section from full text
function extractMethodology(fullText: string): string {
  // In production, use NLP to extract Methods section
  const methodsMatch = fullText.match(/## Methods([\s\S]*?)## Results/i)
  return methodsMatch ? methodsMatch[1].substring(0, 2000) : ''
}

// Helper: Search PubMed (simplified)
async function searchPubMed(query: string, limit: number): Promise<OncologyPaper[]> {
  // In production, use NCBI E-utilities API
  return [] // Placeholder
}

// Helper: Search ArXiv (simplified)
async function searchArXiv(keywords: string[], category: string, limit: number): Promise<OncologyPaper[]> {
  // In production, use ArXiv API
  return [] // Placeholder
}
```

### Production Metrics: Oncology Research Swarm

**Before Swarm (Manual Review)**:
- Papers reviewed: 150/month (5% coverage)
- Researcher time: 8 hours/day Ã— 2 researchers = 160 hours/month
- Cost: $240K/year (researcher salaries)
- Quality: 70% accuracy (30% include papers with methodological flaws)
- Latency: Weekly digest (papers 1-7 days old)

**After Swarm Deployment**:
- Papers reviewed: 3,000/month (100% coverage)
- Processing time: 15 minutes/day (automated)
- Cost: $1,200/month (API costs: $0.40/paper Ã— 3,000)
- Quality: 91% accuracy (Statistician agent catches methodological flaws)
- Latency: Daily digest (papers &lt;24 hours old)

**Business Impact**:
- **Cost**: $240K â†’ $14.4K/year (94% reduction)
- **Coverage**: 150 â†’ 3,000 papers/month (20x increase)
- **Researcher time freed**: 320 â†’ 10 hours/month (97% reduction)
- **Clinical outcomes**: Earlier adoption of breakthrough treatments (estimated 2-3 month time-to-implementation improvement)

**ROI Example**:
- Early identification of CAR-T therapy for elderly patients (from swarm)
- Hospital adopts protocol 6 months earlier than competitors
- 40 additional patients treated in first year
- Patient outcome improvement: 15% survival rate increase
- **Swarm cost**: $14.4K/year
- **Value created**: Immeasurable (lives saved) + competitive advantage

### Key Architectural Decisions

**1. Why Hierarchical (vs Flat Swarm)?**
```typescript
// Hierarchical advantages:
// - Clear separation of concerns (Scout â†’ Stats â†’ Review)
// - Supervisor provides consistent quality gate
// - Easy to add new worker agents without changing others
// - Explainable decisions (audit trail through hierarchy)
```

**2. Semantic Circuit Breakers**
```typescript
// Prevent infinite loops and budget overruns
const circuitBreakers = {
  maxPapersProcessed: 3000,  // Stop after 3K papers
  budgetLimit: 50,  // $50/day
  qualityThreshold: 7,  // Only include papers scoring â‰¥7
  humanReviewFlag: true  // Escalate ambiguous cases
}

if (totalCost &gt;= circuitBreakers.budgetLimit) {
  console.log('âš ï¸ Budget limit reached, stopping swarm')
  return briefs
}
```

**3. Autonomous Feedback Loops**
```typescript
// If Reviewer consistently disagrees with Statistician scores, retrain Statistician
async function feedbackLoop(briefs: ResearchBrief[]) {
  const disagreements = briefs.filter(b =>
    Math.abs(b.quality.score - b.clinical.relevance_score) &gt;= 4
  )

  if (disagreements.length > briefs.length * 0.2) {
    console.log('âš ï¸ High disagreement rate, triggering recalibration')
    await recalibrateStatistician(disagreements)
  }
}
```

**4. Human-in-the-Loop (HITL) Gates**
- Papers with breakthrough novelty + moderate quality â†’ Human review
- Contradictions between agents â†’ Human review
- Any paper flagged by 2+ agents â†’ Human review

### Comparison: Hierarchical vs Flat Architecture

| Dimension | Flat (All agents equal) | Hierarchical (Manager-Worker) |
|-----------|-------------------------|-------------------------------|
| **Complexity** | Low | Medium |
| **Consistency** | Variable (agent disagreements) | High (Supervisor decides) |
| **Scalability** | Hard (nÂ² connections) | Easy (add workers, not connections) |
| **Explainability** | Low (voting system) | High (clear decision tree) |
| **Cost** | Lower (fewer LLM calls) | Higher (Supervisor overhead) |
| **Best For** | Simple tasks | Enterprise production |

**Verdict**: Hierarchical wins for production systems requiring consistency and auditability.

---

## 1. Hierarchical Architecture: Manager-Worker Pattern

### The Pattern

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Manager Agent  â”‚
                    â”‚   (Coordinator) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                  â”‚                  â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
     â”‚ Worker  â”‚       â”‚ Worker  â”‚       â”‚ Worker  â”‚
     â”‚ (Market)â”‚       â”‚ (Tech)  â”‚       â”‚ (Finance)â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Manager Agent:**
- Decomposes high-level goals into sub-tasks
- Routes sub-tasks to specialized worker agents
- Aggregates worker outputs
- Makes final decisions

**Worker Agents:**
- Specialize in one domain (market research, coding, finance)
- Execute assigned tasks autonomously
- Report results back to manager
- Request clarification if task is ambiguous

### Implementation: Manager Agent

```typescript
/**
 * Manager Agent: Coordinates Hierarchical Swarm
 */
import Anthropic from '@anthropic-ai/sdk'

interface Task {
  id: string
  description: string
  assigned_to?: string
  status: 'pending' | 'in_progress' | 'completed' | 'failed'
  result?: any
  retry_count: number
}

interface WorkerAgent {
  id: string
  name: string
  specialization: string
  model: string
  available: boolean
}

class ManagerAgent {
  private anthropic: Anthropic
  private workers: Map<string, WorkerAgent>
  private taskQueue: Task[]

  constructor() {
    this.anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })
    this.workers = new Map()
    this.taskQueue = []
  }

  // Register worker agents
  registerWorker(worker: WorkerAgent) {
    this.workers.set(worker.id, worker)
    console.log(`âœ… Registered worker: ${worker.name} (${worker.specialization})`)
  }

  // Step 1: Decompose high-level goal into sub-tasks
  async decompose(goal: string): Promise<Task[]> {
    const prompt = `You are a Manager Agent coordinating a team of specialized workers.

Goal: "${goal}"

Available Workers:
${Array.from(this.workers.values()).map(w =>
  `- ${w.name}: ${w.specialization}`
).join('\n')}

Decompose this goal into 3-5 specific, actionable sub-tasks. For each sub-task:
1. Write a clear description
2. Assign it to the most appropriate worker
3. Ensure tasks can be executed independently (minimal dependencies)

Return JSON array:
[
  {
    "description": "Task description",
    "assigned_to": "worker_id",
    "dependencies": []
  }
]`

    const response = await this.anthropic.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 2048,
      messages: [{ role: 'user', content: prompt }]
    })

    const tasksJson = response.content[0].text.match(/\[[\s\S]*\]/)?.[0]
    const taskDefinitions = JSON.parse(tasksJson || '[]')

    const tasks: Task[] = taskDefinitions.map((t: any, index: number) => ({
      id: `task_${index + 1}`,
      description: t.description,
      assigned_to: t.assigned_to,
      status: 'pending',
      retry_count: 0
    }))

    this.taskQueue.push(...tasks)
    return tasks
  }

  // Step 2: Execute tasks (parallel or sequential based on dependencies)
  async executeTasks(tasks: Task[]): Promise<Map<string, any>> {
    const results = new Map<string, any>()

    // Execute tasks in parallel (assuming no dependencies)
    await Promise.all(
      tasks.map(async (task) => {
        task.status = 'in_progress'

        try {
          const worker = this.workers.get(task.assigned_to!)
          if (!worker) throw new Error(`Worker ${task.assigned_to} not found`)

          console.log(`ğŸ”„ ${worker.name} executing: ${task.description}`)

          const result = await this.executeWorkerTask(worker, task)

          task.status = 'completed'
          task.result = result
          results.set(task.id, result)

          console.log(`âœ… ${worker.name} completed: ${task.description}`)

        } catch (error) {
          task.status = 'failed'
          task.retry_count++

          console.error(`âŒ Task failed: ${task.description}`, error)

          // Retry logic (max 2 retries)
          if (task.retry_count &lt; 2) {
            console.log(`ğŸ”„ Retrying task: ${task.description}`)
            await this.executeTasks([task])
          }
        }
      })
    )

    return results
  }

  // Step 3: Worker executes task
  private async executeWorkerTask(worker: WorkerAgent, task: Task): Promise<string> {
    const prompt = `You are ${worker.name}, a ${worker.specialization} specialist.

Your task: ${task.description}

Execute this task and return your findings. Be specific and actionable.`

    const response = await this.anthropic.messages.create({
      model: worker.model,
      max_tokens: 2048,
      messages: [{ role: 'user', content: prompt }]
    })

    return response.content[0].text
  }

  // Step 4: Aggregate results and make final decision
  async synthesize(goal: string, taskResults: Map<string, any>): Promise<string> {
    const resultsText = Array.from(taskResults.entries())
      .map(([taskId, result]) => {
        const task = this.taskQueue.find(t => t.id === taskId)
        return `### ${task?.description}\n${result}\n`
      })
      .join('\n---\n\n')

    const prompt = `You are a Manager Agent synthesizing the work of your team.

Original Goal: "${goal}"

Team Results:
${resultsText}

Synthesize these results into a coherent final deliverable that achieves the goal.`

    const response = await this.anthropic.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 4096,
      messages: [{ role: 'user', content: prompt }]
    })

    return response.content[0].text
  }

  // Complete workflow
  async execute(goal: string): Promise<string> {
    console.log(`\nğŸ¯ Manager Agent: Starting workflow for goal: "${goal}"\n`)

    // Step 1: Decompose
    const tasks = await this.decompose(goal)
    console.log(`ğŸ“‹ Decomposed into ${tasks.length} tasks\n`)

    // Step 2: Execute
    const results = await this.executeTasks(tasks)
    console.log(`\nâœ… All tasks completed (${results.size}/${tasks.length})\n`)

    // Step 3: Synthesize
    const final = await this.synthesize(goal, results)
    console.log(`\nğŸ‰ Final deliverable ready\n`)

    return final
  }
}
```

### Usage: Product Launch Swarm

```typescript
// Initialize manager
const manager = new ManagerAgent()

// Register specialized workers
manager.registerWorker({
  id: 'market_researcher',
  name: 'Market Researcher',
  specialization: 'market analysis, competitive research, trend identification',
  model: 'claude-3-5-sonnet-20241022',
  available: true
})

manager.registerWorker({
  id: 'tech_lead',
  name: 'Tech Lead',
  specialization: 'software architecture, code generation, technical documentation',
  model: 'claude-3-5-sonnet-20241022',
  available: true
})

manager.registerWorker({
  id: 'marketing_writer',
  name: 'Marketing Writer',
  specialization: 'copywriting, brand messaging, content strategy',
  model: 'claude-3-5-sonnet-20241022',
  available: true
})

manager.registerWorker({
  id: 'financial_analyst',
  name: 'Financial Analyst',
  specialization: 'budget planning, ROI analysis, cost modeling',
  model: 'claude-3-haiku-20240307', // Cheaper model for simpler tasks
  available: true
})

// Execute swarm
const goal = 'Launch a new AI-powered customer support chatbot product. Include market analysis, technical architecture, marketing strategy, and budget.'

const result = await manager.execute(goal)

console.log('=== FINAL PRODUCT LAUNCH PLAN ===')
console.log(result)
```

**Output:**
```
ğŸ¯ Manager Agent: Starting workflow for goal: "Launch a new AI-powered customer support chatbot product..."

ğŸ“‹ Decomposed into 4 tasks

ğŸ”„ Market Researcher executing: Analyze the customer support chatbot market...
ğŸ”„ Tech Lead executing: Design technical architecture for AI chatbot...
ğŸ”„ Marketing Writer executing: Create go-to-market strategy and messaging...
ğŸ”„ Financial Analyst executing: Create budget and ROI projections...

âœ… Market Researcher completed: Analyze the customer support chatbot market...
âœ… Tech Lead completed: Design technical architecture for AI chatbot...
âœ… Marketing Writer completed: Create go-to-market strategy and messaging...
âœ… Financial Analyst completed: Create budget and ROI projections...

âœ… All tasks completed (4/4)

ğŸ‰ Final deliverable ready

=== FINAL PRODUCT LAUNCH PLAN ===
[Synthesized plan combining all worker outputs]
```

---

## 2. Semantic Circuit Breakers: Preventing Infinite Loops

### The Problem

**Scenario:** Manager agent delegates task to Worker A â†’ Worker A asks for clarification â†’ Manager delegates to Worker B â†’ Worker B asks for clarification â†’ **Infinite loop!**

**Real Example:**
1. Manager: "Research our competitors"
2. Market Researcher: "Which industry? Which geography?"
3. Manager: "Clarify scope with Product Manager"
4. Product Manager: "What's the budget for research?"
5. Manager: "Get budget from Finance"
6. Finance: "What's the project timeline?"
7. Manager: "Check timeline with Product Manager"
8. **LOOP!** Manager â†” Product Manager â†” Finance â†” Manager...

**Cost:** $50+ in API calls, 10+ minutes wasted, no result delivered

### The Solution: Semantic Circuit Breaker

```typescript
/**
 * Semantic Circuit Breaker: Detect and Stop Infinite Loops
 */
interface CircuitBreakerConfig {
  max_task_retries: number          // Max retries per task (default: 2)
  max_clarification_loops: number   // Max back-and-forth clarifications (default: 3)
  max_total_iterations: number      // Max total agent calls (default: 20)
  similarity_threshold: number      // Cosine similarity for duplicate detection (default: 0.9)
}

class SemanticCircuitBreaker {
  private config: CircuitBreakerConfig
  private callHistory: Array<{
    agent: string
    task: string
    timestamp: number
    embedding: number[]
  }>
  private totalCalls: number

  constructor(config?: Partial<CircuitBreakerConfig>) {
    this.config = {
      max_task_retries: 2,
      max_clarification_loops: 3,
      max_total_iterations: 20,
      similarity_threshold: 0.9,
      ...config
    }
    this.callHistory = []
    this.totalCalls = 0
  }

  // Check if circuit should open (stop execution)
  async shouldBreak(agent: string, task: string): Promise<{
    break: boolean
    reason?: string
  }> {
    this.totalCalls++

    // Rule 1: Total iteration limit
    if (this.totalCalls &gt;= this.config.max_total_iterations) {
      return {
        break: true,
        reason: `Max iterations reached (${this.config.max_total_iterations})`
      }
    }

    // Rule 2: Detect duplicate tasks (semantic similarity)
    const taskEmbedding = await this.embed(task)

    for (const historyEntry of this.callHistory) {
      const similarity = this.cosineSimilarity(taskEmbedding, historyEntry.embedding)

      if (similarity &gt; this.config.similarity_threshold) {
        return {
          break: true,
          reason: `Duplicate task detected (similarity: ${similarity.toFixed(2)}). Previous: "${historyEntry.task}"`
        }
      }
    }

    // Rule 3: Detect clarification loops (same agent asked 3+ times)
    const sameAgentCalls = this.callHistory.filter(h => h.agent === agent)
    if (sameAgentCalls.length &gt;= this.config.max_clarification_loops) {
      return {
        break: true,
        reason: `Agent ${agent} called ${sameAgentCalls.length} times (max: ${this.config.max_clarification_loops})`
      }
    }

    // Rule 4: Detect rapid back-and-forth (same 2 agents alternating)
    if (this.callHistory.length &gt;= 4) {
      const recent4 = this.callHistory.slice(-4)
      const agent1 = recent4[0].agent
      const agent2 = recent4[1].agent

      if (
        recent4[2].agent === agent1 &&
        recent4[3].agent === agent2 &&
        agent1 !== agent2
      ) {
        return {
          break: true,
          reason: `Infinite loop detected between ${agent1} and ${agent2}`
        }
      }
    }

    // Record this call
    this.callHistory.push({
      agent,
      task,
      timestamp: Date.now(),
      embedding: taskEmbedding
    })

    return { break: false }
  }

  // Embed task for semantic comparison
  private async embed(text: string): Promise<number[]> {
    // Use OpenAI or Anthropic embeddings
    // Simplified for example
    return Array(1536).fill(0).map(() => Math.random())
  }

  // Calculate cosine similarity
  private cosineSimilarity(a: number[], b: number[]): number {
    const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0)
    const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0))
    const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0))
    return dotProduct / (magnitudeA * magnitudeB)
  }

  // Reset circuit breaker
  reset() {
    this.callHistory = []
    this.totalCalls = 0
  }

  // Get current state
  getState() {
    return {
      total_calls: this.totalCalls,
      history_length: this.callHistory.length,
      most_called_agent: this.getMostCalledAgent()
    }
  }

  private getMostCalledAgent(): string {
    const counts = new Map<string, number>()
    for (const entry of this.callHistory) {
      counts.set(entry.agent, (counts.get(entry.agent) || 0) + 1)
    }
    return Array.from(counts.entries())
      .sort((a, b) => b[1] - a[1])[0]?.[0] || 'none'
  }
}
```

### Integration with Manager Agent

```typescript
class SafeManagerAgent extends ManagerAgent {
  private circuitBreaker: SemanticCircuitBreaker

  constructor() {
    super()
    this.circuitBreaker = new SemanticCircuitBreaker({
      max_total_iterations: 20,
      max_clarification_loops: 3,
      similarity_threshold: 0.9
    })
  }

  // Override executeWorkerTask with circuit breaker
  protected async executeWorkerTask(worker: WorkerAgent, task: Task): Promise<string> {
    // Check circuit breaker BEFORE executing
    const circuitCheck = await this.circuitBreaker.shouldBreak(worker.id, task.description)

    if (circuitCheck.break) {
      throw new Error(`ğŸ›‘ Circuit breaker opened: ${circuitCheck.reason}`)
    }

    // Execute task if circuit is closed
    return await super.executeWorkerTask(worker, task)
  }

  // Override execute with circuit breaker monitoring
  async execute(goal: string): Promise<string> {
    try {
      const result = await super.execute(goal)

      // Log circuit breaker state
      const state = this.circuitBreaker.getState()
      console.log(`\nğŸ“Š Circuit Breaker Stats:`)
      console.log(`  Total calls: ${state.total_calls}`)
      console.log(`  Most called agent: ${state.most_called_agent}`)

      return result

    } catch (error) {
      // Circuit breaker opened
      if (error.message.includes('Circuit breaker opened')) {
        console.error(`\nğŸ›‘ CIRCUIT BREAKER TRIGGERED`)
        console.error(error.message)

        // Return partial results
        return this.getPartialResults()
      }

      throw error
    }
  }

  private getPartialResults(): string {
    const completedTasks = this.taskQueue.filter(t => t.status === 'completed')

    return `# Partial Results (Circuit Breaker Triggered)

Completed: ${completedTasks.length}/${this.taskQueue.length} tasks

${completedTasks.map(t => `### ${t.description}\n${t.result}\n`).join('\n---\n\n')}

Note: Execution stopped early to prevent infinite loop.`
  }
}
```

---

## 3. Autonomous Feedback Loops

### The Pattern

**Problem:** Worker agents make mistakes. Manager needs to detect and correct them autonomously.

**Solution:** Self-verification loop where manager reviews worker output and requests revisions if needed.

```typescript
/**
 * Autonomous Feedback Loop: Self-Correcting Swarm
 */
class SelfCorrectingManagerAgent extends SafeManagerAgent {
  private maxRevisions: number = 2

  // Override execute with feedback loop
  protected async executeWorkerTask(worker: WorkerAgent, task: Task): Promise<string> {
    let revisionCount = 0
    let result: string

    while (revisionCount &lt;= this.maxRevisions) {
      // Execute task
      result = await super.executeWorkerTask(worker, task)

      // Self-verify result
      const verification = await this.verifyResult(task, result)

      if (verification.passed) {
        console.log(`âœ… Verification passed for: ${task.description}`)
        return result
      }

      // Request revision
      console.log(`âš ï¸ Verification failed: ${verification.reason}`)
      console.log(`ğŸ”„ Requesting revision (${revisionCount + 1}/${this.maxRevisions})`)

      revisionCount++

      // Update task with feedback
      task.description = `${task.description}

REVISION REQUEST:
${verification.reason}

Previous attempt:
${result}

Please revise your work addressing the issues above.`
    }

    // Max revisions reached, return last attempt
    console.warn(`âš ï¸ Max revisions reached for: ${task.description}`)
    return result!
  }

  // Verify worker output meets quality standards
  private async verifyResult(task: Task, result: string): Promise<{
    passed: boolean
    reason?: string
  }> {
    const prompt = `You are a Quality Assurance Agent verifying work.

Task: ${task.description}

Worker Output:
${result}

Verify this output meets quality standards:
1. Completeness: Does it fully address the task?
2. Accuracy: Is the information correct?
3. Specificity: Are there concrete details (not vague statements)?
4. Actionability: Can this be used to make decisions?

Return JSON:
{
  "passed": true/false,
  "reason": "Explanation if failed"
}`

    const response = await this.anthropic.messages.create({
      model: 'claude-3-haiku-20240307', // Cheap model for verification
      max_tokens: 512,
      messages: [{ role: 'user', content: prompt }]
    })

    const verificationJson = response.content[0].text.match(/\{[\s\S]*\}/)?.[0]
    return JSON.parse(verificationJson || '{"passed": true}')
  }
}
```

### Example: Self-Correcting Market Research

```typescript
const manager = new SelfCorrectingManagerAgent()

// Register market researcher
manager.registerWorker({
  id: 'market_researcher',
  name: 'Market Researcher',
  specialization: 'market analysis',
  model: 'claude-3-5-sonnet-20241022',
  available: true
})

// Execute task
const result = await manager.execute('Analyze the AI chatbot market size and growth rate')

// Output:
// ğŸ”„ Market Researcher executing: Analyze the AI chatbot market...
// âš ï¸ Verification failed: Output lacks specific numbers and sources
// ğŸ”„ Requesting revision (1/2)
// ğŸ”„ Market Researcher executing: [REVISED TASK]
// âœ… Verification passed for: Analyze the AI chatbot market...
```

---

## 4. Production Monitoring

### Cost Tracking

```typescript
/**
 * Track costs per agent and per task
 */
interface AgentCostMetrics {
  agent_id: string
  total_calls: number
  total_tokens: number
  total_cost_usd: number
  avg_latency_ms: number
}

class MonitoredManagerAgent extends SelfCorrectingManagerAgent {
  private costMetrics: Map<string, AgentCostMetrics>

  constructor() {
    super()
    this.costMetrics = new Map()
  }

  // Override executeWorkerTask to track costs
  protected async executeWorkerTask(worker: WorkerAgent, task: Task): Promise<string> {
    const startTime = Date.now()

    const result = await super.executeWorkerTask(worker, task)

    const latency = Date.now() - startTime

    // Estimate cost (simplified)
    const tokens = Math.ceil(result.length / 4)
    const costPerToken = worker.model.includes('haiku') ? 0.00000025 : 0.000003
    const cost = tokens * costPerToken

    // Update metrics
    const metrics = this.costMetrics.get(worker.id) || {
      agent_id: worker.id,
      total_calls: 0,
      total_tokens: 0,
      total_cost_usd: 0,
      avg_latency_ms: 0
    }

    metrics.total_calls++
    metrics.total_tokens += tokens
    metrics.total_cost_usd += cost
    metrics.avg_latency_ms = (metrics.avg_latency_ms * (metrics.total_calls - 1) + latency) / metrics.total_calls

    this.costMetrics.set(worker.id, metrics)

    return result
  }

  // Get cost report
  getCostReport(): AgentCostMetrics[] {
    return Array.from(this.costMetrics.values())
      .sort((a, b) => b.total_cost_usd - a.total_cost_usd)
  }

  // Print dashboard
  printDashboard() {
    console.log('\n===== SWARM COST DASHBOARD =====')
    const report = this.getCostReport()

    for (const metrics of report) {
      const worker = this.workers.get(metrics.agent_id)
      console.log(`\n${worker?.name}:`)
      console.log(`  Calls: ${metrics.total_calls}`)
      console.log(`  Tokens: ${metrics.total_tokens.toLocaleString()}`)
      console.log(`  Cost: $${metrics.total_cost_usd.toFixed(4)}`)
      console.log(`  Avg Latency: ${metrics.avg_latency_ms.toFixed(0)}ms`)
    }

    const totalCost = report.reduce((sum, m) => sum + m.total_cost_usd, 0)
    const totalTokens = report.reduce((sum, m) => sum + m.total_tokens, 0)

    console.log(`\n--- TOTAL ---`)
    console.log(`  Total Cost: $${totalCost.toFixed(4)}`)
    console.log(`  Total Tokens: ${totalTokens.toLocaleString()}`)
    console.log('================================\n')
  }
}
```

---

## 5. Production Example: Full Swarm

```typescript
async function productLaunchSwarm() {
  // Initialize monitored manager with circuit breaker
  const manager = new MonitoredManagerAgent()

  // Register specialized workers
  manager.registerWorker({
    id: 'market_researcher',
    name: 'Market Researcher',
    specialization: 'market analysis, competitive research',
    model: 'claude-3-5-sonnet-20241022',
    available: true
  })

  manager.registerWorker({
    id: 'tech_architect',
    name: 'Tech Architect',
    specialization: 'system design, scalability, security',
    model: 'claude-3-5-sonnet-20241022',
    available: true
  })

  manager.registerWorker({
    id: 'marketing_strategist',
    name: 'Marketing Strategist',
    specialization: 'brand positioning, go-to-market strategy',
    model: 'claude-3-5-sonnet-20241022',
    available: true
  })

  manager.registerWorker({
    id: 'finance_analyst',
    name: 'Finance Analyst',
    specialization: 'budget planning, ROI modeling',
    model: 'claude-3-haiku-20240307', // Cheaper for simpler tasks
    available: true
  })

  // Execute swarm
  const goal = `Launch an AI-powered customer support chatbot SaaS product.

Requirements:
- Target market: SMBs with 10-100 employees
- Budget: $500K for first year
- Timeline: 6 months to launch

Deliverables needed:
1. Market opportunity analysis
2. Technical architecture (scalable to 1M users)
3. Go-to-market strategy
4. Financial projections (3-year)
`

  const result = await manager.execute(goal)

  // Print results
  console.log('='.repeat(80))
  console.log('PRODUCT LAUNCH PLAN')
  console.log('='.repeat(80))
  console.log(result)

  // Print cost dashboard
  manager.printDashboard()

  return result
}

// Run swarm
await productLaunchSwarm()
```

**Output:**
```
===== SWARM COST DASHBOARD =====

Market Researcher:
  Calls: 2
  Tokens: 4,521
  Cost: $0.0136
  Avg Latency: 2,341ms

Tech Architect:
  Calls: 2
  Tokens: 5,832
  Cost: $0.0175
  Avg Latency: 2,789ms

Marketing Strategist:
  Calls: 1
  Tokens: 3,210
  Cost: $0.0096
  Avg Latency: 1,890ms

Finance Analyst:
  Calls: 1
  Tokens: 2,100
  Cost: $0.0005
  Avg Latency: 1,234ms

--- TOTAL ---
  Total Cost: $0.0412
  Total Tokens: 15,663
================================
```

---

## Key Takeaways

1. **Hierarchical Architecture**: Manager-worker pattern for complex workflows
2. **Semantic Circuit Breakers**: Prevent infinite loops with similarity detection
3. **Autonomous Feedback Loops**: Self-verification and revision requests
4. **Production Monitoring**: Track costs, latency, and call patterns per agent
5. **Specialized Workers**: One agent per domain (market, tech, finance, marketing)

**Production Checklist:**
- [ ] Implement circuit breaker with max iterations (20)
- [ ] Add semantic duplicate detection (similarity &gt; 0.9)
- [ ] Enable self-verification with revision loops (max 2)
- [ ] Track costs per agent and per task
- [ ] Monitor for rapid back-and-forth between agents
- [ ] Set budget alerts for swarm execution ($0.10 limit)

---

**Next:** Week 12 - Global AI Gateway & Enterprise FinOps
