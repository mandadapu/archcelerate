---
title: "Multi-Agent Coordination Patterns"
description: "Coordinate multiple AI agents effectively with idempotent hand-offs, atomic state checkpointing, and resilient pipeline execution"
estimatedMinutes: 50
objectives:
  - Design sequential, parallel, and hierarchical multi-agent workflows
  - Implement idempotent agent hand-offs with persistent state checkpointing
  - Choose between Supervisor and Choreography orchestration models
  - Build Egress Hand-offs to reduce inter-agent context bloat by 87%
  - Validate workflow DAGs to prevent circular dependency deadlocks
---

# Multi-Agent Coordination Patterns

## Why Multi-Agent Systems?

**Simple Explanation**: Just like a company needs different specialists (marketing, engineering, sales), complex AI tasks often need different "specialist" agents working together. A single AI agent trying to do everything is like asking one person to run an entire company.

**When You Need Multiple Agents**:
1. **Task Complexity**: The task requires multiple distinct skills (research + writing + coding)
2. **Parallel Processing**: Different parts can be done simultaneously to save time
3. **Specialization**: Each agent optimized for specific capabilities
4. **Reliability**: If one agent fails, others can continue or compensate

**Real Example**: Building a blog post about a technical topic
- **Researcher Agent**: Finds latest information and sources
- **Writer Agent**: Creates engaging content from research
- **Fact Checker Agent**: Verifies claims and statistics
- **SEO Agent**: Optimizes for search engines

## Core Concepts

### Agent Roles & Capabilities

**Simple Explanation**: Think of agents as specialists with specific skills. A researcher agent knows how to search and analyze, while a writer agent knows how to create compelling content.

```typescript
interface Agent {
  role: string          // What the agent does
  capabilities: string[] // Skills/tools it can use
  execute: (task: Task) => Promise<Result>
}

// Example: Research specialist
const researcher: Agent = {
  role: 'researcher',
  capabilities: ['web_search', 'document_analysis', 'data_extraction'],
  execute: async (task) => {
    // Specialized research logic
    const sources = await webSearch(task.query)
    const analysis = await analyzeDocuments(sources)
    return {
      findings: analysis,
      sources: sources,
      confidence: 0.85
    }
  }
}

// Example: Writer specialist
const writer: Agent = {
  role: 'writer',
  capabilities: ['content_generation', 'summarization', 'editing'],
  execute: async (task) => {
    const prompt = `Write a ${task.style} article about:
    ${task.topic}

    Using this research:
    ${task.context}

    Target audience: ${task.audience}`

    const response = await anthropic.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 2000,
      messages: [{ role: 'user', content: prompt }]
    })

    return {
      content: response.content[0].text,
      wordCount: response.content[0].text.split(' ').length
    }
  }
}

// Example: Coder specialist
const coder: Agent = {
  role: 'coder',
  capabilities: ['code_generation', 'debugging', 'testing'],
  execute: async (task) => {
    const code = await generateCode(task.requirements)
    const tests = await generateTests(code)
    const bugs = await analyzeCode(code)

    return {
      code,
      tests,
      issues: bugs,
      tested: bugs.length === 0
    }
  }
}
```

**Technical Details**:
- **Role Definition**: Clear responsibilities prevent overlap
- **Capability Registry**: Allows dynamic agent selection based on task requirements
- **Stateless vs Stateful**: Stateless agents are easier to scale, stateful remember context
- **Cost**: Each agent call costs separately - plan carefully!

**Architect's Tip ‚Äî Supervisor vs. Choreography (The Orchestration Decision)**: "Every multi-agent system faces the same architectural fork: **Supervisor** (Hub-and-Spoke) or **Choreography** (Event-Driven). A Supervisor has one coordinator that dispatches tasks and collects results ‚Äî it's easy to reason about but creates a single point of failure and a bottleneck. Choreography has agents react to events from each other ‚Äî it scales better but is harder to debug because there's no central log of 'who did what.' An Architect picks Supervisor for **transactional workflows** where you need rollback capability (refund processing, compliance audits), and Choreography for **streaming pipelines** where throughput matters more than consistency (content generation, monitoring)."

```typescript
/**
 * Supervisor vs. Choreography: The Orchestration Decision
 *
 * SUPERVISOR (Hub-and-Spoke):
 * ‚úÖ Central control ‚Äî easy to debug, audit, and rollback
 * ‚úÖ Single orchestrator knows full workflow state
 * ‚úÖ Natural fit for transactional workflows
 * ‚ùå Single point of failure (supervisor crash = full stop)
 * ‚ùå Bottleneck at high concurrency (all agents report to one node)
 *
 * CHOREOGRAPHY (Event-Driven):
 * ‚úÖ No single point of failure ‚Äî agents react independently
 * ‚úÖ Scales horizontally (add agents without changing coordinator)
 * ‚úÖ Natural fit for streaming/pipeline workloads
 * ‚ùå Hard to debug (no central "who did what" log)
 * ‚ùå Circular event loops can emerge silently
 *
 * Interview Defense: "We use Supervisor for compliance-sensitive
 * workflows where we need audit trails and rollback. We use
 * Choreography for content pipelines where throughput matters
 * more than transactional guarantees."
 */

type OrchestrationModel = 'supervisor' | 'choreography'

interface OrchestrationDecision {
  workflow: string
  needsRollback: boolean
  needsAuditTrail: boolean
  agentCount: number
  throughputCritical: boolean
  concurrentUsers: number
}

function selectOrchestrationModel(
  config: OrchestrationDecision
): { model: OrchestrationModel; reasoning: string } {
  // Rule 1: Transactional workflows always use Supervisor
  if (config.needsRollback || config.needsAuditTrail) {
    return {
      model: 'supervisor',
      reasoning: `Workflow "${config.workflow}" requires ${
        config.needsRollback ? 'rollback' : 'audit trail'
      } ‚Äî Supervisor provides central state tracking`
    }
  }

  // Rule 2: High concurrency + throughput ‚Üí Choreography
  if (config.throughputCritical && config.concurrentUsers > 100) {
    return {
      model: 'choreography',
      reasoning: `${config.concurrentUsers} concurrent users with throughput priority ‚Äî Choreography avoids supervisor bottleneck`
    }
  }

  // Rule 3: Small agent count ‚Üí Supervisor (simpler)
  if (config.agentCount <= 4) {
    return {
      model: 'supervisor',
      reasoning: `Only ${config.agentCount} agents ‚Äî Supervisor overhead is minimal, debugging is easier`
    }
  }

  // Default: Choreography for large, non-transactional systems
  return {
    model: 'choreography',
    reasoning: `${config.agentCount} agents without transactional requirements ‚Äî Choreography scales better`
  }
}

// Decision matrix:
//
// | Workflow              | Rollback? | Audit? | Agents | Model         |
// |-----------------------|-----------|--------|--------|---------------|
// | Refund processing     | Yes       | Yes    | 3      | Supervisor    |
// | Content generation    | No        | No     | 6      | Choreography  |
// | Compliance audit      | No        | Yes    | 4      | Supervisor    |
// | Real-time monitoring  | No        | No     | 8      | Choreography  |
// | Invoice approval      | Yes       | Yes    | 3      | Supervisor    |
```

## Orchestration Patterns

### Pattern 1: Sequential Workflow (Pipeline)

**Simple Explanation**: Agents work one after another, like an assembly line. The output of one agent becomes the input for the next.

**When to Use**:
- Output of one agent is needed as input for the next
- Tasks have dependencies (can't write before researching)
- Need to maintain quality through staged review

```typescript
async function sequentialWorkflow(topic: string) {
  console.log('Starting sequential workflow for:', topic)

  // Stage 1: Research (0-30 seconds)
  console.log('Stage 1: Research...')
  const research = await agents.researcher.execute({
    type: 'research',
    query: topic,
    depth: 'comprehensive'
  })
  console.log(`‚úì Found ${research.sources.length} sources`)

  // Stage 2: Outline (5-10 seconds)
  console.log('Stage 2: Outline...')
  const outline = await agents.writer.execute({
    type: 'outline',
    context: research.findings,
    format: 'blog_post'
  })
  console.log(`‚úì Created ${outline.sections.length} sections`)

  // Stage 3: Write (20-40 seconds)
  console.log('Stage 3: Writing...')
  const draft = await agents.writer.execute({
    type: 'write',
    outline: outline,
    context: research.findings,
    style: 'professional'
  })
  console.log(`‚úì Wrote ${draft.wordCount} words`)

  // Stage 4: Review (10-15 seconds)
  console.log('Stage 4: Review...')
  const review = await agents.reviewer.execute({
    type: 'review',
    content: draft.content,
    criteria: ['accuracy', 'clarity', 'engagement']
  })

  // Stage 5: Revise if needed (15-30 seconds)
  if (review.needsRevision) {
    console.log('Stage 5: Revising...')
    const final = await agents.writer.execute({
      type: 'revise',
      content: draft.content,
      feedback: review.suggestions
    })
    return final
  }

  return draft
}

// Usage
const blogPost = await sequentialWorkflow('AI Agent Coordination Patterns')
// Total time: 50-125 seconds
// Total cost: ~$0.15-0.30 (depending on content length)
```

**Performance Metrics**:
- **Total Time**: 50-125 seconds (sum of all stages)
- **Parallelization**: None (must be sequential)
- **Cost**: 5 agent calls √ó $0.03-0.06 = $0.15-0.30 per workflow
- **Quality**: Highest (each stage reviews previous)

### Pattern 2: Parallel Workflow (Fan-Out/Fan-In)

**Simple Explanation**: Multiple agents work at the same time on different parts, then combine results. Like having multiple researchers each investigating different aspects simultaneously.

**When to Use**:
- Tasks can be split into independent parts
- Speed is critical (want to minimize total time)
- Different perspectives improve quality

```typescript
async function parallelWorkflow(task: string) {
  console.log('Starting parallel workflow for:', task)

  // Fan-Out: Multiple agents work simultaneously
  const startTime = Date.now()

  const [research, examples, references, competitors] = await Promise.all([
    // Agent 1: General research (30s)
    agents.researcher.execute({
      type: 'research',
      query: task,
      focus: 'general_overview'
    }),

    // Agent 2: Code examples (25s)
    agents.coder.execute({
      type: 'examples',
      query: task,
      language: 'typescript'
    }),

    // Agent 3: Academic references (35s)
    agents.librarian.execute({
      type: 'references',
      query: task,
      sources: ['arxiv', 'papers_with_code']
    }),

    // Agent 4: Competitor analysis (40s)
    agents.analyst.execute({
      type: 'competitor_analysis',
      topic: task
    })
  ])

  const fanOutTime = Date.now() - startTime
  console.log(`‚úì Parallel execution completed in ${fanOutTime}ms`)

  // Fan-In: Coordinator synthesizes all results
  const synthesis = await agents.coordinator.execute({
    type: 'synthesize',
    inputs: {
      research: research.findings,
      codeExamples: examples.code,
      academicSources: references.papers,
      marketAnalysis: competitors.insights
    }
  })

  const totalTime = Date.now() - startTime
  console.log(`‚úì Total workflow: ${totalTime}ms`)

  return {
    content: synthesis,
    metadata: {
      parallelTime: fanOutTime,
      totalTime: totalTime,
      speedup: '3.5x compared to sequential'
    }
  }
}

// Performance comparison
// Sequential: 30 + 25 + 35 + 40 = 130 seconds
// Parallel: max(30, 25, 35, 40) = 40 seconds + 5s synthesis = 45 seconds
// Speedup: 2.9x faster!
```

**Performance Metrics**:
- **Total Time**: 45 seconds (longest agent + synthesis)
- **Speedup**: 2-4x compared to sequential
- **Cost**: Same as sequential (same number of calls)
- **Tradeoff**: Less quality control between stages

### Pattern 3: Hierarchical Coordination (Manager-Worker)

**Simple Explanation**: One "manager" agent breaks down complex tasks and delegates to "worker" agents, then combines their results. Like a project manager coordinating a team.

```typescript
class ManagerAgent {
  private workers: Map<string, Agent>

  constructor(workers: Agent[]) {
    this.workers = new Map(workers.map(w => [w.role, w]))
  }

  async delegateTask(complexTask: ComplexTask) {
    // Step 1: Analyze and decompose the task
    const decomposition = await this.decomposeTask(complexTask)
    console.log(`Decomposed into ${decomposition.subtasks.length} subtasks`)

    // Step 2: Create execution plan
    const plan = this.createExecutionPlan(decomposition)
    console.log(`Execution plan:`, plan)

    // Step 3: Assign subtasks to appropriate workers
    const assignments = plan.subtasks.map(subtask => ({
      subtask,
      agent: this.selectBestAgent(subtask.requirements)
    }))

    // Step 4: Execute with proper coordination
    const results = []
    for (const assignment of assignments) {
      if (assignment.subtask.dependencies.length === 0) {
        // No dependencies, can run immediately
        results.push(assignment.agent.execute(assignment.subtask))
      } else {
        // Has dependencies, wait for them
        const dependencyResults = results.filter((_, i) =>
          assignment.subtask.dependencies.includes(i)
        )
        await Promise.all(dependencyResults)
        results.push(assignment.agent.execute(assignment.subtask))
      }
    }

    const completedResults = await Promise.all(results)

    // Step 5: Synthesize and validate
    const synthesized = await this.synthesize(completedResults)
    const validated = await this.validate(synthesized, complexTask.requirements)

    return validated
  }

  private async decomposeTask(task: ComplexTask) {
    // Use LLM to intelligently break down the task
    const response = await anthropic.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 1500,
      messages: [{
        role: 'user',
        content: `Decompose this complex task into subtasks:

Task: ${task.description}
Requirements: ${JSON.stringify(task.requirements)}
Available agents: ${Array.from(this.workers.keys()).join(', ')}

Return JSON array of subtasks with:
- description: what needs to be done
- assignTo: which agent should do it
- dependencies: array of subtask indices this depends on
- estimatedTime: seconds`
      }]
    })

    return JSON.parse(response.content[0].text)
  }

  private selectBestAgent(requirements: string[]): Agent {
    // Score each agent based on capability match
    const scores = Array.from(this.workers.entries()).map(([role, agent]) => {
      const matchScore = requirements.filter(req =>
        agent.capabilities.includes(req)
      ).length
      return { agent, score: matchScore }
    })

    // Return agent with highest score
    return scores.sort((a, b) => b.score - a.score)[0].agent
  }

  private async synthesize(results: Result[]) {
    // Combine all results into coherent output
    const combined = await anthropic.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 2000,
      messages: [{
        role: 'user',
        content: `Synthesize these agent results into a coherent output:

${results.map((r, i) => `Result ${i + 1}: ${JSON.stringify(r)}`).join('\n\n')}`
      }]
    })

    return combined.content[0].text
  }
}

// Example usage
const manager = new ManagerAgent([
  researcher,
  writer,
  coder,
  reviewer,
  analyst
])

const result = await manager.delegateTask({
  description: 'Create a comprehensive guide on building AI agents with code examples',
  requirements: [
    'research current best practices',
    'provide working code examples',
    'explain tradeoffs',
    'include performance metrics'
  ]
})
```

**Why This Works**:
- **Intelligent Decomposition**: LLM breaks down complex tasks appropriately
- **Dynamic Assignment**: Best agent chosen based on capabilities
- **Dependency Management**: Ensures proper execution order
- **Quality Control**: Manager validates final output

## Communication Patterns

### Shared Memory

```typescript
class SharedMemory {
  private store = new Map<string, any>()

  async write(key: string, value: any, metadata?: any) {
    this.store.set(key, {
      value,
      metadata,
      timestamp: Date.now(),
      version: (this.store.get(key)?.version || 0) + 1
    })
  }

  async read(key: string) {
    return this.store.get(key)?.value
  }

  async subscribe(key: string, callback: (value: any) => void) {
    // Notify callback when key changes
    // Implementation depends on your event system
  }
}

// Agents share findings through memory
const memory = new SharedMemory()

// Agent 1 writes findings
await memory.write('research_findings', researchResults)

// Agent 2 reads and builds on it
const findings = await memory.read('research_findings')
const article = await writeArticle(findings)
```

### Message Passing

```typescript
class MessageBus {
  private subscribers = new Map<string, Function[]>()

  subscribe(topic: string, handler: Function) {
    if (!this.subscribers.has(topic)) {
      this.subscribers.set(topic, [])
    }
    this.subscribers.get(topic)!.push(handler)
  }

  async publish(topic: string, message: any) {
    const handlers = this.subscribers.get(topic) || []
    await Promise.all(handlers.map(h => h(message)))
  }
}

// Usage
const bus = new MessageBus()

// Agent subscribes to events
bus.subscribe('research_complete', async (data) => {
  console.log('Starting writing based on research...')
  await writer.execute({ type: 'write', context: data })
})

// Another agent publishes event
await bus.publish('research_complete', researchResults)
```

**Architect's Tip ‚Äî Selective Context Summarization (The Egress Hand-off)**: "The #1 hidden cost in multi-agent systems is **context bloat**. When Agent A passes its full 8,000-token output to Agent B, and Agent B passes its 10,000-token output to Agent C, you're paying for 18,000 tokens of context that Agent C doesn't need. An Architect enforces an **Egress Hand-off** ‚Äî each agent summarizes its output into a **500-token structured handoff** before passing to the next agent. This cuts inter-agent token costs by 87% and actually improves downstream quality because the receiving agent isn't distracted by irrelevant details."

```typescript
/**
 * Selective Context Summarization (Egress Hand-off)
 *
 * Problem: Agent A produces 8,000 tokens. Agent B receives all 8,000
 * plus its own prompt (2,000 tokens). Agent C receives A's 8,000 +
 * B's 10,000 + its own prompt. By Agent D, you're at 35,000+ tokens
 * of context ‚Äî most of which is irrelevant noise.
 *
 * Cost: At $0.003/1K input tokens, a 4-agent chain costs $0.174
 * per request in context alone. At 100K requests/month = $17,400.
 *
 * Solution: Each agent produces a structured 500-token "Egress Summary"
 * before handing off. Downstream agents receive ONLY the summary,
 * not the full working context.
 *
 * Result: 4-agent chain drops from 58,000 to 7,500 input tokens.
 * Monthly cost: $2,250 (87% reduction). Quality improves because
 * downstream agents focus on relevant signals.
 *
 * Interview Defense: "We enforce Egress Hand-offs between agents.
 * Each agent summarizes its output into 500 tokens before passing
 * downstream. This cut our inter-agent token costs by 87% and
 * actually improved task accuracy by 12% because downstream
 * agents weren't distracted by irrelevant context."
 */

interface EgressSummary {
  agentId: string
  taskCompleted: string        // What this agent did (1 sentence)
  keyFindings: string[]        // Top 3-5 findings (bullet points)
  confidence: number           // 0-1 confidence score
  handoffContext: string       // Structured context for next agent
  tokenCount: number           // Must be <= 500
  warnings: string[]           // Issues the next agent should know about
}

async function createEgressSummary(
  agentId: string,
  fullOutput: string,
  nextAgentRole: string
): Promise<EgressSummary> {
  const response = await anthropic.messages.create({
    model: 'claude-haiku-4-5-20251001',  // Cheap model for summarization
    max_tokens: 600,
    messages: [{
      role: 'user',
      content: `You are creating a handoff summary for the "${nextAgentRole}" agent.

Summarize the following output in EXACTLY this JSON format:
{
  "taskCompleted": "one sentence of what was done",
  "keyFindings": ["finding 1", "finding 2", "finding 3"],
  "confidence": 0.0-1.0,
  "handoffContext": "structured context the next agent needs (max 300 tokens)",
  "warnings": ["any issues or gaps"]
}

RULES:
- Total output must be under 500 tokens
- Include ONLY information relevant to "${nextAgentRole}"
- Omit internal reasoning and intermediate steps

Output to summarize:
${fullOutput}`
    }]
  })

  const parsed = JSON.parse(response.content[0].text)

  return {
    agentId,
    ...parsed,
    tokenCount: response.usage.output_tokens
  }
}

// Cost comparison for a 4-agent chain:
//
// WITHOUT Egress Hand-off (full context forwarding):
//   Agent A output: 8,000 tokens
//   Agent B input:  8,000 + 2,000 prompt = 10,000 tokens ‚Üí output: 10,000
//   Agent C input: 10,000 + 8,000 + 2,000 = 20,000 tokens ‚Üí output: 6,000
//   Agent D input:  6,000 + 20,000 + 2,000 = 28,000 tokens
//   Total input tokens: 10,000 + 20,000 + 28,000 = 58,000
//   Cost at $0.003/1K: $0.174 per request
//   Monthly (100K requests): $17,400
//
// WITH Egress Hand-off (500-token summaries):
//   Agent A output: 8,000 tokens ‚Üí Egress: 500 tokens
//   Agent B input:  500 + 2,000 = 2,500 tokens ‚Üí Egress: 500 tokens
//   Agent C input:  500 + 2,000 = 2,500 tokens ‚Üí Egress: 500 tokens
//   Agent D input:  500 + 2,000 = 2,500 tokens
//   Total input tokens: 2,500 + 2,500 + 2,500 = 7,500
//   Cost at $0.003/1K: $0.023 per request
//   Monthly (100K requests): $2,250
//
// Savings: $15,150/month (87% reduction)
// Quality: +12% accuracy (less noise in context)
```

### Idempotent Agent Hand-offs: Atomic State Checkpointing

**Architect's Tip ‚Äî The Immutable Artifact Contract**: "In a multi-agent system, every agent output must be treated as an **Immutable Artifact** with a unique version ID. Use a persistent state store (like Redis or Postgres) to 'checkpoint' the exact output of Agent A before notifying Agent B. If the system crashes, the orchestrator resumes from the last completed artifact rather than re-triggering the entire chain. This ensures **Atomic Consistency** across the team. Without checkpointing, a crash after the Researcher succeeds but before the Writer starts means you re-run the Researcher ‚Äî wasting tokens and potentially getting different results."

```typescript
/**
 * Idempotent Agent Hand-offs
 *
 * Problem: In a sequential pipeline (Researcher ‚Üí Writer ‚Üí Reviewer),
 * if the Writer crashes after the Researcher succeeds, a naive system
 * restarts the ENTIRE pipeline. The Researcher runs again, wasting
 * $0.35 in tokens, and may produce DIFFERENT results (LLM outputs
 * are non-deterministic). The Writer then receives different context
 * than the original plan intended.
 *
 * Solution: Checkpoint every agent's output as an immutable artifact
 * with a version ID in a persistent store. On restart, the orchestrator
 * checks the checkpoint store and resumes from the last completed
 * artifact ‚Äî skipping already-completed agents entirely.
 *
 * Interview Defense: "Every agent output is checkpointed as an immutable
 * artifact with a content hash and version ID. On crash recovery, the
 * orchestrator queries the checkpoint store and resumes from the last
 * completed stage. This makes our pipelines idempotent ‚Äî re-running
 * the same workflow ID produces the same result without duplicate work
 * or token waste."
 */

interface AgentArtifact {
  artifactId: string          // Unique ID: `${workflowId}-${agentId}-${version}`
  workflowId: string          // Parent workflow execution ID
  agentId: string             // Which agent produced this
  stage: number               // Pipeline stage (0 = first agent, 1 = second, etc.)
  contentHash: string         // SHA-256 of the output (for deduplication)
  output: any                 // The actual agent output
  inputHash: string           // Hash of the input this agent received
  model: string               // Model used (for reproducibility)
  tokenCost: number           // Tokens consumed
  createdAt: Date
  status: 'completed' | 'failed'
}

interface CheckpointStore {
  save(artifact: AgentArtifact): Promise<void>
  getLatestForStage(workflowId: string, stage: number): Promise<AgentArtifact | null>
  getWorkflowState(workflowId: string): Promise<Map<number, AgentArtifact>>
}

// Redis-backed checkpoint store for production
class RedisCheckpointStore implements CheckpointStore {
  private redis: any  // Redis client

  constructor(redisClient: any) {
    this.redis = redisClient
  }

  async save(artifact: AgentArtifact): Promise<void> {
    const key = `checkpoint:${artifact.workflowId}:stage:${artifact.stage}`
    await this.redis.set(key, JSON.stringify(artifact))

    // Also store by artifact ID for direct lookup
    await this.redis.set(`artifact:${artifact.artifactId}`, JSON.stringify(artifact))

    // Set TTL (24 hours ‚Äî artifacts are ephemeral, not permanent storage)
    await this.redis.expire(key, 86400)

    console.log(
      `üìå Checkpointed: ${artifact.agentId} (stage ${artifact.stage}) ‚Üí ` +
      `${artifact.artifactId} [${artifact.tokenCost} tokens]`
    )
  }

  async getLatestForStage(
    workflowId: string,
    stage: number
  ): Promise<AgentArtifact | null> {
    const key = `checkpoint:${workflowId}:stage:${stage}`
    const data = await this.redis.get(key)
    return data ? JSON.parse(data) : null
  }

  async getWorkflowState(
    workflowId: string
  ): Promise<Map<number, AgentArtifact>> {
    const state = new Map<number, AgentArtifact>()
    // Scan for all stages of this workflow
    const keys = await this.redis.keys(`checkpoint:${workflowId}:stage:*`)

    for (const key of keys) {
      const data = await this.redis.get(key)
      if (data) {
        const artifact = JSON.parse(data)
        state.set(artifact.stage, artifact)
      }
    }
    return state
  }
}

class IdempotentPipelineExecutor {
  private checkpoints: CheckpointStore
  private agents: Array<{ agent: Agent; stage: number }>

  constructor(checkpoints: CheckpointStore, agents: Agent[]) {
    this.checkpoints = checkpoints
    this.agents = agents.map((agent, i) => ({ agent, stage: i }))
  }

  async execute(workflowId: string, initialInput: any): Promise<any> {
    console.log(`\n=== Idempotent Pipeline: ${workflowId} ===`)

    // Step 1: Check existing checkpoints (crash recovery)
    const existingState = await this.checkpoints.getWorkflowState(workflowId)
    const resumeFromStage = this.findResumePoint(existingState)

    if (resumeFromStage > 0) {
      console.log(
        `‚ôªÔ∏è  Resuming from stage ${resumeFromStage} ` +
        `(${resumeFromStage} stages already checkpointed)`
      )
    }

    // Step 2: Execute pipeline, skipping completed stages
    let currentInput = initialInput

    for (const { agent, stage } of this.agents) {
      // Check if this stage is already completed
      const existing = existingState.get(stage)
      if (existing && existing.status === 'completed') {
        console.log(`‚è≠Ô∏è  Stage ${stage} (${agent.role}): SKIPPED (checkpointed)`)
        currentInput = existing.output  // Use cached output as next input
        continue
      }

      // Execute this stage
      console.log(`‚ñ∂Ô∏è  Stage ${stage} (${agent.role}): EXECUTING...`)
      const startTime = Date.now()

      const output = await agent.execute({
        ...currentInput,
        _workflowId: workflowId,
        _stage: stage
      })

      const duration = Date.now() - startTime

      // Checkpoint the output BEFORE proceeding to next stage
      const artifact: AgentArtifact = {
        artifactId: `${workflowId}-${agent.role}-${Date.now()}`,
        workflowId,
        agentId: agent.role,
        stage,
        contentHash: this.hashContent(output),
        output,
        inputHash: this.hashContent(currentInput),
        model: 'claude-sonnet-4-5-20250929',
        tokenCost: output._tokenCost || 0,
        createdAt: new Date(),
        status: 'completed'
      }

      await this.checkpoints.save(artifact)

      console.log(
        `‚úÖ Stage ${stage} (${agent.role}): COMPLETED ` +
        `(${duration}ms, ${artifact.tokenCost} tokens)`
      )

      currentInput = output  // Pass to next stage
    }

    console.log(`\nüèÅ Pipeline ${workflowId} complete`)
    return currentInput
  }

  private findResumePoint(
    existingState: Map<number, AgentArtifact>
  ): number {
    // Find the highest completed stage
    let maxCompleted = -1
    for (const [stage, artifact] of existingState) {
      if (artifact.status === 'completed' && stage > maxCompleted) {
        maxCompleted = stage
      }
    }
    return maxCompleted + 1  // Resume from the NEXT stage
  }

  private hashContent(content: any): string {
    // Simple hash for deduplication (use crypto.createHash in production)
    return Buffer.from(JSON.stringify(content)).toString('base64').slice(0, 32)
  }
}

// Crash Recovery Example:
//
// FIRST RUN (crashes after stage 1):
//   ‚ñ∂Ô∏è  Stage 0 (researcher): EXECUTING...
//   üìå Checkpointed: researcher (stage 0) ‚Üí wf-123-researcher-001
//   ‚úÖ Stage 0 (researcher): COMPLETED (15,000ms, 2,400 tokens)
//   ‚ñ∂Ô∏è  Stage 1 (writer): EXECUTING...
//   üìå Checkpointed: writer (stage 1) ‚Üí wf-123-writer-001
//   ‚úÖ Stage 1 (writer): COMPLETED (22,000ms, 3,100 tokens)
//   ‚ñ∂Ô∏è  Stage 2 (reviewer): EXECUTING...
//   üí• CRASH ‚Äî process killed (OOM, timeout, network failure)
//
// SECOND RUN (resumes from stage 2):
//   ‚ôªÔ∏è  Resuming from stage 2 (2 stages already checkpointed)
//   ‚è≠Ô∏è  Stage 0 (researcher): SKIPPED (checkpointed)
//   ‚è≠Ô∏è  Stage 1 (writer): SKIPPED (checkpointed)
//   ‚ñ∂Ô∏è  Stage 2 (reviewer): EXECUTING...
//   üìå Checkpointed: reviewer (stage 2) ‚Üí wf-123-reviewer-001
//   ‚úÖ Stage 2 (reviewer): COMPLETED (8,000ms, 1,200 tokens)
//   üèÅ Pipeline wf-123 complete
//
// WITHOUT checkpointing: Re-run all 3 stages ‚Üí $0.67 wasted, 45s lost
// WITH checkpointing:    Resume from stage 2 ‚Üí $0.00 wasted, 0s lost
//
// | Metric               | Without Checkpointing | With Checkpointing |
// |----------------------|-----------------------|--------------------|
// | Tokens wasted        | 5,500 (stages 0+1)    | 0                  |
// | Cost wasted          | $0.45                  | $0.00              |
// | Time wasted          | 37 seconds             | 0 seconds          |
// | Result consistency   | Different (LLM non-determinism) | Identical (cached) |
// | Redis overhead       | N/A                    | ~2ms per checkpoint |
```

---

## Dynamic Autonomous Refinement Patterns

Since you've already mastered the Multi-Agent Coordination and Task Delegation patterns, the next frontier in AI Workflows is moving from **Static Orchestration** (pre-defined steps) to **Dynamic Autonomous Refinement.**

In a production environment, the biggest workflow failure isn't that the agent stops ‚Äî it's that the agent finishes with a "plausible but incorrect" result. To fix this, we introduce the **Cognitive Feedback Loop** ‚Äî a self-correcting workflow that treats AI output as a "draft" until it passes a multi-stage validation gate.

### Pattern: The Critic-Refine Loop (Self-Correction)

Instead of asking an agent to "Write a technical summary," you implement a loop where the primary agent must justify its work to a secondary Critic Agent.

- **Draft Stage**: Agent A generates the initial output.
- **Audit Stage**: Agent B (The Critic) receives the draft and the original requirements. It identifies missing context, hallucinations, or formatting errors.
- **Refinement Stage**: Agent A receives the critique and must generate a "Version 2."
- **Exit Gate**: The loop repeats until the Critic issues a `PASSED` status or the Max-Iteration Circuit Breaker is hit.

**Architect's Tip ‚Äî The Critic-Refine Loop (Autonomous Self-Correction)**: "A single-pass agent is a liability. In production, the biggest risk isn't that the agent crashes ‚Äî it's that it finishes with a 'plausible but wrong' answer. The Critic-Refine pattern treats every output as a draft. A dedicated Critic Agent ‚Äî with a completely separate system prompt focused on finding flaws ‚Äî reviews the draft against the original requirements. The primary agent then receives the critique and must produce a revised version. The loop exits only when the Critic issues a PASS verdict or the circuit breaker kills it after 3 iterations. This pattern reduces hallucination rates by 60% and catches formatting/compliance errors that would otherwise reach production."

```typescript
/**
 * Critic-Refine Loop: Autonomous Self-Correction
 *
 * Problem: A single-pass agent produces "plausible but incorrect" output
 * 68% of the time on complex tasks. Users don't catch errors until
 * production ‚Äî by then the damage is done.
 *
 * Solution: Introduce a Critic Agent that reviews every draft against
 * the original requirements. The primary agent must address every
 * critique before the output is accepted. A circuit breaker prevents
 * infinite refinement loops.
 *
 * Interview Defense: "Every agent output is treated as a draft. A
 * dedicated Critic Agent ‚Äî with a different system prompt focused on
 * finding flaws ‚Äî reviews it against requirements. The primary agent
 * must address every critique. We cap at 3 iterations with an economic
 * circuit breaker. This reduced our hallucination rate from 12% to 4.5%
 * and caught 94% of formatting errors before production."
 */

interface CriticVerdict {
  status: 'PASSED' | 'NEEDS_REVISION'
  issues: {
    severity: 'critical' | 'major' | 'minor'
    description: string
    location: string        // Which section has the issue
    suggestion: string      // How to fix it
  }[]
  overallScore: number      // 0-100
  passThreshold: number     // Score required to pass (e.g., 85)
}

interface RefinementCycle {
  iteration: number
  draft: string
  verdict: CriticVerdict
  tokenCost: number
  durationMs: number
}

class CriticRefineLoop {
  private maxIterations: number
  private maxTokenBudget: number
  private passThreshold: number

  constructor(config: {
    maxIterations?: number     // Circuit breaker (default: 3)
    maxTokenBudget?: number    // Economic guardrail (default: 10000)
    passThreshold?: number     // Minimum score to pass (default: 85)
  } = {}) {
    this.maxIterations = config.maxIterations ?? 3
    this.maxTokenBudget = config.maxTokenBudget ?? 10000
    this.passThreshold = config.passThreshold ?? 85
  }

  async execute(
    requirements: string,
    primaryAgent: Agent,
    criticAgent: Agent
  ): Promise<{
    finalOutput: string
    cycles: RefinementCycle[]
    totalTokens: number
    totalDuration: number
  }> {
    const cycles: RefinementCycle[] = []
    let totalTokens = 0
    let currentDraft = ''

    for (let i = 1; i <= this.maxIterations; i++) {
      console.log(`\n--- Iteration ${i}/${this.maxIterations} ---`)

      // DRAFT STAGE: Primary agent generates (or refines)
      const draftPrompt = i === 1
        ? `Complete this task:\n${requirements}`
        : `Revise your previous draft based on this critique:\n\n` +
          `PREVIOUS DRAFT:\n${currentDraft}\n\n` +
          `CRITIQUE:\n${JSON.stringify(cycles[cycles.length - 1].verdict.issues, null, 2)}\n\n` +
          `Address every issue. Do not repeat the same mistakes.`

      const draftStart = Date.now()
      const draftResult = await primaryAgent.execute({
        type: 'generate',
        prompt: draftPrompt
      })
      currentDraft = draftResult.text
      const draftTokens = draftResult.tokenCost || 0

      // AUDIT STAGE: Critic reviews the draft
      const criticPrompt = `You are a strict quality auditor. Review this draft against the original requirements.

REQUIREMENTS:
${requirements}

DRAFT (Iteration ${i}):
${currentDraft}

Evaluate and return JSON:
{
  "status": "PASSED" | "NEEDS_REVISION",
  "issues": [
    {
      "severity": "critical" | "major" | "minor",
      "description": "what is wrong",
      "location": "which section",
      "suggestion": "how to fix it"
    }
  ],
  "overallScore": 0-100,
  "passThreshold": ${this.passThreshold}
}

Rules:
- PASSED only if overallScore >= ${this.passThreshold} AND zero critical issues
- Be specific ‚Äî vague feedback wastes refinement cycles`

      const criticResult = await criticAgent.execute({
        type: 'evaluate',
        prompt: criticPrompt
      })
      const verdict: CriticVerdict = JSON.parse(criticResult.text)
      const criticTokens = criticResult.tokenCost || 0
      const cycleDuration = Date.now() - draftStart

      const cycleTokens = draftTokens + criticTokens
      totalTokens += cycleTokens

      cycles.push({
        iteration: i,
        draft: currentDraft,
        verdict,
        tokenCost: cycleTokens,
        durationMs: cycleDuration
      })

      console.log(
        `  Score: ${verdict.overallScore}/100 | ` +
        `Issues: ${verdict.issues.length} | ` +
        `Tokens: ${cycleTokens} | ` +
        `Status: ${verdict.status}`
      )

      // EXIT GATE: Check if we can stop
      if (verdict.status === 'PASSED') {
        console.log(`\n‚úÖ PASSED on iteration ${i}`)
        break
      }

      // ECONOMIC CIRCUIT BREAKER: Don't spend forever refining
      if (totalTokens >= this.maxTokenBudget) {
        console.log(`\n‚ö†Ô∏è Token budget exhausted (${totalTokens}/${this.maxTokenBudget})`)
        break
      }
    }

    return {
      finalOutput: currentDraft,
      cycles,
      totalTokens,
      totalDuration: cycles.reduce((s, c) => s + c.durationMs, 0)
    }
  }
}

// Production example: Technical document generation
//
// const loop = new CriticRefineLoop({
//   maxIterations: 3,
//   maxTokenBudget: 10000,
//   passThreshold: 85
// })
//
// const result = await loop.execute(
//   'Write a 2-page security audit summary for the Q4 SOC 2 report',
//   primaryAgent,   // Writer (Sonnet)
//   criticAgent     // Auditor (Sonnet with strict system prompt)
// )
//
// Iteration trace:
//
// | Iteration | Score | Critical | Major | Minor | Tokens | Status         |
// |-----------|-------|----------|-------|-------|--------|----------------|
// | 1         | 62    | 2        | 3     | 1     | 3,200  | NEEDS_REVISION |
// | 2         | 81    | 0        | 2     | 2     | 2,800  | NEEDS_REVISION |
// | 3         | 91    | 0        | 0     | 1     | 2,400  | PASSED ‚úÖ      |
//
// Total: 8,400 tokens ($0.07) | 3 iterations | 45 seconds
//
// Without Critic-Refine: Score 62, 2 critical issues reach production
// With Critic-Refine: Score 91, zero critical issues, $0.07 cost
//
// | Metric                    | Single-Pass | Critic-Refine Loop |
// |---------------------------|-------------|-------------------|
// | Output quality (avg)      | 62/100      | 89/100            |
// | Critical issues to prod   | 2.1/doc     | 0.04/doc          |
// | Hallucination rate        | 12%         | 4.5%              |
// | Formatting compliance     | 71%         | 97%               |
// | Token cost per document   | 3,200       | 8,400 (2.6x)     |
// | Cost per document         | $0.026      | $0.068            |
// | Rework cost saved         | $0          | $4.50/doc (human) |
```

### Pattern: Multi-Path Speculative Execution

For high-stakes decisions (like financial forecasting or medical triaging), "Single-Path" reasoning is a liability. This pattern runs multiple logic chains in parallel and compares the outcomes.

- **Fan-Out**: Three identical agents receive the same query but use different **Sampling Temperatures** or **System Prompts** (e.g., one is "Conservative," one is "Aggressive," one is "Balanced").
- **Comparison**: A **Consensus Agent** analyzes all three outputs.
- **Synthesis**: If all paths align, the result is highly confident. If they diverge, the system triggers a **Human-in-the-Loop (HITL)** escalation.

**Architect's Tip ‚Äî Multi-Path Speculative Execution (Confidence Through Divergence)**: "For safety-critical decisions, a single reasoning path is an unacceptable risk. An Architect runs the same query through 3 parallel agents with different cognitive biases ‚Äî Conservative (temperature 0.1, risk-averse prompt), Balanced (temperature 0.5, neutral), and Aggressive (temperature 0.9, opportunity-seeking). A Consensus Agent compares the three outputs. If all three align on the same recommendation, confidence is high. If they diverge ‚Äî Conservative says 'Block' while Aggressive says 'Approve' ‚Äî the system triggers HITL escalation. This costs 3x the tokens per query but catches edge cases that single-path reasoning misses 100% of the time."

```typescript
/**
 * Multi-Path Speculative Execution
 *
 * Problem: Single-path reasoning produces one answer with no
 * way to gauge confidence. For a medical triage system, a single
 * "low risk" classification could be catastrophically wrong.
 *
 * Solution: Run the same query through 3 parallel agents with
 * different cognitive biases. A Consensus Agent compares outputs.
 * Agreement = high confidence. Divergence = HITL escalation.
 *
 * Interview Defense: "For safety-critical decisions, we run
 * Multi-Path Speculative Execution ‚Äî 3 agents with different
 * temperatures and system prompts process the same query in
 * parallel. A Consensus Agent compares outputs. If all 3 agree,
 * we auto-approve with high confidence. If they diverge on the
 * recommendation, we escalate to a human reviewer. This catches
 * edge cases that single-path reasoning misses entirely."
 */

interface SpeculativePath {
  pathId: string
  bias: 'conservative' | 'balanced' | 'aggressive'
  temperature: number
  systemPrompt: string
  result: any
  confidence: number
  recommendation: string
  reasoning: string
  tokenCost: number
}

interface ConsensusResult {
  unanimous: boolean
  majorityRecommendation: string
  divergenceScore: number     // 0 = full agreement, 1 = total disagreement
  paths: SpeculativePath[]
  action: 'auto_approve' | 'hitl_escalation'
  escalationReason?: string
}

class MultiPathExecutor {
  private divergenceThreshold: number

  constructor(divergenceThreshold: number = 0.3) {
    this.divergenceThreshold = divergenceThreshold
  }

  async execute(
    query: string,
    context: string
  ): Promise<ConsensusResult> {
    // FAN-OUT: 3 parallel paths with different cognitive biases
    const pathConfigs: Array<{
      bias: 'conservative' | 'balanced' | 'aggressive'
      temperature: number
      systemPrompt: string
    }> = [
      {
        bias: 'conservative',
        temperature: 0.1,
        systemPrompt: `You are a risk-averse analyst. Prioritize safety and caution.
Flag any uncertainty. When in doubt, recommend the safer option.
False negatives (missing a risk) are 10x worse than false positives.`
      },
      {
        bias: 'balanced',
        temperature: 0.5,
        systemPrompt: `You are a balanced analyst. Weigh evidence objectively.
Consider both risks and opportunities. Provide a nuanced recommendation.`
      },
      {
        bias: 'aggressive',
        temperature: 0.9,
        systemPrompt: `You are an opportunity-focused analyst. Identify upside potential.
Consider innovative approaches. Accept calculated risks when the
expected value is positive.`
      }
    ]

    console.log(`üîÄ Fan-Out: Executing ${pathConfigs.length} parallel paths...`)
    const startTime = Date.now()

    // Execute all paths in parallel
    const paths: SpeculativePath[] = await Promise.all(
      pathConfigs.map(async (config, i) => {
        const response = await anthropic.messages.create({
          model: 'claude-sonnet-4-5-20250929',
          max_tokens: 1000,
          temperature: config.temperature,
          system: config.systemPrompt,
          messages: [{
            role: 'user',
            content: `${query}\n\nContext:\n${context}\n\n` +
              `Return JSON: { "recommendation": "string", ` +
              `"confidence": 0-1, "reasoning": "string" }`
          }]
        })

        const parsed = JSON.parse(response.content[0].text)
        return {
          pathId: `path-${i}`,
          bias: config.bias,
          temperature: config.temperature,
          systemPrompt: config.systemPrompt,
          result: parsed,
          confidence: parsed.confidence,
          recommendation: parsed.recommendation,
          reasoning: parsed.reasoning,
          tokenCost: response.usage.input_tokens + response.usage.output_tokens
        }
      })
    )

    const fanOutDuration = Date.now() - startTime
    console.log(`  Fan-Out completed in ${fanOutDuration}ms`)

    // CONSENSUS: Compare all paths
    const recommendations = paths.map(p => p.recommendation)
    const uniqueRecommendations = new Set(recommendations)
    const unanimous = uniqueRecommendations.size === 1

    // Calculate divergence score
    const divergenceScore = 1 - (1 / uniqueRecommendations.size)

    // Determine majority
    const recCounts = new Map<string, number>()
    for (const rec of recommendations) {
      recCounts.set(rec, (recCounts.get(rec) || 0) + 1)
    }
    const majorityRecommendation = Array.from(recCounts.entries())
      .sort((a, b) => b[1] - a[1])[0][0]

    // DECISION: Auto-approve or escalate
    const action = divergenceScore <= this.divergenceThreshold
      ? 'auto_approve' as const
      : 'hitl_escalation' as const

    const escalationReason = action === 'hitl_escalation'
      ? `Paths diverged: ${paths.map(p => `${p.bias}="${p.recommendation}"`).join(', ')}. ` +
        `Divergence score ${divergenceScore.toFixed(2)} exceeds threshold ${this.divergenceThreshold}.`
      : undefined

    if (action === 'hitl_escalation') {
      console.log(`‚ö†Ô∏è HITL ESCALATION: ${escalationReason}`)
    } else {
      console.log(`‚úÖ AUTO-APPROVED: All paths agree on "${majorityRecommendation}"`)
    }

    return {
      unanimous,
      majorityRecommendation,
      divergenceScore,
      paths,
      action,
      escalationReason
    }
  }
}

// Production example: Medical triage classification
//
// const executor = new MultiPathExecutor(0.3)  // Escalate if >30% divergence
//
// const result = await executor.execute(
//   'Classify this patient symptom report for triage priority',
//   patientSymptoms
// )
//
// Scenario 1: All paths agree (auto-approve)
//   Conservative: "HIGH PRIORITY" (confidence: 0.92)
//   Balanced:     "HIGH PRIORITY" (confidence: 0.88)
//   Aggressive:   "HIGH PRIORITY" (confidence: 0.85)
//   ‚Üí Divergence: 0.0 | Action: AUTO_APPROVE
//   ‚Üí Total cost: 3 √ó $0.02 = $0.06
//
// Scenario 2: Paths diverge (HITL escalation)
//   Conservative: "HIGH PRIORITY"   (confidence: 0.71)
//   Balanced:     "MEDIUM PRIORITY" (confidence: 0.55)
//   Aggressive:   "LOW PRIORITY"    (confidence: 0.62)
//   ‚Üí Divergence: 0.67 | Action: HITL_ESCALATION
//   ‚Üí Human reviewer examines all 3 reasoning chains
//
// | Metric                      | Single-Path   | Multi-Path Speculative |
// |-----------------------------|---------------|------------------------|
// | Confidence calibration      | None          | Divergence score       |
// | Edge case detection         | 0% (silent)   | 94% (divergence flag)  |
// | HITL escalation rate        | N/A           | ~15% of queries        |
// | Token cost per query        | $0.02         | $0.06 (3x)            |
// | Misclassification rate      | 8.2%          | 1.4%                  |
// | False confidence rate       | 23%           | 3%                    |
```

### Pattern: The Contextual Short-Circuit (State Pruning)

Large workflows often suffer from **Context Poisoning** ‚Äî where irrelevant data from Step 1 ruins the reasoning in Step 4. This pattern uses **State Pruning** to keep each agent's context window clean.

- **Isolation**: Each agent in the workflow operates in its own **Micro-Context**.
- **Summary Egress**: Instead of passing the whole 50-page research log, the Researcher Agent must output a **JSON Manifest** of "Fact-Verified Findings."
- **Injection**: The next agent only receives the Manifest, keeping its context window clean and its reasoning focused.

**Architect's Tip ‚Äî Contextual Short-Circuit (Preventing Context Poisoning)**: "This pattern extends the Egress Hand-off you've already learned into a stricter discipline. The Egress Hand-off reduces token cost by summarizing. The Contextual Short-Circuit goes further ‚Äî it enforces **schema-validated JSON Manifests** between agents. The Researcher can't pass 'I found some interesting things about the topic' ‚Äî it must output `{ findings: [...], sources: [...], confidence: number }`. If the manifest fails schema validation, the hand-off is rejected. This prevents context poisoning where vague, unstructured text from one agent degrades the next agent's reasoning quality."

```typescript
/**
 * Contextual Short-Circuit: Schema-Enforced State Pruning
 *
 * Problem: In a 5-agent pipeline, Agent E receives the accumulated
 * context of Agents A-D ‚Äî 40,000+ tokens of mixed-quality text.
 * Agent E's reasoning degrades because it's distracted by irrelevant
 * details from Agent A's exploratory research phase.
 *
 * Solution: Each agent outputs a schema-validated JSON Manifest.
 * The next agent receives ONLY the manifest ‚Äî not the raw context.
 * If the manifest fails validation, the hand-off is rejected and
 * the agent must re-generate a compliant summary.
 *
 * Interview Defense: "We enforce Contextual Short-Circuits between
 * every agent. Each agent must output a schema-validated JSON Manifest
 * ‚Äî not raw text. The downstream agent receives only the manifest,
 * keeping its context window clean. If validation fails, the hand-off
 * is rejected. This eliminated context poisoning and improved
 * downstream agent accuracy by 23%."
 */

import { z } from 'zod'

// Schema for Research Agent ‚Üí Writer Agent hand-off
const ResearchManifestSchema = z.object({
  taskCompleted: z.string().max(100),
  findings: z.array(z.object({
    fact: z.string(),
    source: z.string().url(),
    confidence: z.number().min(0).max(1),
    verified: z.boolean()
  })).min(1).max(10),
  keyInsight: z.string().max(300),
  gapsIdentified: z.array(z.string()),
  tokenCount: z.number().max(500)  // Enforce size limit
})

type ResearchManifest = z.infer<typeof ResearchManifestSchema>

// Schema for Coder Agent ‚Üí Reviewer Agent hand-off
const CodeManifestSchema = z.object({
  taskCompleted: z.string().max(100),
  filesModified: z.array(z.object({
    path: z.string(),
    changeType: z.enum(['created', 'modified', 'deleted']),
    summary: z.string().max(200)
  })),
  testsPassing: z.boolean(),
  codeQualityScore: z.number().min(0).max(100),
  knownIssues: z.array(z.string()),
  tokenCount: z.number().max(500)
})

type CodeManifest = z.infer<typeof CodeManifestSchema>

class ContextualShortCircuit {
  /**
   * Validate and enforce a manifest between agents.
   * Rejects hand-offs that don't conform to the schema.
   */
  async enforceManifest<T>(
    agentOutput: string,
    schema: z.ZodSchema<T>,
    agentId: string
  ): Promise<{ valid: true; manifest: T } | { valid: false; errors: string[] }> {
    // Step 1: Parse JSON from agent output
    let parsed: any
    try {
      parsed = JSON.parse(agentOutput)
    } catch {
      return {
        valid: false,
        errors: [`Agent ${agentId} output is not valid JSON`]
      }
    }

    // Step 2: Validate against schema
    const result = schema.safeParse(parsed)

    if (!result.success) {
      const errors = result.error.issues.map(
        issue => `${issue.path.join('.')}: ${issue.message}`
      )
      console.log(
        `‚ùå Manifest rejected from ${agentId}:\n` +
        errors.map(e => `  - ${e}`).join('\n')
      )
      return { valid: false, errors }
    }

    console.log(`‚úÖ Manifest accepted from ${agentId} (${JSON.stringify(result.data).length} chars)`)
    return { valid: true, manifest: result.data }
  }

  /**
   * Execute a pipeline with schema-enforced hand-offs.
   * Each agent receives ONLY the validated manifest from the previous agent.
   */
  async executePipeline(
    stages: Array<{
      agent: Agent
      outputSchema: z.ZodSchema<any>
      maxRetries: number
    }>,
    initialInput: string
  ): Promise<{ finalOutput: any; manifests: any[] }> {
    const manifests: any[] = []
    let currentInput = initialInput

    for (const stage of stages) {
      let manifest: any = null

      for (let retry = 0; retry <= stage.maxRetries; retry++) {
        const prompt = retry === 0
          ? `Complete this task and return a JSON manifest:\n${currentInput}`
          : `Your previous output failed validation. Errors:\n` +
            `${manifests[manifests.length - 1]?.errors?.join('\n')}\n\n` +
            `Fix the issues and return a valid JSON manifest:\n${currentInput}`

        const output = await stage.agent.execute({ type: 'generate', prompt })

        const validation = await this.enforceManifest(
          output.text,
          stage.outputSchema,
          stage.agent.id
        )

        if (validation.valid) {
          manifest = validation.manifest
          break
        }

        if (retry === stage.maxRetries) {
          throw new Error(
            `Agent ${stage.agent.id} failed to produce valid manifest ` +
            `after ${stage.maxRetries + 1} attempts`
          )
        }
      }

      manifests.push(manifest)
      // Next agent receives ONLY the manifest ‚Äî not the raw context
      currentInput = JSON.stringify(manifest)
    }

    return { finalOutput: manifests[manifests.length - 1], manifests }
  }
}

// Production example: 4-agent content pipeline
//
// const shortCircuit = new ContextualShortCircuit()
//
// const result = await shortCircuit.executePipeline([
//   { agent: researcherAgent, outputSchema: ResearchManifestSchema, maxRetries: 2 },
//   { agent: coderAgent,      outputSchema: CodeManifestSchema,     maxRetries: 2 },
//   { agent: writerAgent,     outputSchema: WriterManifestSchema,   maxRetries: 1 },
//   { agent: reviewerAgent,   outputSchema: ReviewManifestSchema,   maxRetries: 1 }
// ], 'Create a technical guide on WebSocket authentication')
//
// Context size comparison (4-agent chain):
//
// | Agent   | Without Short-Circuit | With Short-Circuit | Reduction |
// |---------|----------------------|-------------------|-----------|
// | Agent A | 2,000 tokens (own)   | 2,000 tokens      | 0%        |
// | Agent B | 10,000 tokens (A+B)  | 2,500 tokens      | 75%       |
// | Agent C | 22,000 tokens (A+B+C)| 2,500 tokens      | 89%       |
// | Agent D | 40,000 tokens (all)  | 2,500 tokens      | 94%       |
// | TOTAL   | 74,000 tokens        | 9,500 tokens      | 87%       |
//
// | Metric                        | Raw Context Passing | Short-Circuit |
// |-------------------------------|--------------------|--------------  |
// | Total input tokens (4 agents) | 74,000             | 9,500          |
// | Monthly cost (100K requests)  | $22,200            | $2,850         |
// | Context poisoning incidents   | ~15%               | 0%             |
// | Downstream accuracy           | 74%                | 97%            |
// | Schema validation failures    | N/A                | ~8% (auto-retry)|
```

### The Architect's Workflow Health Checklist

Every production workflow must pass these three operational gates before deployment:

| Gate | Production Requirement | Verification |
|------|----------------------|--------------|
| **Idempotency** | If the workflow crashes at Step 3, can it resume using Step 2's cached output without re-running completed work? | Test by killing the process mid-pipeline and verifying checkpoint-based recovery |
| **Observability** | Can you trace exactly why the Critic rejected a draft in the logs? Can you replay any agent's input/output for debugging? | Verify structured logging captures every agent input, output, verdict, and mutation |
| **Economic Guardrail** | Is there a hard token-limit for the Critic-Refine loop to prevent infinite spend? Does Multi-Path have a budget cap? | Confirm circuit breakers fire at configured thresholds and produce clear error messages |

**Interview Defense Template:**

> **Interviewer:** "How do you ensure AI workflows don't fail silently or run up costs?"
>
> **You:** "Every workflow passes three gates: Idempotency ‚Äî we checkpoint every agent output so crashes resume from the last completed stage, not from scratch. Observability ‚Äî every agent input, output, critique, and plan mutation is logged with structured tracing so we can replay any decision. Economic Guardrail ‚Äî the Critic-Refine loop has a 3-iteration circuit breaker and a 10,000-token budget cap. Multi-Path Speculative Execution has a per-query cost limit. If any gate fails in staging, the workflow doesn't deploy."

---

## Best Practices

1. **Clear Role Definition**: Each agent should have a specific, well-defined purpose
2. **Avoid Over-Coordination**: Too much coordination overhead defeats the purpose
3. **Handle Failures Gracefully**: One agent failure shouldn't break the entire system
4. **Checkpoint Agent Outputs**: Every stage should be an immutable artifact in a persistent store for crash recovery
5. **Monitor Costs**: Multi-agent systems can get expensive quickly
6. **Use Caching**: Many agents may need the same information
7. **Set Timeouts**: Prevent one slow agent from blocking everything

## Common Pitfalls

1. **Too Many Agents**: More agents ‚â† better results. Start simple.
   - **Bad**: 10 agents for a simple task ‚Üí $5 in API calls
   - **Good**: 2-3 agents for complex task ‚Üí $0.30 in API calls

2. **Circular Dependencies**: Agent A waits for B, B waits for A
   - **Fix**: Use dependency graphs, validate before execution

**Architect's Tip ‚Äî DAG-Based Workflow Validation (The Cycle Detector)**: "Never execute a multi-agent workflow without first parsing it into a **Directed Acyclic Graph (DAG)** and validating it. A circular dependency between agents is a **silent deadlock** ‚Äî Agent A waits for B, B waits for C, C waits for A, and your system hangs forever with no error message. An Architect validates the DAG before the first agent fires. If a cycle is detected, it's a **hard stop** ‚Äî no execution, immediate error to the developer. This costs 0.1ms and prevents hours of debugging deadlocked production systems."

```typescript
/**
 * DAG-Based Workflow Validation
 *
 * Problem: Circular dependencies between agents cause silent deadlocks.
 * Agent A ‚Üí B ‚Üí C ‚Üí A creates an infinite wait with no error.
 * In production, this manifests as "the system just hangs" with
 * no logs, no errors, and confused users.
 *
 * Solution: Parse agent dependencies into a DAG. Run topological
 * sort before execution. If a cycle exists, reject the workflow
 * immediately with a clear error showing the cycle path.
 *
 * Interview Defense: "We validate every workflow as a DAG before
 * execution. Cycle detection costs 0.1ms and prevents silent
 * deadlocks that would otherwise take hours to debug in production."
 */

interface WorkflowNode {
  agentId: string
  dependsOn: string[]  // Agent IDs this node waits for
}

interface ValidationResult {
  valid: boolean
  executionOrder: string[] | null
  cycle: string[] | null
  parallelGroups: string[][] | null
}

function validateWorkflowDAG(nodes: WorkflowNode[]): ValidationResult {
  const graph = new Map<string, string[]>()
  const inDegree = new Map<string, number>()

  // Build adjacency list and in-degree count
  for (const node of nodes) {
    if (!graph.has(node.agentId)) graph.set(node.agentId, [])
    if (!inDegree.has(node.agentId)) inDegree.set(node.agentId, 0)

    for (const dep of node.dependsOn) {
      if (!graph.has(dep)) graph.set(dep, [])
      graph.get(dep)!.push(node.agentId)
      inDegree.set(node.agentId, (inDegree.get(node.agentId) || 0) + 1)
    }
  }

  // Kahn's algorithm for topological sort
  const queue: string[] = []
  const executionOrder: string[] = []
  const parallelGroups: string[][] = []

  // Start with nodes that have no dependencies
  for (const [id, degree] of inDegree) {
    if (degree === 0) queue.push(id)
  }

  while (queue.length > 0) {
    // All nodes in current queue can run in parallel
    const currentGroup = [...queue]
    parallelGroups.push(currentGroup)

    const nextQueue: string[] = []
    for (const current of queue) {
      executionOrder.push(current)
      for (const neighbor of graph.get(current) || []) {
        const newDegree = inDegree.get(neighbor)! - 1
        inDegree.set(neighbor, newDegree)
        if (newDegree === 0) nextQueue.push(neighbor)
      }
    }
    queue.length = 0
    queue.push(...nextQueue)
  }

  // If not all nodes are in execution order, there's a cycle
  if (executionOrder.length !== nodes.length) {
    const cycleNodes = nodes
      .filter(n => !executionOrder.includes(n.agentId))
      .map(n => n.agentId)
    return {
      valid: false,
      executionOrder: null,
      cycle: cycleNodes,
      parallelGroups: null
    }
  }

  return {
    valid: true,
    executionOrder,
    cycle: null,
    parallelGroups
  }
}

// Example: Valid workflow
//
// const valid = validateWorkflowDAG([
//   { agentId: 'researcher',  dependsOn: [] },
//   { agentId: 'coder',       dependsOn: [] },
//   { agentId: 'writer',      dependsOn: ['researcher', 'coder'] },
//   { agentId: 'reviewer',    dependsOn: ['writer'] }
// ])
//
// Result: {
//   valid: true,
//   executionOrder: ['researcher', 'coder', 'writer', 'reviewer'],
//   parallelGroups: [['researcher', 'coder'], ['writer'], ['reviewer']]
// }
//
// ‚Üí researcher and coder run in parallel (Group 1)
// ‚Üí writer runs after both complete (Group 2)
// ‚Üí reviewer runs last (Group 3)

// Example: Circular dependency (HARD STOP)
//
// const invalid = validateWorkflowDAG([
//   { agentId: 'researcher',  dependsOn: ['reviewer'] },  // ‚Üê cycle!
//   { agentId: 'writer',      dependsOn: ['researcher'] },
//   { agentId: 'reviewer',    dependsOn: ['writer'] }
// ])
//
// Result: {
//   valid: false,
//   cycle: ['researcher', 'writer', 'reviewer'],
//   executionOrder: null
// }
//
// ‚Üí HARD STOP: "Circular dependency detected:
//     researcher ‚Üí writer ‚Üí reviewer ‚Üí researcher"
// ‚Üí Fix the workflow before any agent fires
```

3. **No Conflict Resolution**: What happens when agents disagree?
   - **Fix**: Implement arbitration (see Week 11, Conflict Resolution)

4. **Ignoring Latency**: Sequential can be too slow for users
   - **Fix**: Use parallel where possible, show progress indicators

## Real-World Example

**Task**: Generate a technical blog post with code examples

```typescript
async function createTechnicalBlogPost(topic: string) {
  const manager = new ManagerAgent([researcher, coder, writer, reviewer])

  // Manager automatically:
  // 1. Has researcher find information (30s)
  // 2. Has coder create examples (parallel, 25s)
  // 3. Has writer create draft with research + code (20s)
  // 4. Has reviewer check quality (15s)
  // 5. Has writer revise if needed (15s)

  const post = await manager.delegateTask({
    description: `Technical blog post about ${topic}`,
    requirements: ['accurate', 'code examples', 'beginner friendly']
  })

  return post
}

// Total time: ~90 seconds (with parallelization)
// Total cost: ~$0.40
// Quality: High (multiple review stages)
```

---

## Architect Challenge: The Specialist vs. Generalist Quiz

**You are designing a multi-agent system for an investment firm. The CEO wants an "AI Analyst" that produces weekly investment reports.**

**The Situation:**

Each report requires: (1) **Market Research** ‚Äî scanning 50+ sources for sector trends, (2) **Financial Modeling** ‚Äî running DCF valuations on 10 stocks, (3) **Risk Assessment** ‚Äî evaluating geopolitical and regulatory risks, and (4) **Report Writing** ‚Äî producing a polished 20-page PDF. The current single-agent approach takes **45 minutes** and costs **$2.80 per report**. The CFO wants to scale from 10 reports/week to 200 reports/week. The current architecture won't survive.

**Your options:**

**A)** Use a **single powerful agent** (Opus) with a massive prompt that includes all instructions for research, modeling, risk, and writing. Give it web search, calculator, and PDF tools. Scale by running 200 sequential requests.

**B)** Deploy a **Supervisor-Specialist Pattern**. One lightweight Supervisor agent (Haiku) decomposes each report request into 4 sub-tasks, dispatches them to 4 specialized agents (Research-Sonnet, Finance-Sonnet, Risk-Haiku, Writer-Sonnet), validates the DAG for dependency cycles, collects results via Egress Hand-offs (500-token summaries), and synthesizes the final report.

**C)** Use **Choreography** with event-driven agents. Each agent listens for events and publishes results. No central coordinator ‚Äî agents self-organize through a message bus.

**D)** Fine-tune a single model on 500 example reports so it can do everything in one call without multiple agents.

<details>
<summary><strong>Click to reveal the correct answer</strong></summary>

### Correct Answer: B ‚Äî Supervisor-Specialist Pattern

An Architect uses **Supervisor-Specialist** for transactional, multi-skill workflows where quality and auditability matter.

**The Math:**

```typescript
// Current: Single agent (Opus)
//   Time per report: 45 minutes
//   Cost per report: $2.80
//   200 reports/week sequential: 150 hours (impossible)
//   200 reports/week parallel: 200 √ó $2.80 = $560/week

// Supervisor-Specialist Pattern:
//   Supervisor (Haiku): $0.02 per dispatch
//   Research Agent (Sonnet): $0.35 (parallel, 8 min)
//   Finance Agent (Sonnet): $0.40 (parallel, 10 min)
//   Risk Agent (Haiku): $0.08 (parallel, 3 min)
//   Writer Agent (Sonnet): $0.30 (sequential after others, 5 min)
//   Egress summaries: 4 √ó $0.01 = $0.04
//
//   Total per report: $1.19
//   Time per report: max(8, 10, 3) + 5 = 15 minutes (67% faster)
//   200 reports/week: 200 √ó $1.19 = $238/week (58% cheaper)
//   Annual savings: (560 - 238) √ó 52 = $16,744
```

**Why other answers fail:**

- **A) Single powerful agent** ‚Äî Opus at $2.80/report √ó 200 = $560/week. No parallelism within each report (45 min each). At 200 reports, you need 150 hours of sequential processing per week. Even with parallel instances, you're paying 2.4x more than the Specialist pattern and getting no quality improvement from specialization.

- **C) Choreography** ‚Äî Investment reports are **transactional workflows** that need audit trails. The CFO needs to know exactly which agent produced which section for compliance. Choreography makes this nearly impossible to trace. When the Risk Agent produces a wrong assessment, you need the Supervisor's central log to identify and fix it. Choreography is for streaming pipelines, not auditable financial documents.

- **D) Fine-tune a single model** ‚Äî Violates the **Behavior vs. Memory** rule. Market data changes daily. A fine-tuned model would confidently report last month's stock prices. Fine-tuning teaches behavior (format, tone), not facts (market data). The report would look polished but contain stale, hallucinated numbers ‚Äî the worst possible outcome for an investment firm.

**The Architect's Principle:** "Supervisor-Specialist is the default for **business-critical, multi-skill workflows**. The Supervisor provides auditability (every sub-task is logged), rollback (re-run just the failed agent), and cost control (use cheap models for simple sub-tasks, expensive models only where quality demands it). The 500-token Egress Hand-off between agents prevents context bloat. The DAG validation prevents deadlocks. This is not just a pattern ‚Äî it's an **operating system for AI workflows**."

</details>

---

## Resources
- [Multi-Agent Systems](https://lilianweng.github.io/posts/2023-06-23-agent/)
- [AutoGPT Architecture](https://github.com/Significant-Gravitas/AutoGPT)
- [LangChain Multi-Agent](https://python.langchain.com/docs/modules/agents/multi_agent)
