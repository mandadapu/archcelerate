---
title: 'AI Cyber-Defense Pipeline with Multi-Model Routing'
description: 'Building a 4-agent security log analysis pipeline using LangGraph with Haiku, Sonnet, and Opus for cost-optimized threat detection and incident reporting'
---

# AI Cyber-Defense Pipeline with Multi-Model Routing

Security Operations Centers (SOCs) drown in logs. A mid-size organization generates 10,000-100,000 security events per day, and human analysts can realistically triage a few hundred. The rest go unread. This case study walks through a production multi-agent architecture that automates the full pipeline: **ingest, detect, classify, and report** — using the right model for each step to keep costs viable at scale.

---

## The Problem

Traditional SIEM tools fire thousands of alerts, most of them false positives. Analysts suffer from alert fatigue and miss real threats buried in noise. An AI-powered pipeline can:

1. **Parse and normalize** logs from heterogeneous sources (syslog, JSON, CSV, Windows Event Log)
2. **Detect threats** using both rule-based patterns and AI reasoning across correlated events
3. **Classify severity** with MITRE ATT&CK mappings and business impact scoring
4. **Generate reports** that both executives and incident responders can act on immediately

The key constraint: doing this with a single expensive model (Opus) at scale costs $12-15/day for enterprise volumes. Multi-model routing cuts that to under $1.10/day — an **92% reduction**.

---

## Architecture Overview

The system uses **LangGraph** to orchestrate four specialized agents in a sequential pipeline with conditional routing. Each agent uses the cheapest model capable of doing its job well.

```
Raw Logs → [Ingest Agent] → [Detect Agent] → [Classify Agent] → [Report Agent] → Incident Report
             Haiku 4.5       Sonnet 4.5       Sonnet 4.5         Opus 4.6
             $0.25/MTok      $3.00/MTok       $3.00/MTok         $15.00/MTok
```

Explore the full system design interactively:

<CyberDefenseDesign />

---

## Key Design Decision: Multi-Model Routing

The most important architectural decision in this system is **not** which model to use — it's recognizing that different pipeline stages have fundamentally different complexity requirements.

### Matching Model to Task Complexity

| Stage | Task Type | Reasoning Required | Model Choice |
|-------|-----------|-------------------|--------------|
| Ingest | Structured extraction | Minimal — pattern matching | Haiku 4.5 |
| Detect | Pattern correlation | Moderate — cross-entry reasoning | Sonnet 4.5 |
| Classify | Framework mapping | Moderate — domain knowledge | Sonnet 4.5 |
| Report | Narrative generation | High — nuanced, dual-audience writing | Opus 4.6 |

**The principle:** Use the cheapest model that won't degrade output quality for that specific task. Log parsing doesn't need Opus-level reasoning. Incident reports do.

---

## Implementation: LangGraph Pipeline

### Shared State

All agents read from and write to a single `PipelineState` object. LangGraph manages state transitions and conditional routing.

```typescript
interface PipelineState {
  // Ingest Agent writes
  rawLogs: string[]
  parsedLogs: LogEntry[]
  invalidCount: number
  totalCount: number

  // Detect Agent writes
  threats: Threat[]
  anomalies: Anomaly[]
  detectionStats: {
    rulesMatched: number
    aiDetections: number
    totalThreats: number
  }

  // Classify Agent writes
  classifiedThreats: ClassifiedThreat[]

  // Report Agent writes
  report: IncidentReport
}
```

### Conditional Routing

Not every pipeline run needs every agent. Conditional edges reduce unnecessary API calls:

```typescript
function shouldDetect(state: PipelineState): string {
  // Skip detection if no valid logs were parsed
  return state.parsedLogs.length > 0 ? 'detect' : 'empty_report'
}

function shouldClassify(state: PipelineState): string {
  // Skip classification if no threats were found
  return state.threats.length > 0 ? 'classify' : 'clean_report'
}

// Classify → Report always proceeds (even low-risk findings need documentation)
```

This means a batch of malformed logs costs only the Haiku parsing call — not the full pipeline.

---

## Agent Deep Dive: Detection Layer

The Detect Agent uses a two-layer approach that balances cost with thoroughness:

```typescript
interface DetectionResult {
  threats: Threat[]
  method: 'rule_based' | 'ai_detected' | 'both'
  processingTime: number
}

async function detectThreats(logs: LogEntry[]): Promise<DetectionResult> {
  // Layer 1: Free, instant rule-based detection
  const ruleResults = applyDetectionRules(logs)

  // Layer 2: AI-powered detection for novel threats
  let aiResults: Threat[] = []
  try {
    aiResults = await detectWithSonnet(logs, ruleResults)
  } catch (error) {
    // Graceful degradation: rule-based results are still valid
    console.warn('AI detection failed, using rules only:', error)
  }

  return {
    threats: deduplicateThreats([...ruleResults, ...aiResults]),
    method: aiResults.length > 0 ? 'both' : 'rule_based',
    processingTime: Date.now() - start,
  }
}
```

**Why two layers?** Rule-based detection catches known patterns (brute force, port scans) for free. AI detection finds novel threats that rules miss — like low-and-slow attacks correlated across dozens of log entries. The AI layer is additive, not a replacement.

---

## Failure Modes: Every Agent Has a Fallback

Production systems fail. Every agent in this pipeline has a defined degradation path:

| Agent | Failure Scenario | Fallback Behavior |
|-------|-----------------|-------------------|
| **Ingest** | Parsing fails for an entry | Keep as raw with `is_valid: false`, continue with valid entries |
| **Detect** | AI detection API timeout | Return rule-based results only |
| **Classify** | Classification model error | Auto-assign MEDIUM risk, ensure all threats reach Report |
| **Report** | Report generation fails | Produce structured template with raw classified data |

**The principle:** No single agent failure should crash the pipeline. Degraded output is always better than no output when security is at stake.

---

## Cost Optimization in Practice

Here's what multi-model routing saves at different scales:

| Scale | Logs/Day | Routed Cost | All-Opus Cost | Savings |
|-------|----------|-------------|---------------|---------|
| Small team | 50 | $0.006 | $0.025 | 76% |
| Mid-size | 500 | $0.024 | $0.180 | 87% |
| Large org | 5,000 | $0.139 | $1.400 | 90% |
| Enterprise | 50,000 | $1.062 | $12.500 | 92% |

At enterprise scale, the difference is $11.44/day — over **$4,100/year** saved on a single pipeline. And this is just one pipeline; organizations typically run multiple.

---

## MITRE ATT&CK Integration

The Classify Agent maps every detected threat to the MITRE ATT&CK framework, providing standardized taxonomy that security teams already know:

```typescript
interface ClassifiedThreat {
  threatId: string
  originalThreat: Threat
  risk: 'critical' | 'high' | 'medium' | 'low' | 'informational'
  riskScore: number // 0-10, computed as likelihood x impact x exploitability
  mitreTechnique: string // e.g., "T1110" (Brute Force)
  mitreStage: string // e.g., "initial_access", "lateral_movement"
  businessImpact: string
  affectedSystems: string[]
  remediationPriority: number
}
```

This structured output means the Report Agent doesn't invent its own severity scale — it works with industry-standard classifications that map directly to playbooks SOC teams already have.

---

## Lessons for AI Architects

### 1. Model Selection is an Architecture Decision

Choosing models isn't a one-time choice at project start. Each component of your system has different requirements. Map task complexity to model capability — and reassess as models improve and pricing changes.

### 2. Conditional Routing Saves More Than You Think

Short-circuit evaluation isn't just a cost optimization — it's a correctness guarantee. If there are no valid logs, the Detect Agent has nothing meaningful to analyze. Sending it empty data would generate false results, not just waste money.

### 3. Design for Graceful Degradation

Every external API call can fail. Define what "good enough" output looks like at each stage. In security, a partial report with rule-based detections is infinitely more valuable than a crashed pipeline with no output.

### 4. Shared State Simplifies Everything

LangGraph's shared state pattern means agents don't need to know about each other. The Detect Agent reads `parsedLogs` and writes `threats`. It doesn't know or care that a Classify Agent exists. This makes testing, swapping models, and adding new agents trivial.

### 5. Use Frameworks Where They Add Value

LangGraph handles state management, conditional routing, and error recovery. These are hard to get right from scratch. The agents themselves are straightforward LLM calls with structured output — keep agent logic simple and let the framework handle orchestration complexity.
