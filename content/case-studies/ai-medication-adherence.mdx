---
title: 'AI for Medication Adherence'
description: 'How predictive ML models close the gap between prescribed medications and patient behavior — a $500 billion problem hiding in plain sight'
---

# The Feynman Summary: AI for Medication Adherence

*Explaining it like you're teaching a curious friend over coffee.*

---

Here's the thing about medicine that nobody likes to talk about: we already have the drugs that work. People just don't take them.

Half of all people with chronic diseases — diabetes, high blood pressure, heart problems — don't take their pills the way they're supposed to. Some never even pick up the prescription. And this isn't a small deal. It kills about 125,000 Americans a year and wastes somewhere around $500 billion. That's not the cost of developing new drugs. That's the cost of people not taking the drugs we already have.

So why don't people take their meds? It's never just one reason. It's a tangle: the pills are expensive, the regimen is confusing, they feel fine so they think they don't need it, they can't get to the pharmacy, they're depressed, they're juggling three jobs. It's a messy, human, multi-variable problem.

And that's exactly the kind of problem AI is good at.

---

## What the AI Actually Does

Think of it in three layers — like a weather forecasting system, but for human behavior:

---

### Layer 1: "Who's going to stop taking their meds?"

The AI looks at everything it can find about a patient — their medical history, what drugs they're on, how many refills they've picked up on time, their income, their insurance, whether they live near a pharmacy, whether they've missed appointments before. It takes all of these variables — dozens, sometimes hundreds — and finds patterns that humans can't see.

It's like this: imagine you're trying to predict which of 10,000 patients won't pick up their blood pressure medication next month. A doctor might have a gut feeling about three or four of them. The AI can score all 10,000 and rank them by risk. Not perfectly — but well enough to focus your limited resources on the 200 patients who need the most help.

---

### Layer 2: "When are they going to drop off?"

This is the more interesting part. It's not just about *who* — it's about *when*. The AI watches behavioral signals over time: Are the gaps between refills getting longer? Did they just change insurance? Did they just get a new medication added to their regimen?

It's like watching a ball rolling toward the edge of a table. The ball hasn't fallen yet, but you can see it's heading that way. These models can give you days or weeks of warning before a patient actually becomes non-adherent. And that warning is the whole game — because once someone has missed two weeks of blood pressure medication, you can't give them those two weeks back.

The best models right now are about 70–80% accurate, which sounds modest until you realize that without them, you're essentially at 0% — you're just waiting for the patient to show up sick.

---

### Layer 3: "What happens if they stop?"

This is where it gets really consequential. The AI connects the dots between medication gaps and hospital readmissions. It can estimate: if this specific patient with these specific conditions stops taking this specific drug for this long, here's the probability they end up back in the hospital within 30 days.

One hospital used this approach for COPD patients and cut readmissions by 48%. Not by giving people better drugs — by giving the right people the right nudge at the right time.

---

## The Punchline

Here's the Feynman part — the thing that makes this beautiful as a system:

**The prediction is only valuable if it leads to action.** A risk score sitting in a database helps nobody. The real innovation isn't the algorithm — it's connecting the algorithm to a workflow. When the model says "this patient is likely to drop off next week because they can't afford the copay," the system needs to automatically route that to someone who can help with a cheaper alternative or a patient assistance program.

The AI doesn't replace the doctor or the pharmacist. It's more like a really good assistant who has read every chart, remembers every missed appointment, knows every patient's financial situation, and taps the doctor on the shoulder at exactly the right moment to say: *"Hey — check on this one before it's too late."*

---

## The Bottom Line

That's it. That's the whole idea. We have the medicines. We have the patients. We just need to close the gap between the two. And it turns out that predicting human behavior at scale — messy, complicated, deeply personal human behavior — is something that machine learning is surprisingly good at, if you give it the right data and connect it to the right actions.

The $500 billion question isn't whether the AI works. It's whether healthcare systems will actually deploy it.
